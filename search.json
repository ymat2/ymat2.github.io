[
  {
    "objectID": "win/wsl.html",
    "href": "win/wsl.html",
    "title": "WSL — Windows Subsystem for Linux",
    "section": "",
    "text": "https://learn.microsoft.com/ja-jp/windows/wsl/\nWindows で Linux ディストリビューションを扱うための機能",
    "crumbs": [
      "Windows",
      "WSL"
    ]
  },
  {
    "objectID": "win/wsl.html#wsl-のインストール-windows11-の場合",
    "href": "win/wsl.html#wsl-のインストール-windows11-の場合",
    "title": "WSL — Windows Subsystem for Linux",
    "section": "WSL のインストール: Windows11 の場合",
    "text": "WSL のインストール: Windows11 の場合\nhttps://learn.microsoft.com/ja-jp/windows/wsl/install\n\nWSL のインストール\n\nWinX → A でターミナルを管理者として起動。\n   wsl --install\n既定では Ubuntu がインストールされる。-d でほかのディストリビューションを指定可能。\n\n\n\n再起動と設定\n\nマシンを再起動する。\n再起動後、インストール処理を経て Ubuntu が起動する。\nEnter new UNIX usernaem: と表示されたらユーザーネームを設定。\nNG例:\n松田  # 日本語\ny matsuda  # スペースを含む\ny.matsuda  # ピリオドを含む\nEnter new UNIX password: と表示されたらパスワードを設定。 sudo とかするときに要求される。\nRetype new UNIX password: と表示されたらパスワードを再入力。",
    "crumbs": [
      "Windows",
      "WSL"
    ]
  },
  {
    "objectID": "win/wsl.html#wsl-のインストール-windows10-の場合",
    "href": "win/wsl.html#wsl-のインストール-windows10-の場合",
    "title": "WSL — Windows Subsystem for Linux",
    "section": "WSL のインストール: Windows10 の場合",
    "text": "WSL のインストール: Windows10 の場合\nhttps://learn.microsoft.com/ja-jp/windows/wsl/install-manual\n\nWindows subsystem for Linux (WSL) を有効化する\n\nWinS → 「コントロールパネル」を検索 → 「開く」\n「プログラム」を開く。\nWindows の機能の有効化または無効化」をクリック。\n「Windows Subsystem for Linux」にチェック → 「OK」\n「今すぐ再起動(N)」\n\n\n\nUbuntu のインストール\n\nWinS → 「Microsoft Store」を検索 → 「開く」\n「Ubuntu」を検索してクリック。\n「入手」\n\n\n\nUbuntu の起動と設定\n\nWinS → 「Ubuntu」を検索 → 「開く」\nEnter new UNIX usernaem: と表示されたらユーザーネームを設定。\nNG例:\n松田  # 日本語\ny matsuda  # スペースを含む\ny.matsuda  # ピリオドを含む\nEnter new UNIX password: と表示されたらパスワードを設定。 sudo とかするときに要求される。\nRetype new UNIX password: と表示されたらパスワードを再入力。",
    "crumbs": [
      "Windows",
      "WSL"
    ]
  },
  {
    "objectID": "win/wsl.html#ubuntu-の更新アップグレード",
    "href": "win/wsl.html#ubuntu-の更新アップグレード",
    "title": "WSL — Windows Subsystem for Linux",
    "section": "Ubuntu の更新・アップグレード",
    "text": "Ubuntu の更新・アップグレード\n# 最新のパッケージ情報を取得\nsudo apt update\n\n# パッケージを最新に更新\nsudo apt upgrade",
    "crumbs": [
      "Windows",
      "WSL"
    ]
  },
  {
    "objectID": "win/powershell.html",
    "href": "win/powershell.html",
    "title": "PowerShell",
    "section": "",
    "text": "https://learn.microsoft.com/ja-jp/powershell/\nMicrosoft 製 CUI。",
    "crumbs": [
      "Windows",
      "PowerShell"
    ]
  },
  {
    "objectID": "win/powershell.html#コマンドレット",
    "href": "win/powershell.html#コマンドレット",
    "title": "PowerShell",
    "section": "コマンドレット",
    "text": "コマンドレット\nPowerShellで実行できるネイティブコマンドはコマンドレットと呼ばれており、 “動詞-名詞”の名前で登録されている。\nGet-Command  # すべてのコマンドレットを取得\nLinux でいう sudo にあたる操作は、PowerShell を「管理者として開く」ことで実行するか、 マシンの設定から、システム &gt; 開発者向け で “sudo の有効化” を ON にして sudo を使う。\n\nエイリアス\n例えばディレクトリを移るコマンドは Set-Location だが、要は cd と同じ。 実際、Set-Location には sl, cd, chdir の3つのエイリアスが用意されている。\nman Set-Location\n他にもエイリアスを調べるには Get-Alias\n\n\nLinux コマンド\nWSL を有効化していれば、wsl に続ける形で Linux コマンドを実行可能:\nwhich wget\n&gt;&gt;&gt; NG\n\nwsl which wget\n&gt;&gt;&gt; 実行可能",
    "crumbs": [
      "Windows",
      "PowerShell"
    ]
  },
  {
    "objectID": "win/powershell.html#profile",
    "href": "win/powershell.html#profile",
    "title": "PowerShell",
    "section": "PROFILE",
    "text": "PROFILE\n\nhttps://learn.microsoft.com/ja-jp/powershell/module/microsoft.powershell.core/about/about_profiles?view=powershell-7.4\nhttps://qiita.com/smicle/items/0ca4e6ae14ea92000d18\n\nPowerShell でも Linux でいう .profile とか .bashrc を設定したい。 設定用のファイルは $PROFILE で決まっており、スコープに応じて以下がある:\n&gt; echo $PROFILE.AllUsersAllHosts\nC:\\Windows\\System32\\WindowsPowerShell\\v1.0\\profile.ps1\n\n&gt; echo $PROFILE.AllUsersCurrentHost\nC:\\Windows\\System32\\WindowsPowerShell\\v1.0\\Microsoft.PowerShell_profile.ps1\n\n&gt; echo $PROFILE.CurrentUserAllHosts\nC:\\Users\\_username_\\OneDrive\\ドキュメント\\WindowsPowerShell\\profile.ps1\n\n&gt; echo $PROFILE.CurrentUserCurrentHost\nC:\\Users\\_username_\\OneDrive\\ドキュメント\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1\nCurrentUserCurrentHost が一番安全だけど、 C:\\Users\\_username_\\OneDrive\\ドキュメント\\ とかいう諸悪の根源ディレクトリにおきたくない。\nひとまず $PROFILE.AllUsersAllHosts に読み込みのみの PROFILE を置いて、 $HOME のスクリプトを読む、という設定にしてみる:\n\n\n$PROFILE.AllUsersAllHosts\n\n$USER_PROFILE=\"$HOME\\profile.ps1\"\nif (Test-Path $USER_PROFILE) {. $USER_PROFILE}\n\nこの PROFILE でファイルを実行する (Linux でいう source) には 実行権限の付与が必要:\nSet-ExecutionPolicy -ExecutionPolicy RemoteSigned\nひとまず touch と which を定義:\n\n\n$HOME\\profile.ps1\n\nSet-Alias touch New-Item\nfunction which() {(Get-Command $args).Path}\n\n\n引数をともなう Alias の設定は function を使う。\n既存のコマンドの上書きはできない？",
    "crumbs": [
      "Windows",
      "PowerShell"
    ]
  },
  {
    "objectID": "win/powershell.html#windows-標準のターミナル",
    "href": "win/powershell.html#windows-標準のターミナル",
    "title": "PowerShell",
    "section": "Windows 標準のターミナル",
    "text": "Windows 標準のターミナル\n\nコマンドプロンプト\n\n古の Microsoft 製 CUI\n\nPowerShell\n\nコマンドプロンプトの後継 (Windows7 以降)。\n\n\nコマンドプロンプトで使えたコマンドも基本的に使える。\n\nWindows Terminal\n\nコマンドプロンプト、PowerShell、bash (WSL 経由) など複数のコマンドラインシェルのホストアプリケーション。\n\n\nWinX → I/A(管理者として実行)\n\n\nCtrl,で設定画面。 デフォルトのプロファイルや外観をいじれる。",
    "crumbs": [
      "Windows",
      "PowerShell"
    ]
  },
  {
    "objectID": "win/0-dev-win.html#はじめに",
    "href": "win/0-dev-win.html#はじめに",
    "title": "Windows 開発環境",
    "section": "はじめに",
    "text": "はじめに\nWindows で UNIX ライクなコマンドライン操作を行うには、いくつかの選択肢がある。\n\nWSL (Windows Subsystem for Linux)\n\nWindows で Linux ディストリビューションを実行する環境を提供する機能。\n\n\nWSL2 からは、カーネルも Linux になっている。\n\n\nMicrosoft としては WSL を推奨している。\n\n\n便利だが、ディスクスペースを食いつぶす問題がある。\n\nPowerShell\n\nMicrosoft 製 CUI。UNIX とは異なる体系。\n\n\nコマンドレットエイリアスのおかげで多少の互換はある。\n\n\nいずれにしても最初はアプリケーションのインストールのために PowerShell での作業になる。 (GUI でもいける。)\n\nGit Bash\n\n後述する Git for Windows をインストールするとついてくる UNIX ライクな環境。\n\n\nパッケージ管理とかビルドユーティリティとかはついてない最低限の構成。\n\nMSYS2 + MinGW\n\nMSYS2 は Windows における POSIX 準拠を目指した開発環境。 パッケージ管理ツールとして Arch Linux で使われる pacman をフォークしている。\n\n\nMinGW は Windows 用の C/C++ ビルドツールチェイン。\n\n\n他の UNIX 系 OS との互換性をできる限り保つなら WSL、 Windows (C ドライブ) 内の作業で完結させつつもビルド環境が必要なら MSYS2 + MinGW、 それ以外の用途なら PowerShell か Git Bash がいいのでは。\n\nデスクトップを OneDrive 下に置く設定は無効にして C:/Users/_username_ で作業する方が安全。",
    "crumbs": [
      "Windows",
      "Windows 開発環境"
    ]
  },
  {
    "objectID": "win/0-dev-win.html#パッケージ管理",
    "href": "win/0-dev-win.html#パッケージ管理",
    "title": "Windows 開発環境",
    "section": "パッケージ管理",
    "text": "パッケージ管理\nWindows におけるパッケージ管理の主な選択肢として、 Microsoft 公式の Winget、 古株で対応するパッケージも多い Chocolatey、 ユーザー権限で使いやすい Scoop の3つがある。\n\nWinget\n新しめの Windows ならデフォルトで使えるはず。 後述のツールはどれも winget で入れることができる。\n\nBasic usage\n\nwinget install/uninstall\n\nパッケージのインストール/アンインストール\n\nwinget search\n\nパッケージの検索\n\n\n例: winget search rstat\n\nwinget list\n\nインストール済みパッケージの表示\n\n\n\n\n\nChocolatey\n\nChocolatey のインストール\nPowerShell を管理者として開く。その後下記のインストールコマンドを実行:\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\n\n\nBasic usage\n\nchoco install/uninstall\n\nパッケージのインストール/アンインストール (管理者権限が必要)\n\nchoco search\n\nパッケージの検索\n\nchoco list\n\nインストール済みパッケージの表示\n\n\n\n\n\nScoop\n\nインストール\nSet-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\nInvoke-RestMethod -Uri https://get.scoop.sh | Invoke-Expression",
    "crumbs": [
      "Windows",
      "Windows 開発環境"
    ]
  },
  {
    "objectID": "win/0-dev-win.html#git",
    "href": "win/0-dev-win.html#git",
    "title": "Windows 開発環境",
    "section": "Git",
    "text": "Git\nプロジェクトのバージョン管理のためにも必須。 インストールは winget か、Git for Windows を参照。",
    "crumbs": [
      "Windows",
      "Windows 開発環境"
    ]
  },
  {
    "objectID": "win/0-dev-win.html#r",
    "href": "win/0-dev-win.html#r",
    "title": "Windows 開発環境",
    "section": "R",
    "text": "R\n\nR for Windows\nRtools\n\nVSCode で使うには PATH を教えてあげる必要がある:\n\n\nsettings.json\n\n{\n  \"r.rpath.windows\": \"C:\\\\Program Files\\\\R\\\\R-4.4.0\\\\bin\\\\x64\\\\R.exe\",\n  \"r.rterm.windows\": \"C:\\\\Program Files\\\\R\\\\R-4.4.0\\\\bin\\\\x64\\\\Rterm.exe\",\n}",
    "crumbs": [
      "Windows",
      "Windows 開発環境"
    ]
  },
  {
    "objectID": "win/0-dev-win.html#python",
    "href": "win/0-dev-win.html#python",
    "title": "Windows 開発環境",
    "section": "Python",
    "text": "Python\n\nhttps://learn.microsoft.com/ja-jp/windows/python/beginners\nhttps://www.python.org/downloads/windows/\n\nPython 環境構築 — Windows を参照",
    "crumbs": [
      "Windows",
      "Windows 開発環境"
    ]
  },
  {
    "objectID": "win/0-dev-win.html#統合開発環境",
    "href": "win/0-dev-win.html#統合開発環境",
    "title": "Windows 開発環境",
    "section": "統合開発環境",
    "text": "統合開発環境\n好きなやつを入れる:\n\nVSCode\nRstudio\nPositron",
    "crumbs": [
      "Windows",
      "Windows 開発環境"
    ]
  },
  {
    "objectID": "win/0-dev-win.html#quarto",
    "href": "win/0-dev-win.html#quarto",
    "title": "Windows 開発環境",
    "section": "Quarto",
    "text": "Quarto\nhttps://quarto.org/docs/get-started/\nWindows 用のやつを入れてあげる。 (R に付属しているやつを使うことはできなさそう?)\nPDF のレンダリング用に tex を入れてやる (c.f. ~/AppData/Roaming/TinyTeX/):\nquarto install tinytex\n\nPDF で日本語フォントを使うには?\nQuarto PDF で日本語フォントを使う場合、 デフォルトでは原ノ味フォントが使われるらしい。 Ubuntu とかは最初のインストールでプリセットされていたはずだが、 Windows の Quarto では原ノ味含め、日本語フォントがプリセットされていないっぽい。\nそこで、tlmgr を使ってフォントをインストールしてやることで使えるようになる:\n&gt; .\\AppData\\Roaming\\TinyTeX\\bin\\windows\\tlmgr.bat install haranoaji\nLocale 'Japanese_Japan.932' is unsupported, and may crash the interpreter.\ntlmgr.pl: package repository https://ftp.kddilabs.jp/CTAN/systems/texlive/tlnet/ (verified)\n[1/1, ??:??/??:??] install: haranoaji [25570k]\nLocale 'Japanese_Japan.932' is unsupported, and may crash the interpreter.\nrunning mktexlsr ...\ndone running mktexlsr.\ntlmgr.pl: package log updated: C:/Users/kokep/AppData/Roaming/TinyTeX/texmf-var/web2c/tlmgr.log\ntlmgr.pl: command log updated: C:/Users/kokep/AppData/Roaming/TinyTeX/texmf-var/web2c/tlmgr-commands.log",
    "crumbs": [
      "Windows",
      "Windows 開発環境"
    ]
  },
  {
    "objectID": "slides/snp24/03_snpeff.html#part.-3-snpeff-によるアノテーション",
    "href": "slides/snp24/03_snpeff.html#part.-3-snpeff-によるアノテーション",
    "title": "Part. 3 SnpEff によるアノテーション",
    "section": "Part. 3 SnpEff によるアノテーション",
    "text": "Part. 3 SnpEff によるアノテーション\n目標\n\n公開データを用いた SNP 解析ができるようになる。\nデータの中身と解析の流れについて理解を深める。\n\n\nコンテンツ\n\n基本的なコマンドライン操作\nNGS 公開データの取得\nクオリティコントロール\nリードマッピング\nバリアントコール\nSNP アノテーション"
  },
  {
    "objectID": "slides/snp24/03_snpeff.html#snpeff-を用いた変異のアノテーション",
    "href": "slides/snp24/03_snpeff.html#snpeff-を用いた変異のアノテーション",
    "title": "Part. 3 SnpEff によるアノテーション",
    "section": "SnpEff を用いた変異のアノテーション",
    "text": "SnpEff を用いた変異のアノテーション\n遺伝子の位置情報 (GTF/GFF) を参照して、 “この SNP は XX 遺伝子上の変異で、しかもアミノ酸を変える” みたいな情報を付加する。"
  },
  {
    "objectID": "slides/snp24/03_snpeff.html#snpeff-実行環境の構築-のための-java-環境構築",
    "href": "slides/snp24/03_snpeff.html#snpeff-実行環境の構築-のための-java-環境構築",
    "title": "Part. 3 SnpEff によるアノテーション",
    "section": "SnpEff 実行環境の構築 (のための Java 環境構築)",
    "text": "SnpEff 実行環境の構築 (のための Java 環境構築)\n https://pcingola.github.io/SnpEff/download/ \nSnpEff は Java というプログラミング言語に依存している。 遺伝研の Java はちょっと古いので、 最新版の Java をインストール する:\nmkdir ~/bin\ncd ~/bin\nwget https://download.oracle.com/java/23/latest/jdk-23_linux-x64_bin.tar.gz\ntar zxvf jdk-23_linux-x64_bin.tar.gz\n# rm jdk-23_linux-x64_bin.tar.gz"
  },
  {
    "objectID": "slides/snp24/03_snpeff.html#snpeff-実行環境の構築-のための-java-環境構築-1",
    "href": "slides/snp24/03_snpeff.html#snpeff-実行環境の構築-のための-java-環境構築-1",
    "title": "Part. 3 SnpEff によるアノテーション",
    "section": "SnpEff 実行環境の構築 (のための Java 環境構築)",
    "text": "SnpEff 実行環境の構築 (のための Java 環境構築)\nJava コマンドをどこでも使えるようにする。 (PATH を通す。)\nホームに戻って、.bash_profile (もしくは .bashrc) というファイルがあることを確認する。\ncd\nls -a\nどちらかを開いて、以下の行を追加して保存する:\nexport JAVA_HOME=${HOME}/bin/jdk-23  # ダウンロードしたものに合わせる。jdk23-1 なら ${HOME}/bin/jdk23-1 と書く。\nexport PATH=${JAVA_HOME}/bin:$PATH\nexport MALLOC_ARENA_MAX=2\n編集したファイルを読み込み、Java の動作確認をする:\nsource .bash_profile\njava -version"
  },
  {
    "objectID": "slides/snp24/03_snpeff.html#snpeff-実行環境の構築",
    "href": "slides/snp24/03_snpeff.html#snpeff-実行環境の構築",
    "title": "Part. 3 SnpEff によるアノテーション",
    "section": "SnpEff 実行環境の構築",
    "text": "SnpEff 実行環境の構築\n最新版の SnpEff をダウンロードする:\ncd ~/bin\nwget https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip\nunzip snpEff_latest_core.zip\n# rm snpEff_latest_core.zip\n先ほどと同じように SnpEff の PATH を通す。 ホームの .bash_profile か .bashrc を開いて以下の行を追加する:\nexport PATH=${HOME}/bin/snpEff/scripts:$PATH\nSnpEff の動作確認をする:\nsnpEff -version"
  },
  {
    "objectID": "slides/snp24/03_snpeff.html#snpeff-による変異のアノテーション",
    "href": "slides/snp24/03_snpeff.html#snpeff-による変異のアノテーション",
    "title": "Part. 3 SnpEff によるアノテーション",
    "section": "SnpEff による変異のアノテーション",
    "text": "SnpEff による変異のアノテーション\nSnpEff は既存の遺伝子情報データベースをダウンロードしたり、 手元の GTF/GFF からデータベースを自作したりして使う。\nEscherichia_coli_b_str_rel606 の遺伝子情報をダウンロード:\ncd ~/snp24  # 作業ディレクトリへ戻るのを忘れずに\nsnpEff download -v Escherichia_coli_b_str_rel606\n変異のアノテーション:\nsnpEff Escherichia_coli_b_str_rel606 hq_SRR030257.vcf &gt; hq_SRR030257_snpeff.vcf"
  },
  {
    "objectID": "slides/snp24/03_snpeff.html#snpeff-の結果-vcf",
    "href": "slides/snp24/03_snpeff.html#snpeff-の結果-vcf",
    "title": "Part. 3 SnpEff によるアノテーション",
    "section": "SnpEff の結果 (VCF)",
    "text": "SnpEff の結果 (VCF)\nless hq_SRR030257_snpeff.vcf\n長くて見づらいが、INFO フィールドに新たに ANN= に続く形でアノテーション結果が書かれている。\nアノテーション結果は | 区切りの16項目からなる。 複数の遺伝子にまたがる場合はさらに , 区切りで続く。\n例:\nG|missense_variant|MODERATE|pcnB|ECB_00142|transcript|ACT37835|protein_coding|1/1|c.904A&gt;C|p.Asn302His|904/1365|904/1365|302/454||WARNING_TRANSCRIPT_NO_START_CODON\n# ALTアリル|変異の種類|変異の影響|遺伝子名|遺伝子ID|タイプ|転写産物名|転写産物biotype|Rank/total|塩基の位置と変異|アミノ酸の位置と変異|cDNA_position/cDNA_length|CDS_position/CDS_length|Protein_position/Protein_length|Distance to feature|エラーや警告\npcnB のアミノ酸を変える変異、302番目のアスパラギンがヒスチジンになっている。"
  },
  {
    "objectID": "slides/snp24/03_snpeff.html#snpeff-の結果-genes",
    "href": "slides/snp24/03_snpeff.html#snpeff-の結果-genes",
    "title": "Part. 3 SnpEff によるアノテーション",
    "section": "SnpEff の結果 (genes)",
    "text": "SnpEff の結果 (genes)\nSnpEff を実行すると、snpEff_genes.txt というファイルもできる。\nこのファイルには各転写産物ごとに、どの程度の影響の変異がいくつあるかがタブ区切りで整理されている。\nアミノ酸を変える変異をともなう遺伝子を抜き出してみる:\ncat snpEff_genes.txt | awk 'NR&gt;1 { if ($11 &gt;= 1) { print $0 } }'\n🔰 元論文 Barrick et al. 2009 の Table. 1 と比べてみよう。"
  },
  {
    "objectID": "slides/snp24/03_snpeff.html#ニワトリで-snpeff-を動かす場合",
    "href": "slides/snp24/03_snpeff.html#ニワトリで-snpeff-を動かす場合",
    "title": "Part. 3 SnpEff によるアノテーション",
    "section": "ニワトリで SnpEff を動かす場合",
    "text": "ニワトリで SnpEff を動かす場合\n生物種/ゲノムのバージョンによってはデータベースがない場合もある:\nsnpEff databases | grep Gallus\n# GRCg6a.99  Gallus_gallus\n# Galgal4.75  Gallus_gallus\nニワトリも GRCg7b を使う場合、データベースを自作する必要がある:\n\nやり方\n\nhttps://pcingola.github.io/SnpEff/snpeff/build_db/\n\n\nhttps://ymat2.github.io/bio/snpEff.html"
  },
  {
    "objectID": "slides/snp24/03_snpeff.html#part.-3-まとめ",
    "href": "slides/snp24/03_snpeff.html#part.-3-まとめ",
    "title": "Part. 3 SnpEff によるアノテーション",
    "section": "Part. 3 まとめ",
    "text": "Part. 3 まとめ\n達成🎉\n\nSnpEff を使って SNP のアノテーションができるようになった。\n\n\n参考\n\nSnpEff 公式サイト"
  },
  {
    "objectID": "slides/snp24/03_snpeff.html#今日のまとめ",
    "href": "slides/snp24/03_snpeff.html#今日のまとめ",
    "title": "Part. 3 SnpEff によるアノテーション",
    "section": "今日のまとめ",
    "text": "今日のまとめ\n達成🎉\n\n公開データを用いた SNP 解析ができるようになった。\nデータの中身と解析の流れについて理解が深まった。\n\n\nできるようになったこと\n\n基本的なコマンドライン操作\nNGS 公開データの取得\nクオリティコントロール\nリードマッピング\nバリアントコール\nSNP アノテーション\n\n\n\nTop へ戻る"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#今日の目標と実施内容",
    "href": "slides/snp24/01_basic-prefetch-qc.html#今日の目標と実施内容",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "今日の目標と実施内容",
    "text": "今日の目標と実施内容\n目標\n\n公開データを用いた SNP 解析ができるようになる。\nデータの中身と解析の流れについて理解を深める。\n\n\nコンテンツ\n\n基本的なコマンドライン操作\nNGS 公開データの取得\nクオリティコントロール\nリードマッピング\nバリアントコール\nSNP アノテーション"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#part.-1-コマンドライン操作データ取得qc",
    "href": "slides/snp24/01_basic-prefetch-qc.html#part.-1-コマンドライン操作データ取得qc",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "Part. 1 コマンドライン操作、データ取得、QC",
    "text": "Part. 1 コマンドライン操作、データ取得、QC\n目標\n\n公開データを用いた SNP 解析ができるようになる。\nデータの中身と解析の流れについて理解を深める。\n\n\nコンテンツ\n\n基本的なコマンドライン操作\nNGS 公開データの取得\nクオリティコントロール\nリードマッピング\nバリアントコール\nSNP アノテーション"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#基本的なコマンドライン操作①",
    "href": "slides/snp24/01_basic-prefetch-qc.html#基本的なコマンドライン操作①",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "基本的なコマンドライン操作①",
    "text": "基本的なコマンドライン操作①\n\ncd (change directory)\n\nディレクトリ📁を移る\n\nmkdir (make directory)\n\n新しいディレクトリを作成する\n\nls (list segments)\n\nディレクトリ内のファイル、ディレクトリを表示する\n\nmv (move)\n\nファイル、ディレクトリを移動する/名前を変更する\n\nrm (remove)\n\nファイル、ディレクトリを削除する"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#基本的なコマンドライン操作②",
    "href": "slides/snp24/01_basic-prefetch-qc.html#基本的なコマンドライン操作②",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "基本的なコマンドライン操作②",
    "text": "基本的なコマンドライン操作②\n\npwd\n\n今いるディレクトリのフルパスを表示する\n\n&gt; (リダイレクト)\n\nコマンドの結果をターミナルに表示する代わりに、ファイルに書き込む\n\nhead -n N\n\nファイルの先頭 N 行を表示する (デフォルトは10行)\n\ntail -n N\n\nファイルの末尾 N 行を表示する (デフォルトは10行)\n\nless\n\nファイルを閲覧モードで開く。Q で閉じる。"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#基本的なコマンドライン操作の練習",
    "href": "slides/snp24/01_basic-prefetch-qc.html#基本的なコマンドライン操作の練習",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "基本的なコマンドライン操作の練習🔰",
    "text": "基本的なコマンドライン操作の練習🔰\n\n遺伝研スパコンにログインし、今日の実習用のディレクトリ snp24 を作成する。\nsnp24 内に移動し、今いるディレクトリのフルパスをターミナルに出力する。\n今いるディレクトリのフルパスを、ファイル fullpath.txt に書き込む。\nfullpath.txt のファイル名を、pwd.txt に書き換える。\npwd.txt の中身を確認する。\npwd.txt を削除する。"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#解答例",
    "href": "slides/snp24/01_basic-prefetch-qc.html#解答例",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "解答例",
    "text": "解答例\n\nmkdir snp24\ncd snp24 して pwd\npwd &gt; fullpath.txt\nmv fullpath.txt pwd.txt\nhead pwd.txt とか、less pwd.txt とか。\nrm pwd.txt\n\n\n今日のハンズオンはすべて snp24 ディレクトリの中で行います。\nハンズオン終了後は、ディレクトリごと消してもらって構いません:\ncd ..        # snp24 のひとつ上のディレクトリへ移動\nrm -r snp24  # snp24 のディレクトリごと削除"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#snp-解析の流れ",
    "href": "slides/snp24/01_basic-prefetch-qc.html#snp-解析の流れ",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "SNP 解析の流れ",
    "text": "SNP 解析の流れ\n\n\n\n\n\n\n\nflowchart TD\n  A(Sample) -.-&gt;|DNA 抽出| B(DNA)\n  B -.-&gt;|NGS| C[Fastq]\n  X[(NCBI)] -.-&gt;|prefetch| C\n  C -.-&gt;|リードマッピング| D[SAM/BAM]\n  D -.-&gt;|バリアントコール| E[VCF/BCF]\n\n\n\n\n\n\n\n\nリードマッピング\n\nリードを参照配列の相同な位置に貼り付ける\n\n\n\n\nバリアントコール\n\n参照配列と異なる配列を特定する"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#今日使うデータの説明",
    "href": "slides/snp24/01_basic-prefetch-qc.html#今日使うデータの説明",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "今日使うデータの説明",
    "text": "今日使うデータの説明\n\n大腸菌 Escherichia coli (E. coli)\n\nゲノムサイズが約 4.6Mb と小さい (ニワトリで約 1Gb)\n参照配列: B str. REL606 (Ensembl47)\nSRA ショートリード: SRR030257\n\n\nなんのデータ？\n\n高温条件下での進化実験 20,000世代 (Barrick et al. 2009)\n\n問い\n\n高温条件で進化させるとどんな遺伝子に変異が入るのか？"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#今日使うソフトウェア一覧",
    "href": "slides/snp24/01_basic-prefetch-qc.html#今日使うソフトウェア一覧",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "今日使うソフトウェア一覧",
    "text": "今日使うソフトウェア一覧\n\n公開データの取得\n\nSRA Toolkit\n\nクオリティコントロール (QC)\n\nfastp\n\nリードマッピング\n\nBWA\n\nバリアントコール\n\nSAMtools\nBCFtools\n\nSNP アノテーション\n\nSnpEff"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#公開データの取得",
    "href": "slides/snp24/01_basic-prefetch-qc.html#公開データの取得",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "公開データの取得",
    "text": "公開データの取得\n研究で読まれた配列データは NCBI などのデータベースにアーカイブされ、だれでも利用できる。\n\n\n\n\n\nflowchart LR\n  A(Sample) -.-&gt;|DNA/RNA 抽出| B(DNA/RNA)\n  B -.-&gt;|アーカイブ| C[(NCBI)]\n\n\n\n\n\n\n  \nどうやって探すか:\n\nNCBI で検索する\n論文の Data availability などから BioProject ID を探す (例: Bendesky et al. 2024)"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#今回使うデータをみてみる",
    "href": "slides/snp24/01_basic-prefetch-qc.html#今回使うデータをみてみる",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "今回使うデータをみてみる",
    "text": "今回使うデータをみてみる\n\nNCBI にアクセスして、 SRR030257 を検索\nGenomes タブの SRA をクリック\n\n\n\n ← ダウンロードにはこの Run ID が必要"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#sra-toolkit-を使って配列をダウンロードする",
    "href": "slides/snp24/01_basic-prefetch-qc.html#sra-toolkit-を使って配列をダウンロードする",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "SRA Toolkit を使って配列をダウンロードする",
    "text": "SRA Toolkit を使って配列をダウンロードする\n https://github.com/ncbi/sra-tools/wiki/08.-prefetch-and-fasterq-dump \nprefetch SRR030257\nfasterq-dump SRR030257/SRR030257.sra\n\nprefetch\n\nSRA アクセッションをダウンロードする\n\nfasterq-dump\n\nSRA アクセッションから Fastq ファイルを取り出す\n\n\n\nls して2つの .fastq ファイルができていたら成功:\nls\n# SRR030257  SRR030257_1.fastq  SRR030257_2.fastq"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#fastq-ファイルの中身を見てみる",
    "href": "slides/snp24/01_basic-prefetch-qc.html#fastq-ファイルの中身を見てみる",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "Fastq ファイルの中身を見てみる",
    "text": "Fastq ファイルの中身を見てみる\nhead SRR030257_1.fastq  # 先頭行を表示\n4行でひとまとまり (1リード) のデータ:\n@SRR030257.1 HWI-EAS_4_PE-FC20GCB:6:1:385:567 length=36  # @リードの情報\nTTACACTCCTGTTAATCCATACAGCAACAGTATTGG                     # 配列\n+SRR030257.1 HWI-EAS_4_PE-FC20GCB:6:1:385:567 length=36  # +\nAAA;A;AA?A?AAAAA?;?A?1A;;????566)=*1                     # クオリティ値"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#クオリティ値",
    "href": "slides/snp24/01_basic-prefetch-qc.html#クオリティ値",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "クオリティ値",
    "text": "クオリティ値\nFastq の4行目は、各塩基のクオリティ値が記号で記されている。\n記号と数字の対応は以下の通り (ASCII コード):\n Quality encoding: !\"#$%&'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHI\n                   |         |         |         |         |\n    Quality score: 0........10........20........30........40\n\nこれらの数字 (Q値) は Log スケールであり、ある塩基が間違って読まれている確率を \\(P\\) として、\n\\[\nQ = -10 \\times \\log_{10}{P}\n\\]\nで計算される。 例えば ? なら \\(Q=30\\) で、間違って読まれている確率は \\(P=0.001\\)。"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#ngs-配列のクオリティコントロール",
    "href": "slides/snp24/01_basic-prefetch-qc.html#ngs-配列のクオリティコントロール",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "NGS 配列のクオリティコントロール",
    "text": "NGS 配列のクオリティコントロール\n\n低品質な (Q値の低い) 塩基\nアダプタ配列の混入\nPCR duplicates\n他サンプルのコンタミネーション\nなど\n\n  \n偽陽性バリアントの増加"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#クオリティコントロールのツール",
    "href": "slides/snp24/01_basic-prefetch-qc.html#クオリティコントロールのツール",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "クオリティコントロールのツール",
    "text": "クオリティコントロールのツール\n\n\n\n\n\n\n\n\n\n\n\n\n\nTool name\nlanguage\ninput\nQC\nQF\nAd\ncont\nPE\n\n\n\n\nFastqPuri\nC, R\nfq\n〇\n〇\n〇\n〇\n〇\n\n\nfastp\nC++\nfq, gz\n〇\n〇\n〇\nx\n〇\n\n\nFastq Screen\nperl\nfq\nx\nx\nx\n〇\nx\n\n\ntrimmomatic\njava\nfq, gz\nx\n〇\n〇\nx\n〇\n\n\nFastQC\njava\nfq, gz\n〇\nx\nx\nx\nx\n\n\nRSeQC\nC, Python\nBAM/SAM\n〇\nx\nx\nx\nx\n\n\n\n Pérez-Rubio et al. 2019 Table. 1 より抜粋 \n QC: Quality Control QF: Quality Filtering Ad: アダプタ配列除去 cont: コンタミ除去 PE: Paired-end 対応 \n今回のハンズオンでは、C++ 製で高速、 圧縮ファイル (gz) にも対応した fastp を使う。"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#fastp-によるクオリティコントロール",
    "href": "slides/snp24/01_basic-prefetch-qc.html#fastp-によるクオリティコントロール",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "fastp によるクオリティコントロール",
    "text": "fastp によるクオリティコントロール\nfastp -i SRR030257_1.fastq -I SRR030257_2.fastq \\\n  -o qc_SRR030257_1.fq.gz -O qc_SRR030257_2.fq.gz \\\n  -q 20 -u 40 -h SRR030257.qc.html\n\n-i, -I\n\n入力 Fastq ファイル。Single-end の場合 -i のみ。\n\n-o, -O\n\n出力 Fastq ファイル。Single-end の場合 -o のみ。\n\n\n.gz をつければそのまま圧縮可能。\n\n-h\n\nレポートファイル (.html) の出力先"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#fastp-によるクオリティコントロール-1",
    "href": "slides/snp24/01_basic-prefetch-qc.html#fastp-によるクオリティコントロール-1",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "fastp によるクオリティコントロール",
    "text": "fastp によるクオリティコントロール\nfastp -i SRR030257_1.fastq -I SRR030257_2.fastq \\\n  -o qc_SRR030257_1.fq.gz -O qc_SRR030257_2.fq.gz \\\n  -q 20 -u 40 -h SRR030257.qc.html\n\n-q\n\nクオリティ値の下限 (デフォルトは15)\n\n-u\n\n基準を下回る塩基が何%以上含まれているリードを除くか (デフォルトは40)\n\n\n今回の場合、\\(Q&lt;20\\) の塩基が40%以上含まれれるリードを除去。"
  },
  {
    "objectID": "slides/snp24/01_basic-prefetch-qc.html#part.-1-まとめ",
    "href": "slides/snp24/01_basic-prefetch-qc.html#part.-1-まとめ",
    "title": "全ゲノム解析ハンズオン 2024 新村グループ",
    "section": "Part. 1 まとめ",
    "text": "Part. 1 まとめ\n達成🎉\n\n基本的なコマンドライン操作を身に付けた。\nNGS の公開データの探し方、使い方を理解した。\nクオリティコントロールの内容と方法を理解した。\n\n\n参考\n\nThe Linux command line for beginners\nSRA Toolkit Wiki\nFastp README\n\n\n\n\nPart. 2 へ"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#全体の流れ",
    "href": "slides/lt/tuat2024pipeline.html#全体の流れ",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "全体の流れ",
    "text": "全体の流れ\n\n遺伝研ジョブスクリプトについて\nプロトコルをざっくり説明:\n\ng1_quality_control.sh\ng2_read_mapping.sh\ng3_snp_calling.sh\ng4_merge.sh\ng5_ld_prune.sh\ng6_pca.sh\ng7_fst.sh\n\nプロトコル: 農工大ラボ/行動グループ/実験プロトコール/全ゲノム解析/\n\\(F_\\text{st}\\) 解析ハンズオン"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#遺伝研ジョブスクリプトの概要",
    "href": "slides/lt/tuat2024pipeline.html#遺伝研ジョブスクリプトの概要",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "遺伝研ジョブスクリプトの概要",
    "text": "遺伝研ジョブスクリプトの概要\n\nhttps://sc.ddbj.nig.ac.jp/software/grid_engine/\n遺伝研スパコンの使い方\n\n大量のデータを扱い、 大規模なメモリ・計算能力を要する解析は手持ちの PC では困難\n  \n複数の高性能な計算機 (スパコン) に適切にリソースを割り振って、 効率的に解析を進める。\n  \n「なんの解析を、どういうリソースでやるか」を書いてコンピュータに渡す。 (ジョブスクリプト)\n\n書き方はいろいろ。 今日は遺伝研スパコンの場合。"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#遺伝研スパコンの基本的な使い方",
    "href": "slides/lt/tuat2024pipeline.html#遺伝研スパコンの基本的な使い方",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "遺伝研スパコンの基本的な使い方",
    "text": "遺伝研スパコンの基本的な使い方\n\nアカウントを発行\nゲートウェイノード (共通) へ ssh 接続 ! 全ユーザが共有する場所なので、ここで作業をしない。\nログインノード (個別) へ移動\nジョブスクリプト (.sh) を書いてジョブを投入 (qsub)"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#ジョブスクリプトの書き方",
    "href": "slides/lt/tuat2024pipeline.html#ジョブスクリプトの書き方",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "ジョブスクリプトの書き方",
    "text": "ジョブスクリプトの書き方\n\n言語は Bash (.sh) (Python でも書ける。)\nジョブスケジューラは Altair Grid Engine(AGE)\n\nまず Bash の記法について説明した後、 AGE 特有の書き方について説明します。\n\n\n\nBash\n\n変数\n\n\n配列\n\n\nFor ループ\n\n\nパイプ |、リダイレクト &gt;\n\n\nエイリアス\n\n\n\n\nAGE\n\n引数 (#$)\n\n\nApptainer (旧 Singularity)\n\n\nアレイジョブ"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#bash-変数配列for-ループ",
    "href": "slides/lt/tuat2024pipeline.html#bash-変数配列for-ループ",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "Bash: 変数、配列、For ループ",
    "text": "Bash: 変数、配列、For ループ\n\n\nsample.sh\n\n#! /bin/Bash\n\nmyfile=sample.vcf           # 変数 myfile に sample.vcf を代入\necho ${myfile}              # echo コマンドで変数の中身を表示\n\nsamples=(uwa hiku WL RIR)   # 4品種を格納する配列 samples\necho ${samples[2]}          # 何番目かで指定。Bash では0始まり\n\nfor x in ${samples[@]}; do  # 配列の中身を1つずつループ\n  touch ${x}.vcf            # touch コマンドでファイルを新規作成\ndone\n\n遺伝研スパコン上で実行してみる:\nbash sample.sh"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#bash-リダイレクト",
    "href": "slides/lt/tuat2024pipeline.html#bash-リダイレクト",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "Bash: リダイレクト >",
    "text": "Bash: リダイレクト &gt;\n\nリダイレクト &gt;\n\nあるコマンドの実行結果を、リダイレクト先のファイルに書き込む。\n\n\n1個 &gt; だと上書き、2個 &gt;&gt; だと追加\n\n\n例:\nls                    # カレントディレクトリのファイルを眺める\nls &gt; ls-result.txt    # ls の結果をファイルに保存\nless ls-result.txt    # ファイルの中身を見てみる\n\npwd                   # カレントディレクトリの PATH を表示\npwd &gt;&gt; ls-result.txt  # ped の結果をファイルに追加\ncat ls-result.txt     # ファイルの中身を見てみる"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#bash-パイプ",
    "href": "slides/lt/tuat2024pipeline.html#bash-パイプ",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "Bash: パイプ |",
    "text": "Bash: パイプ |\n\nパイプ演算子 |\n\nあるコマンドの実行結果を、次のコマンドの引数にする。\n\n\n例:\n## コマンド毎に中間ファイルを作るのは冗長\n$ ls &gt; ls-result.txt         # コマンドの実行結果をファイルに保存して、\n$ grep \"hiku\" ls-result.txt  # そのファイルを引数に指定して...\nhiku.vcf\n\n## パイプで直接流し込む\nls | grep \"hiku\"\nhiku.vcf"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#bash-エイリアス-alias",
    "href": "slides/lt/tuat2024pipeline.html#bash-エイリアス-alias",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "Bash: エイリアス alias",
    "text": "Bash: エイリアス alias\n\nエイリアス alias\n\n長いコマンドの繰り返しを避けるために、 ショートカットコマンドを定義する。\n\n\n例:\nls -a -l             # 隠しファイルを含むすべてのファイルの情報を表示\n                     # 毎回打つのはめんどくさい。。。\n\nalias ls=\"ls -a -l\"  # エイリアスを設定\nls                   # 同じ結果に"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#age-引数",
    "href": "slides/lt/tuat2024pipeline.html#age-引数",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "AGE: 引数",
    "text": "AGE: 引数\n\n\nsample.sh\n\n#!/bin/bash\n\n#$ -S /bin/bash      # インタープリタの指定\n#$ -cwd              # ジョブを実行する場所をカレントディレクトリに\n#$ -V                # ジョブ実行時の環境変数をすべてジョブに受け継ぐ\n#$ -l short          # 計算機の種類の指定 (short, intel, gpu, epyc, medium)\n#$ -l d_rt=00:10:00  # 実行上限時間の指定\n#$ -l s_rt=00:10:00  # 同じ\n#$ -l s_vmem=4G      # メモリ量の指定\n#$ -l mem_req=4G     # 同じ\n#$ -o stdout.txt     # 標準出力のファイル名\n#$ -e stderr.txt     # エラー出力のファイル名\n\necho Hello"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#age-apptainer-旧-singularity",
    "href": "slides/lt/tuat2024pipeline.html#age-apptainer-旧-singularity",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "AGE: Apptainer (旧 Singularity)",
    "text": "AGE: Apptainer (旧 Singularity)\n\nApptainer\n\nよく使われるバイオインフォマティクスの解析環境が用意されている。\n\n\nインストール不要で使える。\n\n\n\n使い方:\n\n/usr/local/biotools/a-z/ から使いたいツールのバージョンを探す。\napptainer exec + バージョンまでのPATH + コマンド\n\nsamtools の場合:\nls /usr/local/biotools/s/samtools*\napptainer exec /usr/local/biotools/s/samtools:1.8--2 samtools --help"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#age-アレイジョブ",
    "href": "slides/lt/tuat2024pipeline.html#age-アレイジョブ",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "AGE: アレイジョブ",
    "text": "AGE: アレイジョブ\n\nアレイジョブ\n\n複数のノードを使って、大量のジョブを同時に捌く。"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#アレイジョブスクリプトの書き方",
    "href": "slides/lt/tuat2024pipeline.html#アレイジョブスクリプトの書き方",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "アレイジョブスクリプトの書き方",
    "text": "アレイジョブスクリプトの書き方\nhttps://sc.ddbj.nig.ac.jp/software/grid_engine/array_jobs\n同じ解析を4サンプルに対して同時に実行する例:\n\n\ntest-array.sh\n\n#!/bin/bash\n\n#$ -S /bin/Bash\n#$ -cwd\n#$ -t 1-4\n#$ -tc 4\n\nsamples=(uwa hiku WL RIR)\nsample=${samples[$SGE_TASK_ID-1]}\n\necho ${sample} is my favorite breed. &gt;&gt; ${sample}.vcf"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#アレイジョブ関連の引数",
    "href": "slides/lt/tuat2024pipeline.html#アレイジョブ関連の引数",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "アレイジョブ関連の引数",
    "text": "アレイジョブ関連の引数\n\n-t 1-4\n\n$SEG_TASK_ID を指定。1,2,3,4 を指定している。\n\n\n3-11:2 (3から11まで1つ飛ばしで) みたいな指定も可能\n\n$SGE_TASK_ID\n\nそのジョブが何個目か、を示す変数。これを使って配列の要素を指定する。\n\n-tc\n\n同時に実行されるジョブ数の上限を指定\n\n\nqquota コマンドで1ユーザが使えるノードの数を確認できる。"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#プロトコルをざっくり説明",
    "href": "slides/lt/tuat2024pipeline.html#プロトコルをざっくり説明",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "プロトコルをざっくり説明:",
    "text": "プロトコルをざっくり説明:\n\ng1_quality_control.sh\ng2_read_mapping.sh\ng3_snp_calling.sh\ng4_merge.sh\ng5_ld_prune.sh\ng6_pca.sh\ng7_fst.sh\n\nプロトコル置き場: 農工大ラボ/行動グループ/実験プロトコール/全ゲノム解析/"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#f_textst-解析ハンズオン-vcf-query",
    "href": "slides/lt/tuat2024pipeline.html#f_textst-解析ハンズオン-vcf-query",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "\\(F_\\text{st}\\) 解析ハンズオン: vcf-query",
    "text": "\\(F_\\text{st}\\) 解析ハンズオン: vcf-query\nvcf-query -l file.vcf.gz\n\n-l\n\nVCF ファイルのサンプルを表示\n\ngrep にパイプしてほしいサンプルのみ抽出\n\n| grep -E 'SM|YKD' &gt; shamo.txt でシャモを抽出\n\n\n| grep -v -E 'SM|YKD' &gt; non-shamo.txt でシャモ以外を抽出"
  },
  {
    "objectID": "slides/lt/tuat2024pipeline.html#f_textst-解析ハンズオン-vcftools",
    "href": "slides/lt/tuat2024pipeline.html#f_textst-解析ハンズオン-vcftools",
    "title": "遺伝研スパコンで集団ゲノミクス解析",
    "section": "\\(F_\\text{st}\\) 解析ハンズオン: vcftools",
    "text": "\\(F_\\text{st}\\) 解析ハンズオン: vcftools\nvcftools --gzvcf file.vcf.gz --weir-fst-pop pop1.txt --weir-fst-pop pop2.txt \\\n  --fst-window-size 10000 --fst-window-step 5000 --out outfile\n\n--gzvcf\n\n圧縮済み VCF ファイル\n\n--weir-fst-pop\n\n\\(F_\\text{ST}\\) を計算したい2集団のサンプルをリストしたテキストファイル\n\n--fst-window-size, --fst-window-step\n\n塩基数で指定\n\n\n\n\n--out\n\n出力ファイルの名前 (.log と .windowed.weir.fst の2ファイル)"
  },
  {
    "objectID": "slides/lt/gnu-nano.html#smallでfriendlyなテキストエディタ-nano",
    "href": "slides/lt/gnu-nano.html#smallでfriendlyなテキストエディタ-nano",
    "title": "GNU nanoエディタを便利に使う",
    "section": "smallでfriendlyなテキストエディタ nano",
    "text": "smallでfriendlyなテキストエディタ nano\nGNUnanoはMacにもLinuxにも元から入っているテキストエディタ。ただしmacOS 12.3 Monterey以降、Macでnanoを打って起動するのはpicoなので、新しいのをhomebrewで入れる。\n\n公式ドキュメント: nano-editor.org/dist/latest/nano.html\nこちらもよろしくお願いします: ymat2.github.io/commandline/nano/\n\n\n新しいバージョンを入れて使うのもよい:\n## Macならhomebrewでインストール\nbrew install nano\n\n## Linux(Ubuntu)ならaptでインストール\nsudo apt install nano"
  },
  {
    "objectID": "slides/lt/gnu-nano.html#基本的な使い方",
    "href": "slides/lt/gnu-nano.html#基本的な使い方",
    "title": "GNU nanoエディタを便利に使う",
    "section": "基本的な使い方",
    "text": "基本的な使い方\nファイル名を指定して開く。ファイルが存在しない場合は新しく作られる。\nnano sample.md\n\nControlX\n\n編集画面から出る。内容を変更している場合は上書きするかどうか聞かれる。\n\nControlO\n\n編集内容を反映。上書き保存のイメージ。\n\nControlK\n\n選択範囲を切り取る。範囲を選択していない場合カーソルのある行が切り取られる。\n\nControlU\n\n切り取った内容をカーソル位置に張り付ける。"
  },
  {
    "objectID": "slides/lt/gnu-nano.html#nanoを便利に使う1-configuration",
    "href": "slides/lt/gnu-nano.html#nanoを便利に使う1-configuration",
    "title": "GNU nanoエディタを便利に使う",
    "section": "nanoを便利に使う1: Configuration",
    "text": "nanoを便利に使う1: Configuration\n~/.bash_profileみたいに、nanoも設定をファイルに書いておくことができる。\n読み込まれる順番は、以下の通り。\n\n/etc/nanorc # システムのデフォルト\n~/.nanorc # これが一番楽\n~/.config/nano/nanorc # 遺伝研のnanoは古すぎてこれは読んでくれない\n\n\nホームに.nanorcを作ってみる:\ncd  # homeディレクトリに移動\nnano .nanorc  # .nanorcをnanoで編集"
  },
  {
    "objectID": "slides/lt/gnu-nano.html#nanoを便利に使う1-configuration-1",
    "href": "slides/lt/gnu-nano.html#nanoを便利に使う1-configuration-1",
    "title": "GNU nanoエディタを便利に使う",
    "section": "nanoを便利に使う1: Configuration",
    "text": "nanoを便利に使う1: Configuration\nset &lt;option&gt;という書き方で設定をどんどん追加していく。\nよく使う & 便利そうな設定を抜粋:\n\n\n.nanorc\n\nset tabsize 4     # Tabでインデントするときの幅をspace4個分に。\nset autoindent    # 改行時にインデントを揃える\nset smooth        # スクロールがスムーズに\nset linenumbers   # 行番号を表示する\nset mouse         # カーソル移動や範囲選択でマウスを使えるように\n\nその他のオプションは公式ドキュメントを参照。"
  },
  {
    "objectID": "slides/lt/gnu-nano.html#nanoを便利に使う2-シンタクスハイライト",
    "href": "slides/lt/gnu-nano.html#nanoを便利に使う2-シンタクスハイライト",
    "title": "GNU nanoエディタを便利に使う",
    "section": "nanoを便利に使う2: シンタクスハイライト",
    "text": "nanoを便利に使う2: シンタクスハイライト\n\nシンタクスハイライトとは\n\n関数、文字列、予約語とかに色をつけてコードを見やすくするあれ。\n\n\n\n\n\n(/etc/nanorcの設定にもよるが、)Macのデフォルトのnanoはハイライトされていない…\nそれも.nanorcで設定できます!!"
  },
  {
    "objectID": "slides/lt/gnu-nano.html#nanoを便利に使う2-シンタクスハイライト-1",
    "href": "slides/lt/gnu-nano.html#nanoを便利に使う2-シンタクスハイライト-1",
    "title": "GNU nanoエディタを便利に使う",
    "section": "nanoを便利に使う2: シンタクスハイライト",
    "text": "nanoを便利に使う2: シンタクスハイライト\n\nハイライト定義ファイルが置かれている場所を探す。\n\nMac(homebrew): /usr/local/share/nano/ / /usr/local/Cellar/nano/%v/share/nano/\nLinux: /usr/share/nano/\n\n.nanorcに以下を追記:\n\n\n.nanorc\n\ninclude \"/usr/share/nano/*.nanorc\"\n\n適当なスクリプトをnanoで開いて、ハイライトされているか見てみる。"
  },
  {
    "objectID": "slides/lt/gnu-nano.html#みなさんのおすすめエディタも教えてください",
    "href": "slides/lt/gnu-nano.html#みなさんのおすすめエディタも教えてください",
    "title": "GNU nanoエディタを便利に使う",
    "section": "みなさんのおすすめエディタも教えてください!!",
    "text": "みなさんのおすすめエディタも教えてください!!\n\n私はnanoの設定こうしています！\nvimの方がはるかに高機能だというのを教えてあげよう\n何言ってんの、時代はvscodeでしょ\n\n個人的にvscodeを食わず嫌いしているのでぜひ誰かにやってほしい…\n\netc.\n\n\n\n技術輪読会のネタについて\n皆さんの意向をお聞きした上で、希望者が多ければgitを学ぶ回をやりたい。"
  },
  {
    "objectID": "slides/lt/gnu-nano.html#補遺-遺伝研でnanoを使うとき",
    "href": "slides/lt/gnu-nano.html#補遺-遺伝研でnanoを使うとき",
    "title": "GNU nanoエディタを便利に使う",
    "section": "補遺: 遺伝研でnanoを使うとき",
    "text": "補遺: 遺伝研でnanoを使うとき\n遺伝研のデフォルトのnanoは、version 2.3.1とかなり古い。(2023-05-09)\n\nキーバインドが結構違う。(ControlXとか基本的なやつは同じ。)\n~/.config/nano/nanorcを読んでくれない。\n.nanorcのワイルドカード*が効かない。\n\n\nデフォルトのnanoを使う場合、\n\n設定ファイルは~/.nanorc\n\n\nキーバインドは自分で設定したり、野生のやつを借りたり。\n\n\nシンタックスハイライトは1つ1つ直接指定: include \"usr/share/nano/python.nanorc\"\n\nおすすめは新しいnanoを入れること\n\nguixならversion 5.6.1が入る。(これもそこそこ古いけど。)\n\n\n*.nanorcもついてくる。(~/.guix-profile/share/nano/*.nanorc)\n\n\n公式から最新版(version 7.2)を落としてきてもいいかも。"
  },
  {
    "objectID": "slides/index.html",
    "href": "slides/index.html",
    "title": "Slides",
    "section": "",
    "text": "2024-11-29 全ゲノム解析 ハンズオン — スモールデータで理解する SNP 解析の流れ\n2024-04-03 新村グループ プロトコル共有 — 遺伝研スパコンで集団ゲノミクス解析\nRで系統樹を扱う — ggtreeによる系統樹の可視化\nWEBサイト作成のための基礎知識 — HTML, CSS, JavaScript, 静的サイトジェネレータ\nGit 基本操作① — GitとGitHubを使い始める\nGit 基本操作② — fetch, merge, pull\n2023-05-09 牧野研 技術輪読会 — GNU nanoエディタを便利に使う",
    "crumbs": [
      "スライド"
    ]
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#今日やること",
    "href": "slides/git-circle/git-vol1.html#今日やること",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "今日やること",
    "text": "今日やること\n\nGit と GitHub とは何か、なぜ必要かを知る\nGit と GitHub を使い始める\nGit の基本操作をやってみる\n\n\n参考\n\n過去の牧野研での git 講習資料\n\n\ngit 公式リファレンス\n\n\nkaito256さん: Github演習"
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#こんなことありませんか",
    "href": "slides/git-circle/git-vol1.html#こんなことありませんか",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "こんなことありませんか？",
    "text": "こんなことありませんか？\n論文を書いて、先生に見せて、修正して、、、\nどれが最新だっけ？\n~$ ls thesis/\n卒論.docx\n卒論_ver2.docx\n卒論_TM_review.docx\n卒論_TM_review.docxのコピー\n卒論_最新.docx\n卒論_最新_TM_review.docx\n20220301_卒論_最終版.docx\n卒論_提出版.docx\n卒論_提出版_こっち.docx"
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#こんなことありませんか-1",
    "href": "slides/git-circle/git-vol1.html#こんなことありませんか-1",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "こんなことありませんか？",
    "text": "こんなことありませんか？\nOneDrive, Google Drive等を活用したバックアップは大切。でも、、、\n\n\n\n\nenrichment.R にバグを発見！！\n何日か前までは大丈夫だったはずだけどどこまで戻ればいいんだ？？\n\n\n\n常に最新版のファイルだけ取っておいて、\nいつでも過去のバージョンに戻れる、\nしかもどのマシンにも共有できる、\n\nという状態が好ましい。"
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#だから私は-gitgithub",
    "href": "slides/git-circle/git-vol1.html#だから私は-gitgithub",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "だから私は Git/GitHub",
    "text": "だから私は Git/GitHub\n\nGit \n\n分散型バージョン管理システム\n\n\nあるファイルを、誰が、いつ、どこを修正したかの履歴を 自分のタイミングで保存\n\n\n手元には最新のファイルのみが残り、いつでも過去のバージョンに戻れる\n\nGitHub \n\nGitで管理しているファイルのホスティングサービス\n\n\nGitを使う上で便利な機能が盛りだくさん\n\n\nまさにHubとして、複数人や複数マシンで同じファイルを共有できる\n\n\n類似サービスにはGitLab など"
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#install-git",
    "href": "slides/git-circle/git-vol1.html#install-git",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "Install git",
    "text": "Install git\nversion 2 以降の git が入っているかどうか確認:\ngit --version\n# git version 2.42.1\n\n入っていなければ:\n\nMac: brew install git\nLinux (Ubuntu): sudo apt update && sudo apt install git\nWindows: WSL2を設定する。 あとはLinuxとおなじ。"
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#初期設定",
    "href": "slides/git-circle/git-vol1.html#初期設定",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "初期設定",
    "text": "初期設定\n\nGitHub に個人アカウントを作る。\n\nユーザー名 (他のユーザーと被らないもの)\nメールアドレス\nパスワード\n\nGit の初期設定をターミナルから行う:\ngit --version        # 2.0以上であることを確認\ngit config --global user.name \"Yuki Matsuda\"\ngit config --global user.email \"your-email@dc.tohoku.ac.jp\"\ngit config --global push.default simple\ncat ~/.gitconfig     # 反映されているか確認\n# [user]\n#   name = Yuki Matsuda\n#   email = your-email@dc.tohoku.ac.jp\n# [push]\n#   default = simple"
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#ssh-任意",
    "href": "slides/git-circle/git-vol1.html#ssh-任意",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "SSH (任意)",
    "text": "SSH (任意)\n\nGitHubとの通信に2つの方式がある。\n\nHTTPS: 設定不要で高速だが、操作によってパスワード入力が必要\nSSH: 一旦ちゃんと設定すればパスワードなしで快適\n\nダウンロード操作(clone/fetch/pull)は高速なHTTPSで、 アップロード操作(push)はパスワード無しのSSHで、というのが楽ちん。\nSSH公開鍵を作って ローカルマシンとGitHubに登録する。\n設定ファイル ~/.gitconfig に pushinsteadof の設定を追加:\n[url \"git@github.com:\"]\n  pushinsteadof = https://github.com/\nMacの場合、keyhcainを使ってPassword入力をスキップする:\ngit config --global credential.helper osxkeychain\nWindowsの場合、SSH鍵作成の際にPassword入力をスキップするのがよい？"
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#休憩-質問タイム",
    "href": "slides/git-circle/git-vol1.html#休憩-質問タイム",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "休憩 & 質問タイム ☕",
    "text": "休憩 & 質問タイム ☕\n\nGit と GitHub  とは何か、なぜ必要かを知る\nGit と GitHub を使い始める\nGit の基本操作をやってみる"
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#手元のプロジェクトをgitで管理する",
    "href": "slides/git-circle/git-vol1.html#手元のプロジェクトをgitで管理する",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "手元のプロジェクトをGitで管理する",
    "text": "手元のプロジェクトをGitで管理する\n\n適当なディレクトリを作ってテキストファイル README.md を新規作成する:\nmkdir new_project && cd new_project\necho Hello, world! &gt; README.md\nローカルリポジトリをつくる:\ngit init\nローカルリポジトリに README.md をコミットする。\n最初は git status や git log で頻繁に確認すると安心。\ngit status\ngit add README.md  # README.mdをindexに登録\ngit status\ngit commit -m \"Create README.md\" # コミットメッセージを添えてコミット\ngit status\ngit log"
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#手元のプロジェクトをgithubでも管理する",
    "href": "slides/git-circle/git-vol1.html#手元のプロジェクトをgithubでも管理する",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "手元のプロジェクトをGithubでも管理する",
    "text": "手元のプロジェクトをGithubでも管理する\n\nGitHubアカウントページの右上の “+” から “New repository” を選択する。\n適当なリポジトリ名（基本は手元と同じ）をつけて “Create repository” を押す。\n手順が表示されるので基本的にそれに従う:\ngit remote add origin https://github.com/USER_NAME/new_project.git  # リモートリポジトリを紐づける\ngit remote -v               # ちゃんと紐づいたか確認\n# git branch -M main        # ブランチの名前をmainに\ngit push -u origin main     # リモートにpush\ngit status\n “Private” リポジトリの場合、SSHで紐付けしないと下り( fetch, pull )でもパスワードを聞かれる。\nリポジトリのページを更新して README.md が見えるか確認する。"
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#すでにあるリポジトリを手元に落としてくる",
    "href": "slides/git-circle/git-vol1.html#すでにあるリポジトリを手元に落としてくる",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "すでにあるリポジトリを手元に落としてくる",
    "text": "すでにあるリポジトリを手元に落としてくる\n\nGitHub上の適当なリポジトリをひとつ選ぶ。 (e.g., https://github.com/ymat2/practice_git)\n右の方の &lt;&gt;Code▼ ボタンを押す。\nSSHではなくHTTPSを選択し、URLをコピー。\ngit clone https://github.com/ymat2/practice-git.git\n中身を眺めてみる:\ncd practice-git\nls -al\ngit log\n\n\n\nclone はどんな時に使う?\n\n他人の作ったソフトウェアをインストールして使うとき\n\n\n新しいPCで最初に作業を始めるとき\n\n\netc."
  },
  {
    "objectID": "slides/git-circle/git-vol1.html#前半おわり",
    "href": "slides/git-circle/git-vol1.html#前半おわり",
    "title": "Git 基本操作① — GitとGitHubを使い始める",
    "section": "前半、おわり",
    "text": "前半、おわり\n\nGit と GitHub  とは何か、なぜ必要かを知る\nGit と GitHub を使い始める\nGit の基本操作をやってみる\n\n\n後半スライドへ"
  },
  {
    "objectID": "python/package.html",
    "href": "python/package.html",
    "title": "Python パッケージ作成",
    "section": "",
    "text": "参考:\n特に:",
    "crumbs": [
      "Python",
      "Python パッケージ作成"
    ]
  },
  {
    "objectID": "python/package.html#pyproject.toml-を使う方法",
    "href": "python/package.html#pyproject.toml-を使う方法",
    "title": "Python パッケージ作成",
    "section": "pyproject.toml を使う方法",
    "text": "pyproject.toml を使う方法\nファイル構成:\nbithon/\n├── LICENSE\n├── README.md\n├── pyproject.toml\n├── src/bithon/\n│   ├── __init__.py\n│   └── bithon.py\n└── tests/\n\npyproject.toml の書き方\n[build-system] では、どのビルドツールを使ってパッケージを作るかを指定する。 書き方はツールごとに決まっている。\n例えば Hatchling の場合:\n\n\npyproject.toml\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[project] では、パッケージのメタ情報を記載する:\n\n\npyproject.toml\n\n[project]\nname = \"bithon\"\nversion = \"0.0.1\"\nauthors = [\n  { name=\"ymat2\", email=\"yuki.matsuda.r7@dc.tohoku.ac.jp\" },\n]\ndescription = \"Personal python package for bioinformatics\"\nreadme = \"README.md\"\nlicense = {file = \"LICENSE\"}\nrequires-python = \"&gt;=3.8\"\ndependencies = []\n\n[project.urls]\nHomepage = \"https://ymat2.github.io\"\nRepository = \"https://github.com/ymat2/bithon\"\n\n\nname\n\nPyPI 既存のものと被ってはいけないらしいが、git から利用する分には OK？\n\nversion\n\nコードを更新した時は番号を変えないと pip install --upgrade で更新されない。\n\ndependencies\n\nリスト形式で依存パッケージを記載する。",
    "crumbs": [
      "Python",
      "Python パッケージ作成"
    ]
  },
  {
    "objectID": "python/package.html#setup.py-を使う方法",
    "href": "python/package.html#setup.py-を使う方法",
    "title": "Python パッケージ作成",
    "section": "setup.py を使う方法",
    "text": "setup.py を使う方法\n\nsetuptools に依存する setup.py を使う方法は現在は非推奨 (Legacy) らしい。 pyproject.toml で一元管理する方法が主流で、Poetry など パッケージ作成をラクに行えるツールがあるっぽい。\n\nファイル構成:\nmython/\n├── LICENSE\n├── README.md\n├── setup.py\n├── mython/\n│   ├── __init__.py\n│   └── mython  # 拡張子なしでもいい\n└── tests/\n\n\nsetup.py\n\nfrom setuptools import setup\n\nsetup(\n  name = \"mython\",\n  version = \"0.1.0\",\n  python_requires = \"&gt;=3.6\",\n  scripts = [\"mython/mython\",]\n)\n\n\nサブディレクトリありの場合\nmython/\n├── LICENSE\n├── README.md\n├── setup.py\n├── mython/\n│   ├── __init__.py\n│   ├── mython\n│   └── util/\n│       ├── __init__.py\n│       ├── bye.py\n│       └── hello.py\n└── tests/\n\nutil/__init__.py\n\nfrom mython.util import * のような形で非明示的に全部読み込むには、 どのスクリプトを含めるかを書いておかないといけない。\n\n\n  __all__ = [\"hello\", \"bye\"]",
    "crumbs": [
      "Python",
      "Python パッケージ作成"
    ]
  },
  {
    "objectID": "python/class.html",
    "href": "python/class.html",
    "title": "オブジェクト指向とクラス",
    "section": "",
    "text": "https://docs.python.org/3/tutorial/classes.html",
    "crumbs": [
      "Python",
      "オブジェクト指向とクラス"
    ]
  },
  {
    "objectID": "python/class.html#オブジェクト指向とは",
    "href": "python/class.html#オブジェクト指向とは",
    "title": "オブジェクト指向とクラス",
    "section": "オブジェクト指向とは",
    "text": "オブジェクト指向とは\nオブジェクト指向とはプログラミングやソフトウェア開発における考え方の1つで、 データとその処理の仕方をひとまとまりのモノ (オブジェクト) として扱う方法をいう。\n例えば RPG などにおける「勇者」というオブジェクトには、 「HP」や「MP」といったデータ (属性という) と、 「攻撃する」や「回復する」といったデータの処理 (メソッドという) がひとまとまりとなっている。 同様に「魔法使い」や「魔王」などのオブジェクトにも属性とメソッドがあり、 これらオブジェクトを基準にプログラムを組み立てていく。",
    "crumbs": [
      "Python",
      "オブジェクト指向とクラス"
    ]
  },
  {
    "objectID": "python/class.html#python-におけるオブジェクト指向プログラミング",
    "href": "python/class.html#python-におけるオブジェクト指向プログラミング",
    "title": "オブジェクト指向とクラス",
    "section": "Python におけるオブジェクト指向プログラミング",
    "text": "Python におけるオブジェクト指向プログラミング\nPython においては、データと、 その処理の仕方 (メソッド) をまとめて記述したもの (オブジェクト) を格納しておく雛形が class である。\nRPG の勇者を例に、シンプルな class を定義してみる。\nこの勇者には「atk: 攻撃力」と「hp: 体力」という属性があり、 「powerup: 攻撃力を上げる」と「recover: 回復する」 という処理があるものとする。\n# シンプルな class の例\nclass RpgHero:\n\n  atk = 50 # 攻撃力\n  hp = 100   # 体力\n\n  def powerup(self, i):\n    self.atk = self.atk + i\n\n  def recover(self, j):\n    self.hp = self.hp + j\n\n\n# 作成したクラスを使うためにインスタンス化:\nyoshihiko = RpgHero()\n\n# 最初の状態をprint:\nprint(\"ATK:\", yoshihiko.atk)\nprint(\"HP:\", yoshihiko.hp)\n# &gt;&gt;&gt; ATK: 50\n# &gt;&gt;&gt; HP: 100\n\n# メソッドを呼び出す:\nyoshihiko.powerup(10)   # 攻撃力を上げてみる\nyoshihiko.recover(25)   # 体力も回復させてみる\n\n# 再び確認:\nprint(\"ATK:\", yoshihiko.atk)\nprint(\"HP:\", yoshihiko.hp)\n# &gt;&gt;&gt; ATK: 60\n# &gt;&gt;&gt; HP: 125\nclass RpgHero でクラスを定義し、 atk = 50, hp = 100 で属性を与えている。 class で def により関数を定義し (メソッド)、 属性に対する処理を記述する。",
    "crumbs": [
      "Python",
      "オブジェクト指向とクラス"
    ]
  },
  {
    "objectID": "python/class.html#コンストラクタとは",
    "href": "python/class.html#コンストラクタとは",
    "title": "オブジェクト指向とクラス",
    "section": "コンストラクタとは",
    "text": "コンストラクタとは\nクラスをインスタンス化した時に最初に呼ばれるメソッドをコンストラクタとよぶ。 データの初期化をするものだと思えばいい。 class 内で __init__() で定義する。\nclass RpgHero:\n\n  def __init__(self):\n    self.atk = 50   # 攻撃力\n    self.hp = 100   # 体力\n\n  def powerup(self, i):\n    self.atk = self.atk + i\n\n  def recover(self, j):\n    self.hp = self.hp + j\n\n\nyoshihiko = RpgHero()\n\nprint(\"ATK:\", yoshihiko.atk)\nprint(\"HP:\", yoshihiko.hp)\n# &gt;&gt;&gt; ATK: 50\n# &gt;&gt;&gt; HP: 100\nインスタンス化のときに値を渡すことでより柔軟に class を利用できる:\nclass RpgHero:\n\n  def __init__(self, atk = 0, hp = 0):  # デフォルト値を持たせておくこともできる\n    self.atk = atk   # 攻撃力\n    self.hp = hp     # 体力\n\n  def powerup(self, i):\n    self.atk = self.atk + i\n\n  def recover(self, j):\n    self.hp = self.hp + j\n\n\nyoshihiko = RpgHero(atk = 50, hp = 100)\ndai = RpgHero(hp = 110)   # dai は HP だけ与えてみる\n\nprint(\"ATK:\", yoshihiko.atk)\nprint(\"HP:\", yoshihiko.hp)\n# &gt;&gt;&gt; ATK: 50\n# &gt;&gt;&gt; HP: 100\n\nprint(\"ATK:\", dai.atk)\nprint(\"HP:\", dai.hp)\n# &gt;&gt;&gt; ATK: 0\n# &gt;&gt;&gt; HP: 110",
    "crumbs": [
      "Python",
      "オブジェクト指向とクラス"
    ]
  },
  {
    "objectID": "python/class.html#クラスの継承",
    "href": "python/class.html#クラスの継承",
    "title": "オブジェクト指向とクラス",
    "section": "クラスの継承",
    "text": "クラスの継承\n一般的な場合の処理を記述したクラスを引き継いで、 より特殊な場合のデータと処理を記述することをクラスの継承という。\n例えば勇者がレベルアップした「マスター」というオブジェクトがあるとする。 このマスターには、もともと勇者が持っていた属性と処理に加えて、 「mp: 魔法力」という属性と「enhance: 魔法力の分だけ攻撃力を上げる」という処理が加わるとする。\n継承先のクラス内では、super() を使うことで継承元のメソッドを呼び出すことができる。\nclass RpgHero:\n\n  def __init__(self):\n    self.atk = 50   # 攻撃力\n    self.hp = 100   # 体力\n\n  def powerup(self, i):\n    self.atk = self.atk + i\n\n  def recover(self, j):\n    self.hp = self.hp + j\n\n# 「勇者」クラスを継承する「マスター」のクラス\nclass RpgMaster(RpgHero):\n\n  def __init__(self, atk=0, hp=0, mp = 0):\n    super().__init__(atk, hp)\n    self.mp = mp\n\n  def enhance(self):\n    super().powerup(self.mp)\n\n\nyoshihiko = RpgMaster(atk = 50, hp = 100, mp = 20)\nyoshihiko.enhance()\n\nprint(\"ATK:\", yoshihiko.atk)\n# &gt;&gt;&gt; ATK: 70",
    "crumbs": [
      "Python",
      "オブジェクト指向とクラス"
    ]
  },
  {
    "objectID": "python/1_uv.html",
    "href": "python/1_uv.html",
    "title": "uv — Rust 製 Python マネージャ",
    "section": "",
    "text": "Python プロジェクト管理、コマンドラインツール管理、Python バージョン管理など一通りの機能を備える。 Rust 製で高速。",
    "crumbs": [
      "Python",
      "uv"
    ]
  },
  {
    "objectID": "python/1_uv.html#installation",
    "href": "python/1_uv.html#installation",
    "title": "uv — Rust 製 Python マネージャ",
    "section": "Installation",
    "text": "Installation\nhttps://docs.astral.sh/uv/getting-started/installation/\n## Linux and MacOS\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n## Windows\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\nUnix 系 OS では .bashrc, .bash_profile, .profile の全部に . \"$HOME/.cargo/env\" が追加される。 先に Rust の環境作っておけばカスタム可能かも。\nWindows ではcurrent user & current host の .ps1 に PATH 設定が追記される。\nほかに pipx, pip, Homebrew, Docker でも入る。 先に Rust の環境があって Crate として入れる場合は GitHub から入れる:\npipx install uv\npip install uv\nbrew install uv  # MacOS\nwinget install --id=astral-sh.uv  -e  # Windows\n\ncargo install --git https://github.com/astral-sh/uv uv",
    "crumbs": [
      "Python",
      "uv"
    ]
  },
  {
    "objectID": "python/1_uv.html#python-インストーラとしての使用",
    "href": "python/1_uv.html#python-インストーラとしての使用",
    "title": "uv — Rust 製 Python マネージャ",
    "section": "Python インストーラとしての使用",
    "text": "Python インストーラとしての使用\nhttps://docs.astral.sh/uv/guides/install-python/\n\nuv python install はサードパーティ製の binary distribution をとってくる。\nuv で入れた Python は現在のところグローバルな使用は想定されていない。 uv run を介すか仮想環境中で使う。 もしくは、プレビュー版 の機能を使って ~/.local/bin にインストールする。\n\n\nuv python install\n\nPython のバージョンを指定してインストール\n\n\n指定しなければ最新版をインストール\n\nuv python list\n\n利用可能なバージョン一覧を表示\n\nuv python find\n\nインストール済みのバージョンを表示\n\nuv python pin\n\nカレントプロジェクトで使用する Python のバージョンを固定\n\nuv python uninstall\n\nPython のバージョンを指定してアンインストール\n\n\nインストール済みの Python があれば、uv は自動的にそれを使う:\n~$ uv python list\ncpython-3.13.0rc2-linux-x86_64-gnu    &lt;download available&gt;\ncpython-3.12.6-linux-x86_64-gnu       &lt;download available&gt;\ncpython-3.12.3-linux-x86_64-gnu       /usr/bin/python3.12\ncpython-3.12.3-linux-x86_64-gnu       /usr/bin/python3 -&gt; python3.12\ncpython-3.12.3-linux-x86_64-gnu       /bin/python3.12\ncpython-3.12.3-linux-x86_64-gnu       /bin/python3 -&gt; python3.12\nPython をインストール:\n~$ uv python install\nSearching for Python installations\nInstalled Python 3.12.6 in 1.99s\n + cpython-3.12.6-linux-x86_64-gnu\n\n~$ uv python list\ncpython-3.13.0rc2-linux-x86_64-gnu    &lt;download available&gt;\ncpython-3.12.6-linux-x86_64-gnu       .local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/bin/python3 -&gt; python3.12\ncpython-3.12.3-linux-x86_64-gnu       /usr/bin/python3.12\ncpython-3.12.3-linux-x86_64-gnu       /usr/bin/python3 -&gt; python3.12\ncpython-3.12.3-linux-x86_64-gnu       /bin/python3.12\ncpython-3.12.3-linux-x86_64-gnu       /bin/python3 -&gt; python3.12\nuv でインストールした python をグローバルに使いたければ インストール先を検出して自前で PATH を通せばいいはず…。\nif [ -d \"${UV_PYTHON_INSTALL_DIR:=$(uv python dir 2&gt;/dev/null)}\" ]; then\n  py_versions=($(ls \"${UV_PYTHON_INSTALL_DIR}\" | sort -V))\n  export PY_LATEST=${UV_PYTHON_INSTALL_DIR}/${py_versions[@]: -1}\n  PATH=\"${PY_LATEST}/bin:${PATH}\"\n  unset py_versions PY_LATEST\nfi",
    "crumbs": [
      "Python",
      "uv"
    ]
  },
  {
    "objectID": "python/1_uv.html#プロジェクトでの使用",
    "href": "python/1_uv.html#プロジェクトでの使用",
    "title": "uv — Rust 製 Python マネージャ",
    "section": "プロジェクトでの使用",
    "text": "プロジェクトでの使用\n\nhttps://docs.astral.sh/uv/guides/projects/\nhttps://docs.astral.sh/uv/concepts/projects/\nhttps://docs.astral.sh/uv/guides/publish/\n\nプロジェクトの立ち上げ:\nuv init hello\ncd hello\n\n# or\n\nmkdir hello && cd hello\nuv init\nデフォルトでは\n\n.git/\n.gitignore\n.python-version\nREADME.md\nhello.py ({project-name}.py)\npyproject.toml\n\nが作られ、すでに git init もされた状態で構築される (git があれば)。\nどのようなプロジェクトにするかでいくつかオプションがある:\n\n--package\n\nパッケージ用プロジェクトとして立ち上げる。\n\n\n{project-name}.py の代わりに src/{project-name}/__init__.py\n\n--app\n\nアプリケーション用プロジェクトとして立ち上げる。\n\n--lib\n\nライブラリ用プロジェクトとして立ち上げる。\n\n\n--package 同様の __init__.py と、加えて py.typed\n\n\nプロジェクト作成後に初めて uv run, uv sync, uv lock を使ったときに .venv/ と uv.lock も作られる。\n\npyproject.toml\n\nプロジェクトに関わる情報を書いておくファイル。 手動で編集してもいいし、uv 経由でツールを入れたりすると自動で dependencies とかは更新される。\n\n.venv/\n\n依存ツール等のインストール先\n\nuv.lock\n\npyproject.toml よりも厳密な依存関係管理のためのファイル。\n\n\n\nパッケージのインストール\nプロジェクトで使用するパッケージの管理もすべて uv がやってくれる。 例えば開発用パッケージとして pytest を使う場合:\nuv add pytest --dev\n自動で pyproject.toml に記述される:\n[tool.uv]\ndev-dependencies = [\n    \"pytest&gt;=8.3.3\",\n]",
    "crumbs": [
      "Python",
      "uv"
    ]
  },
  {
    "objectID": "python/1_uv.html#python-製コマンドラインツールの管理",
    "href": "python/1_uv.html#python-製コマンドラインツールの管理",
    "title": "uv — Rust 製 Python マネージャ",
    "section": "Python 製コマンドラインツールの管理",
    "text": "Python 製コマンドラインツールの管理\n\nhttps://docs.astral.sh/uv/concepts/tools/\nhttps://docs.astral.sh/uv/guides/tools/\n\nPython 製コマンドラインツールを使うためのインターフェイスとして、 インストールせず一時的に実行する uvx と、インストールしてグローバルに使う uv tool が用意されている。 (uvx は uv tool run のエイリアス。) 一応、ほとんどの場面ではインストールせず一時的に使うことが推奨されているっぽい。\n\nPEP 668 にある通り pip でグローバルに使うツールを入れることができなくなったので、 今のところその代わりとしても使える。\n\n\nインストールせず一時的に使う\nuvx ruff  # or `uv tool run ruff`\n\n\nインストールして使う\nuv tool install ruff\nruff\nその他コマンド:\n\nuv tool upgrade\n\nインストール済みツールのアップデート\n\nuv tool list\n\nインストール済みパッケージ一覧を表示\n\nuv tool uninstall\n\nアンインストール\n\nuv tool dir\n\nインストール先の PATH を表示\n\n\n実行ファイルのバイナリは ${HOME}/.local/bin に入る。 (--bin)",
    "crumbs": [
      "Python",
      "uv"
    ]
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "HOME",
    "section": "About",
    "text": "About\n\n松田 優樹 / MATSUDA Yuki\n\n東京農工大学 大学院 連合農学研究科 システム行動生物学研究グループ 博士課程 2 年\n\n連絡先・リンク / Contacts and Links\n\n yuki.matsuda.m10gmail.com (個人)\n\n\n s249780wst.go.tuat.ac.jp (大学)\n\n\n  ymat2 \n\n\n  0009-0006-2288-1621",
    "crumbs": [
      "HOME"
    ]
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "HOME",
    "section": "News",
    "text": "News\n\n\n2025.07.18\n\n共同執筆した書籍 『ヤポネシア人の起源と成立 3 ヤポネシアの動植物ゲノム』 が発売されました。「第2章 ニワトリのゲノム解析」でゲノムから見た日本のニワトリの起源と歴史について概説しています。\n\n2025.04.24 – 2025.04.25\n\n研究会 生物多様性の DNA 情報学 2025 に参加し、ポスター発表を行いました。\n\n2025.03.25\n\n農工大で取り組んできた、 日本のニワトリの起源と分散の軌跡を全ゲノム解析をもちいて明らかにした研究 が Poultry Science に掲載されました。\n\n2024.08.28\n\n東北大 牧野研究室で取り組んでいた、 鳥類とコウモリの寿命の進化に関わる遺伝基盤を調べた研究 が Proceedings of the Royal Society B に掲載されました。\n\n2024.08.21 – 2024.08.24\n\n第26回日本進化学会 (神奈川) に参加し、ポスター発表を行いました。\n\n2024.04.02\n\n東京農工大学 大学院 連合農学研究科に進学しました。 主にニワトリを対象に、家畜化の遺伝的基盤を探る研究を進めていきます。\n\n2024.03.26\n\n東北大学 大学院 生命科学研究科を修了し、修士 (生命科学) を取得しました。\n\n2024.03.16 – 2024.03.21\n\n第71回日本生態学会大会 (横浜) に参加し、ポスター発表を行いました。\n\n2024.03.16\n\nサイトのビルドフレームワークを、HUGO から Quarto に乗り換えました。\n\n2023.08.31 – 2023.09.03\n\n日本進化学会第25回大会 (沖縄) に参加し、ポスター発表を行いました。\n\n2023.01.12\n\n個人サイトを立ち上げました。",
    "crumbs": [
      "HOME"
    ]
  },
  {
    "objectID": "cli/vi.html",
    "href": "cli/vi.html",
    "title": "Vi/Vim",
    "section": "",
    "text": "https://www.vim.org/\nvi (ヴィーアイ) は UNIX に標準搭載されているテキストエディタ。 Vim (ヴィム) は vi の発展版で、近年の UNIX 系 OS で vi を打って起動するのは Vim であることが多い。",
    "crumbs": [
      "開発環境",
      "Vi/Vim"
    ]
  },
  {
    "objectID": "cli/vi.html#最低限覚えておくこと",
    "href": "cli/vi.html#最低限覚えておくこと",
    "title": "Vi/Vim",
    "section": "最低限覚えておくこと",
    "text": "最低限覚えておくこと\n\n起動時はノーマルモード (編集はできない)。\nカーソル移動は (矢印キーも使えるけど) 基本 h: 左, j: 下, k: 上, l: 右 でおこなう。\n編集は i でインサートモード --INSERT-- に入って行う。 インサートモードではカーソル移動はなるべくしない。\nインサートモードから抜けるには esc や controlC\n:w で変更を保存、:q で終了\n:wq や ZZ で保存して終了\n:q! で保存せずに強制終了",
    "crumbs": [
      "開発環境",
      "Vi/Vim"
    ]
  },
  {
    "objectID": "cli/vi.html#設定",
    "href": "cli/vi.html#設定",
    "title": "Vi/Vim",
    "section": "設定",
    "text": "設定\nノーマルモードで :set &lt;option&gt; もしくは ~/.vimrc\nc.f. https://github.com/ymat2/dotfiles/blob/main/.vimrc",
    "crumbs": [
      "開発環境",
      "Vi/Vim"
    ]
  },
  {
    "objectID": "cli/vi.html#vimtutor",
    "href": "cli/vi.html#vimtutor",
    "title": "Vi/Vim",
    "section": "vimtutor",
    "text": "vimtutor\nvim の操作を習得するための練習問題付き教材。 vimtutor で起動する。\n\nカーソル移動\n\nh, j, k, l (左、下、上、右)\n\n\n▲, ◀︎, ▶︎, ▼\n\n起動と終了\n\nesc でノーマルモードへ\n\n\n:q! で保存せずに終了\n\n\n:w で変更を保存、:q で終了\n\n\n:wq で保存して終了\n\nテキストの削除\n\nx でカーソルの右側の文字を削除\n\nテキストの挿入\n\n編集箇所まで移動 (インサートモードでも移動できるけどしないつもりで)\n\n\nI でインサートモードへ\n\n\n編集したら esc や controlC でノーマルモードへ\n\nテキストの追加\n\n編集行まで移動 (行の上ならどの位置でも OK)\n\n\nA でインサートモードへ。カーソルは末尾に移る。\n\n\n編集したらノーマルモードへ\n\n削除コマンド (オペレータ)\n\n削除したい箇所の”先頭”にカーソルを移動\n\n\ndw で空白を含む単語の末尾まで\n\n\nde で空白を含まない単語の末尾まで\n\n\nd$ でカーソル位置から行末まで\n\nモーション + カウント\n\nw、e は単体でカーソル移動コマンドとして機能する。\n\n\n数字と組み合わせて使用できる。\n\n\n2w で2単語先の語頭へ\n\n\n3e で3単語先の終端へ\n\n\n0 で行頭へ\n\nオペレータ + カウント + モーション\n\nd2w でカーソル位置から2単語削除\n\n行の削除\n\n削除する行にカーソルを移動 (位置はどこでもOK)\n\n\ndd で行を削除\n\n\n2dd で2行削除\n\n操作のやり直し\n\nu で直前の操作を取り消し\n\n\nU で行全体の操作を取り消し\n\n行の貼り付け\n\ndd で行をカット\n\n\n貼り付けたい位置のひとつ上の行へカーソルを移動\n\n\np で貼り付け\n\n置換 (使う場面ある？後述する s///g で十分な気もする。)\n\n置換する文字の先頭にカーソルを移動\n\n\nr置換先の文字 で置換\n\n変更\n\nce でカーソル位置から単語の終わりまでを削除\n\n\n同時にインサートモードに移るので、編集して esc\n\nファイル内の移動\n\ncontrolG で行番号を取得\n\n\nG でファイルの最下行へ\n\n\ngg でファイルの先頭へ\n\n\n行番号 G で指定した行へ\n\n検索\n\n/ + 検索したい単語 で下方向、? + 検索したい単語で上方向に検索\n\n\nn で次のヒット、N で前のヒットへカーソルを移動\n\n対応する括弧を検索\n\n% でカーソル位置の括弧と対応する括弧へ移動\n\n置換\n\n:s/old/new/g でカーソル行の “old” を “new” に置換\n\n\n:#,#s/old/new/g で置換開始行と終了行を指定\n\n\n:%s/old/new/g でファイル全体にわたって置換\n\n\n:%s/old/new/gc でファイル全体にわたって1つ1つ確認をとりながら置換\n\n外部コマンドの実行\n\n:! に続けてコマンドを実行できる。(e.x. :!pwd)\n\n\nEnter で終了\n\n範囲選択\n\nv でビジュアルモードに移行\n\n\nカーソルキーを移動して範囲選択\n\n\nshiftv は行選択モード、controlv は矩形選択モード\n\nファイル、標準出力の取り込み\n\n:r ファイル名 でファイルの内容をカーソル位置に挿入\n\n\n:r :!pwd などで、コマンドの標準出力を取り込むこともできる。\n\nオープンコマンド\n\no でカーソル位置の下に行を挿入してインサートモードへ\n\n\nO でカーソル位置の上に行を挿入してインサートモードへ\n\n置換モード\n\nR で置換モードへ\n\n\n文字を打つと元々あった文字は置き換えられる。\n\n\nesc や controlC で脱出\n\nコピー\n\nv でビジュアルモードに移行して範囲選択 → y でコピー\n\n\np でペースト\n\n\nyw で1単語コピー\n\n\nyy で行まるごとコピー",
    "crumbs": [
      "開発環境",
      "Vi/Vim"
    ]
  },
  {
    "objectID": "cli/rsync.html",
    "href": "cli/rsync.html",
    "title": "rsync",
    "section": "",
    "text": "https://rsync.samba.org/\nファイルやディレクトリの同期/バックアップを行うツール。 2つのディレクトリの差分を検出して差分のみ反映するといった使い方が可能。",
    "crumbs": [
      "開発環境",
      "rsync"
    ]
  },
  {
    "objectID": "cli/rsync.html#基本",
    "href": "cli/rsync.html#基本",
    "title": "rsync",
    "section": "基本",
    "text": "基本\n### Local\nrsync -option src/ dest/\n\n### Access via remote shell:\n# Push:\nrsync -option src/ user@host:dest/\n# Pull:\nrsync -option user@host:dest/ src/\n/ の有無で挙動が異なる。\n\nsrc/ dest/\n\nsrc 配下のファイルが dest/ にコピーされる。\n\nsrc dset/\n\nsrc ごと dest/ にコピーされる。\n\n\ndest/src/files",
    "crumbs": [
      "開発環境",
      "rsync"
    ]
  },
  {
    "objectID": "cli/rsync.html#option",
    "href": "cli/rsync.html#option",
    "title": "rsync",
    "section": "Option",
    "text": "Option\n\n-a, --archive\n\n?\n\n-u, --update\n\ndest 側で更新されているファイルをスキップする。\n\n-v, --verbose\n\nメッセージを冗長に表示させる。\n\n-z, --compress\n\n送受信中にファイルを圧縮する。",
    "crumbs": [
      "開発環境",
      "rsync"
    ]
  },
  {
    "objectID": "cli/nano.html#install",
    "href": "cli/nano.html#install",
    "title": "nano — small で friendly なテキストエディタ",
    "section": "Install",
    "text": "Install\nもともと入っているものを使うか、brew や apt でインストールする。\nwhich -a nano\n\nbrew install nano  ## mac\nsudo apt install nano  ## ubuntu\nmacOS 12.3 Monterey 以降、 Mac の nano の正体は pico なので、 いろいろ設定して使いたい場合は brew でインストールする。",
    "crumbs": [
      "開発環境",
      "nano"
    ]
  },
  {
    "objectID": "cli/nano.html#usage",
    "href": "cli/nano.html#usage",
    "title": "nano — small で friendly なテキストエディタ",
    "section": "Usage",
    "text": "Usage\n## 新規作成\nnano\n\n## 既存のファイルを編集\nnano hoge.txt\n\nKeyboard shortcuts\nデフォルトで編集画面の下部に書いてある。 表は編集画面でのショートカット。 nano のバージョンによって異なるものもあるっぽい。\n\n\n\n\n\n\n\n\nKey\nコマンド\n操作\n\n\n\n\ncontrolG\nHelp\nヘルプ画面へ\n\n\ncontrolX\nExit\n編集画面を抜ける\n\n\ncontrolO\nWrite Out\nファイル名を指定して書き込み\n\n\ncontrolR\nRead File\nファイル名を指定して読み込み\n\n\ncontrolW\nWhere Is\nファイル内検索\n\n\ncontrol \nReplace\nファイル内置換\n\n\ncontrolK\nCut\n選択範囲を切り取り\n\n\ncontrolU\nPaste\nカーソル位置に文字列を貼り付け\n\n\ncontrolT\nExecute\nコマンドラインの操作を実行して出力を貼り付け\n\n\ncontrolJ\nJustify\n均等割付\n\n\ncontrolC\nLocation\nカーソル位置の表示\n\n\ncontrol/\nGo To Line\n行数を指定してジャンプ\n\n\ncontrol]\nComplete\nファイル中にあるほかの単語を探して補完\n\n\nMetaU\nUndo\nひとつ前の状態に戻す\n\n\nMetaE\nRedo\n同じ操作をおこなう\n\n\nMetaA\nSet Marl\n選択範囲の開始点をセット\n\n\nMeta6\nCopy\n選択範囲をコピー\n\n\n\nMeta キーは Windows なら alt、Macなら esc",
    "crumbs": [
      "開発環境",
      "nano"
    ]
  },
  {
    "objectID": "cli/nano.html#configuration",
    "href": "cli/nano.html#configuration",
    "title": "nano — small で friendly なテキストエディタ",
    "section": "Configuration",
    "text": "Configuration\n基本的な設定はコマンドラインオプションで指定することもできるが、 一時的な設定でなければ config ファイルに書いてしまった方が楽。\n読み込まれる順番は、まず /etc/nanorc 、次に ~/.nanorc または ~/.config/nano/nanorc。\nLinux では /etc/nanorc や /usr/share/doc/nano/examples/samples.nanorc に、 Mac に brew で入れた場合は /usr/local/Cellar/nano/%v/share/doc/nano/sample.nanorc にドキュメントとコマンドがコメントアウトされて書いてあるので、 これを ~/.nanorc または ~/.config/nano/nanorc にコピーして編集する。(%v は nano のバージョン)\n自分で書いてしまってもいい。たとえば:\n\n\nnanorc\n\nset autoindent    # 改行時にインデントを揃える\nset nowrap        # 横に長い行を勝手に改行しない\nset smooth        # スクロールがスムーズに（あんまり実感したことはない）\nset tabsize 4       # タブサイズ（スペースの数）の設定\nset mouse           # マウスを使えるようにする\n\n\nset mouse の挙動について\n\n設定しなくても一応使える。 普通に文章を選択して CtrlC したり CtrlV したり。 ただカーソルは動かせないっぽい。\n\n\nset mouse すると完全に nano の中の挙動になる。 カーソルも動く。 ダブルクリックで範囲選択開始 (Set Mark)、次のクリックで範囲決定。 もう一度クリックすると解除 (Unset Mark)。\n\n\n\nSyntax highlight\nデフォルトの見た目は非常に寂しい。\nLinuxでは /usr/share/nano/ 、Mac (brew) では /usr/local/share/nano/ や /usr/local/Cellar/nano/%v/share/nano/ にハイライト定義ファイルが置いてあるので、 これらの設定を ~/.nanorc に加える。\nまたは野生の定義ファイルを使う手もある。(c.f. https://github.com/scopatz/nanorc)\n\n\nnanorc\n\ninclude \"/usr/share/nano/*.nanorc\"\n\n\n\nKey Bind\nキーボードショートカットは変更可能。 例えば CtrlZ を Undo に割り当てたい場合、以下のように書く。\n\n\nnanorc\n\nbind ^Z undo    main",
    "crumbs": [
      "開発環境",
      "nano"
    ]
  },
  {
    "objectID": "cli/git.html",
    "href": "cli/git.html",
    "title": "Git/GitHub",
    "section": "",
    "text": "https://git-scm.com/\nhttps://github.co.jp/",
    "crumbs": [
      "開発環境",
      "Git/GitHub"
    ]
  },
  {
    "objectID": "cli/git.html#基本操作",
    "href": "cli/git.html#基本操作",
    "title": "Git/GitHub",
    "section": "基本操作",
    "text": "基本操作\nこれから使い始める人向けスライド:\n\nGit 基本操作① — Git と GitHubを使い始める\nGit 基本操作② — fetch, merge, pull\n\n\n新しいリポジトリの作成\n\nGitHub のサイト右上の “+” ボタンから “New repository” を選択し、“Create repository” する。\n手元の PC にローカルリポジトリをつくる:\nmkdir new_repository\ncd new_repository\ngit init\nファイルを add して commit してもいいし、空の commit をしてもいい:\n## ファイルをつくってadd&commit\necho \"Hello, Github\" &gt; README.md\ngit add README.md\n\n## コミットメッセージを添える\ngit commit -m \"Initial commit\"\n\n## 空のコミットでもいい\ngit commit --allow-empty -m \":coffee: Create repository\"\nリモートリポジトリを紐づけて push:\ngit remote -v        # 何も表示されない\n\n## HTTP の場合\ngit remote add origin https://github.com/*username*/*new_repository*.git\n## SSH の場合\ngit remote add origin git@github.com:*username*/*new_repository*.git\n\ngit remote -v        # リモートリポジトリが表示されることを確認\ngit branch -M main\ngit push -u origin main\nPrivate リポジトリの場合、 SSH で紐付けしないと下り (fetch, pull) のときもパスワードを要求される。\n\n\n\n手元の変更をリモートリポジトリに反映\n\n基本: git add → git commit → git push\n\n\n手元でファイルをいじって変更を確認:\necho \"Hello, Github\" &gt; README.md\ngit status   # README.md が Changes not staged for commit: に表示される。\n変更したファイルをインデックスに登録:\ngit add README.md\ngit status     # README.md が Changes to be committed: に表示される。\n変更をコミット:\ngit commit -m \"modified hoge.txt\"\ngit status   # nothing to commit, working tree clean となる。\ngit log      # コミットが表示される。\nリモートリポジトリへ push:\ngit push\n\n\n\nリモートリポジトリの変更を手元に反映\n\n基本: git fetch → git merge もしくは git pull\n\n\nリモートブランチの状態を手元のファイルまで一気に反映:\ngit pull\nリモートブランチの変更を一度ローカルのアップストリームブランチに反映させてから手元のファイルに反映:\ngit fetch\ngit log --all\ngit merge",
    "crumbs": [
      "開発環境",
      "Git/GitHub"
    ]
  },
  {
    "objectID": "cli/git.html#gitignore",
    "href": "cli/git.html#gitignore",
    "title": "Git/GitHub",
    "section": ".gitignore",
    "text": ".gitignore\nhttps://docs.github.com/ja/get-started/getting-started-with-git/ignoring-files\nリポジトリのルートディレクトリに .gitignore を配置して、 Git の管理から除外するファイルを制御する:\n## 場所を問わず特定のファイル・ディレクトリを除外\nhoge\n\n## .gitignore が置かれたリポジトリの特定のファイル・ディレクトリを除外\n/hoge\n\n## 場所を問わず特定のディレクトリの除外\ndir/\n\n## .gitignore が置かれたリポジトリの特定のディレクトリを除外\n/dir/\n\n## 特定のファイル・ディレクトリのみ追跡\n*\n!hoge\n\n## ワイルドカードによる指定\n/*.py\n/*.Rproj\n~/.config/git/ignore でグローバルに除外対象を設定:\n.DS_Store\nすでに追跡しているファイルを除外するにはトラッキングを外す:\ngit rm --cached &lt;FILE_NAME&gt;",
    "crumbs": [
      "開発環境",
      "Git/GitHub"
    ]
  },
  {
    "objectID": "cli/git.html#ssh-接続",
    "href": "cli/git.html#ssh-接続",
    "title": "Git/GitHub",
    "section": "SSH 接続",
    "text": "SSH 接続\nhttps://docs.github.com/ja/authentication/connecting-to-github-with-ssh/about-ssh\n手順:\n\nSSH キーを生成する。\ngithub に公開キーを登録する。\nssh -T git@github.com で接続確認。\n\n\nssh -T の際に permission denied となる場合\nhttps://docs.github.com/ja/authentication/troubleshooting-ssh/using-ssh-over-the-https-port\nssh-keygen の際にファイル名を変更していると認証がうまくいかない。 ~/.ssh/config に以下を追記して解決。\n\n\n~/.ssh/config\n\nHost github github.com\n  HostName github.com\n  User git\n  IdentityFile ~/.ssh/id_rsa_git    # Github 用の秘密鍵",
    "crumbs": [
      "開発環境",
      "Git/GitHub"
    ]
  },
  {
    "objectID": "cli/git.html#git-submodule",
    "href": "cli/git.html#git-submodule",
    "title": "Git/GitHub",
    "section": "git submodule",
    "text": "git submodule\n外部のリポジトリを自分のリポジトリのサブディレクトリとして取り込む仕組み。\ngit submodule add https://github.com/&lt;username&gt;/&lt;repository&gt;.git &lt;directory&gt;\n\nsubmodule を最新版に更新する\ngit submodule foreach git pull\ngit add &lt;submodule&gt;\ngit commit -m \"updated submodule\"\n# git push\n\n\nサブモジュールを含むリポジトリを clone するとき\n普通に clone してくるとサブモジュールの中身は空になっている。 clone する際に、\ngit clone --recurse-sebmodules &lt;repository&gt;\nとしてサブモジュールの中身ごと落としてくるか、親リポジトリをクローンしたあと、\ngit submodule update --init\nしてサブモジュールの中身を取得する。",
    "crumbs": [
      "開発環境",
      "Git/GitHub"
    ]
  },
  {
    "objectID": "cli/git.html#そのほかのコマンド",
    "href": "cli/git.html#そのほかのコマンド",
    "title": "Git/GitHub",
    "section": "そのほかのコマンド",
    "text": "そのほかのコマンド\n\n直前の操作を修正:\n## 直前のミスコミットを修正\ngit commit --amend -m \"hogehoge\"\n\n## commitの取り消し\ngit reset --soft HEAD^\n\n## addの取り消し\ngit restore --staged file_name\nすでにリポジトリに登録されたファイルを削除:\ngit rm --cached *file*\nファイル名を変更:\ngit mv file file_renamed\ngit stash\ngit merge や git pull の際、コミットするほどでもない手元の変更を一時的に退避するために使う。\nworking directory と staging area の変更を退避する:\ngit stash -u        # -u: Untrackedなファイルも含める\n退避した変更を確認:\ngit stash list\n# stash@{0}: WIP on main: d426bc4 Fix a bug\ngit merge や git pull でリモートの変更を手元に反映した後、 退避していた変更を戻す:\ngit stash apply stash@{0} --index\n--index オプションなしだと、もともとステージングされていた変更も add 前の扱いで戻ってくる。\n退避していた変更を消す:\ngit stash drop stash@{0}  # 退避内容を指定して削除\ngit stash pop stash@{0}   # 退避内容を指定してブランチに戻すとともに削除\ngit stash clear           # 退避内容を全て削除\nリポジトリ名を変更:\n\nリモート側の操作： リポジトリのページ &gt;  “Setting” &gt; “Rename” から変更\n手元の操作：ローカルリポジトリの名前と .git/config を書き換える\nmv repository_name_before repository_name_after\nsed -i -e 's/repository_name_before/repository_name_after/g' .git/config",
    "crumbs": [
      "開発環境",
      "Git/GitHub"
    ]
  },
  {
    "objectID": "bio/snpEff.html",
    "href": "bio/snpEff.html",
    "title": "snpEff — 変異のアノテーション",
    "section": "",
    "text": "参考になる日本語のサイト:",
    "crumbs": [
      "Bioinformatics",
      "snpEff"
    ]
  },
  {
    "objectID": "bio/snpEff.html#installation",
    "href": "bio/snpEff.html#installation",
    "title": "snpEff — 変異のアノテーション",
    "section": "Installation",
    "text": "Installation\n遺伝研で環境構築。 Anaconda を使っていれば conda で入れてしまうのが楽っぽい:\nconda install bioconda::snpeff\n/usr/local/biotools/ にもあるのでそれでもいいかも。 (ただ最新版は動かなかった。)\n\nバイナリ版をインストールする場合 (個人的に推奨):\nSnpEff は Java に依存するので、手元に Java 環境を整える。 (遺伝研にもともとある Java では古くて動かない。)\n最新版の Java (binary) をダウンロードする:\ncd ~/bin\nwget https://download.oracle.com/java/23/latest/jdk-23_linux-x64_bin.tar.gz\ntar zxvf jdk-23_linux-x64_bin.tar.gz\nPATH を通して動作確認:\n\n\n~/.bash_profile\n\nexport JAVA_HOME=${HOME}/bin/jdk-23\nexport PATH=${JAVA_HOME}/bin:$PATH\nexport MALLOC_ARENA_MAX=2\n\nsource .bash_profile\njava -version\nJava が用意できたら SnpEff をダウンロードする:\ncd ~/bin\nwget https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip\nunzip snpEff_latest_core.zip\nPATH を通す:\n\n\n~/.bash_profile\n\nPATH=${HOME}/bin/snpEff/scripts:$PATH\nexport PATH\n\n読み込み & 動作確認:\n. ~/.bash_profile\nsnpEff -h",
    "crumbs": [
      "Bioinformatics",
      "snpEff"
    ]
  },
  {
    "objectID": "bio/snpEff.html#basic-usage",
    "href": "bio/snpEff.html#basic-usage",
    "title": "snpEff — 変異のアノテーション",
    "section": "Basic Usage",
    "text": "Basic Usage\nニワトリ (Gallus gallus) の場合:\n\nデータベースを探してダウンロード\nsnpEff databases | grep Gallus\n# GRCg6a.99  Gallus_gallus [https://snpeff.blob.core.windows.net/databases/v5_2/snpEff_v5_2_GRCg6a.99.zip, https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_GRCg6a.99.zip, https://snpeff.blob.core.windows.net/databases/v5_1/snpEff_v5_1_GRCg6a.99.zip]\n# Galgal4.75  Gallus_gallus [https://snpeff.blob.core.windows.net/databases/v5_2/snpEff_v5_2_Galgal4.75.zip, https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_Galgal4.75.zip, https://snpeff.blob.core.windows.net/databases/v5_1/snpEff_v5_1_Galgal4.75.zip]\n\nsnpEff download -v GRCg6a.99  # ない\nsnpEff download -v Galgal4.75\n\n\nVCF にアノテーション\nsnpEff Galgal4.75 [VCF] &gt; [OUTFILE]",
    "crumbs": [
      "Bioinformatics",
      "snpEff"
    ]
  },
  {
    "objectID": "bio/snpEff.html#ann-field",
    "href": "bio/snpEff.html#ann-field",
    "title": "snpEff — 変異のアノテーション",
    "section": "ANN field",
    "text": "ANN field\nアノテーションは、出力 VCF の INFO フィールドに ANN= の形で書かれる。 以前は EFF フィールドというのが使われていたらしく、こっちが良ければ -formatEff を付ける。\nANN field : ANN=Allele|Annotation|Putative_impact|Gene Name|Gene ID|Feature type|Feature ID|Transcript biotype|Rank/total|HGVS.c|HGVS.p|cDNA_position/cDNA_length|CDS_position/CDS_length|Protein_position/Protein_length|Distance to feature|Errors, Warnings or Information messages\nExample   : ANN=T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1406G&gt;A|p.Gly469Glu|1666/2034|1406/1674|469/557||\nExample   : ANN=T|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G&gt;A|||||3944|",
    "crumbs": [
      "Bioinformatics",
      "snpEff"
    ]
  },
  {
    "objectID": "bio/snpEff.html#output-summary",
    "href": "bio/snpEff.html#output-summary",
    "title": "snpEff — 変異のアノテーション",
    "section": "Output summary",
    "text": "Output summary\nデフォルトでは snpEff を実行したディレクトリに snpEff_summary.html と snpEff_genes.txt の2種類の 要約統計ファイルが出力される。\n-stats で出力先パスの指定が可能。 -noStats で要約統計ファイルを出力しない。 -csvStats で HTML ではなく CSV として出力。",
    "crumbs": [
      "Bioinformatics",
      "snpEff"
    ]
  },
  {
    "objectID": "bio/snpEff.html#custom-annotation",
    "href": "bio/snpEff.html#custom-annotation",
    "title": "snpEff — 変異のアノテーション",
    "section": "Custom Annotation",
    "text": "Custom Annotation\nhttps://pcingola.github.io/SnpEff/snpeff/build_db/\n使いたいデータベースがなかったり、あってもうまくダウンロードできない場合、 手元にゲノム配列とアノテーションファイルがあればデータベースを自作できる。 アノテーションファイルは (GTF/GFF/GenBank file/RefSeq table) のいずれかでできる。 今回 GFF/GTF を使う。\n\n後述するが少なくとも GRCg7b については GFF ではなく GTF がおすすめ。\n\n全ゲノム配列 (.fa) とアノテーション (.gff) をダウンロード:\ndatasets download genome accession GCF_016699485.2 --include gff3,genome\ndatasets コマンドについてはゲノムデータ取得 — datasets コマンドを使う方法を参照。\nsnpEff/snpEff.config に追記:\n\n\nsnpEff.config\n\n#---\n# Custom Annotation\n#---\n\n# Chicken genome, bGalGal1.mat.broiler.GRCg7b\nGRCg7b.genome : Gallus_gallus_domestics\n\nStandard codon tables じゃない場合、それも config に書く必要がある。 (MT とかバクテリアとか)\nsnpEff/data/ に .fa と .gff を格納する:\n# mkdir ~/bin/snpEff/data/  # data/ は download を先にやっていればあるはず\ncd ~/bin/snpEff/data/\nmkdir GRCg7b && cd GRCg7b\n\ncp ~/ref/grcg7b/GCF_016699485.2.fa sequences.fa\ncp ~/ref/grcg7b/GCF_016699485.2.gff genes.gff\n全ゲノム配列の方は snpEff/data/genomes/GRCg7b.fa でもいいらしい。\nここまでできたら snpEff build コマンドでデータベースを作る。 snpEff build は、デフォルトでは CDS とタンパク質の配列を探してチェックをしようとする。\nそれを避けて確認なしでデータベースを作る場合:\nsnpEff build -gff3 -v GRCg7b -noCheckCds -noCheckProtein\n確認を実行する場合:\n# 配列をget\ndatasets download genome accession GCF_016699485.2 --include protein,cds\nunzip ncbi_dataset.zip\n\n# 名前を変えて移動\nmv ncbi_dataset/data/GCF_016699485.2/cds_from_genomic.fna data/GRCg7b/cds.fa\nmv ncbi_dataset/data/GCF_016699485.2/protein.faa data/GRCg7b/protein.fa\n\n# build\nsnpEff build -gff3 -v GRCg7b\n今回使った CDS ファイルは、ヘッダーの違いで受け付けてもらえなかったので -noCheckCds でタンパク質配列のみ確認した:\nProtein check:  GRCg7b  OK: 68163       Not found: 69043        Errors: 521     Error percentage: 0.7585463863490769%\n\nGTF の方を使って再ビルド\nGFF を使ってビルドしたデータベースによるアノテーションでは、 NO_START_CODON となっている遺伝子が散見された。 GTF の方には開始コドンの情報があるが、GFF 側にはそれがなさそうなのが原因？ そこで、GTF を使って再度データベースをビルドしてみる。\ncp ~/ref/grcg7b/GCF_016699485.2.gtf ~/bin/snpEff/data/GRCg7b/genes.gtf\nsnpEff build -gtf22 -v GRCg7b -noCheckCds\n今回使っている GTF は gtf-version 2.2 というもので、 これを使うときは -gtf22 とする。 gff2 の方の GFT は -gff2 で使えるが、obsolete らしい。\nNot found が少なくていいかもしれない:\nProtein check:  GRCg7b  OK: 68138       Not found: 373  Errors: 546     Error percentage: 0.7949449653485529%\nアノテーション:\nsnpEff GRCg7b [VCF] &gt; [OUTFILE]",
    "crumbs": [
      "Bioinformatics",
      "snpEff"
    ]
  },
  {
    "objectID": "bio/paml-tutorial.html",
    "href": "bio/paml-tutorial.html",
    "title": "PAML チュートリアル",
    "section": "",
    "text": "PAML のテストデータを材料に codeml を一通り動かしてみる。\nPhylogenetic Analysis by Maximum Likelihood (PAML) は、DNA やタンパク質の配列を最尤法で系統解析するための 種々のプログラムを含むパッケージ。\n今回はその中で、コドンの配列から同義置換に対する非同義置換の速度である \\omega = d_\\text{N} / d_\\text{S} を推定して正の自然選択の検出を行う codeml を使う。",
    "crumbs": [
      "Bioinformatics",
      "PAML チュートリアル"
    ]
  },
  {
    "objectID": "bio/paml-tutorial.html#テストデータの準備",
    "href": "bio/paml-tutorial.html#テストデータの準備",
    "title": "PAML チュートリアル",
    "section": "テストデータの準備",
    "text": "テストデータの準備\nPAML の方で用意してある リゾチームの配列 を使う。んだけど、ファイルフォーマットが普段牧野研でよく使う形式と異なるので、 ひとまず↓をコピペして使ってください。\n\n\nlysozymeSmall.fa\n\n&gt;Hsa_Human\nAAGGTCTTTGAAAGGTGTGAGTTGGCCAGAACTCTGAAAAGATTGGGAATGGATGGCTAC\nAGGGGAATCAGCCTAGCAAACTGGATGTGTTTGGCCAAATGGGAGAGTGGTTACAACACA\nCGAGCTACAAACTACAATGCTGGAGACAGAAGCACTGATTATGGGATATTTCAGATCAAT\nAGCCGCTACTGGTGTAATGATGGCAAAACCCCAGGAGCAGTTAATGCCTGTCATTTATCC\nTGCAGTGCTTTGCTGCAAGATAACATCGCTGATGCTGTAGCTTGTGCAAAGAGGGTTGTC\nCGTGATCCACAAGGCATTAGAGCATGGGTGGCATGGAGAAATCGTTGTCAAAACAGAGAT\nGTCCGTCAGTATGTTCAAGGTTGTGGAGTG\n\n&gt;Hla_gibbon\nAAGGTCTTTGAAAGGTGTGAGTTGGCCAGAACTCTGAAAAGATTGGGAATGGATGGCTAC\nAGGGGAATCAGCCTAGCAAACTGGATGTGTTTGGCCAAATGGGAGAGTGGTTATAACACA\nCGAGCTACAAACTACAATCCTGGAGACAGAAGCACTGATTATGGGATATTTCAGATCAAT\nAGCCGCTACTGGTGTAATGATGGCAAAACCCCAGGAGCAGTTAATGCCTGTCATTTATCC\nTGCAATGCTTTGCTGCAAGATAACATCGCCGATGCTGTAGCTTGTGCAAAGAGGGTTGTC\nCGCGATCCACAAGGCATTAGAGCATGGGTGGCATGGAGAAATCGTTGTCAAAACAGAGAT\nCTCCGTCAGTATATTCAAGGTTGTGGAGTA\n\n&gt;Cgu/Can_colobus\nAAGATCTTTGAAAGGTGTGAGTTGGCCAGAACTCTGAAAAAATTGGGACTGGATGGCTAC\nAAGGGAGTCAGCCTAGCAAACTGGGTGTGTTTGGCCAAATGGGAGAGTGGTTATAACACA\nGACGCTACAAACTACAATCCTGGAGATGAAAGCACTGATTATGGGATATTTCAGATCAAT\nAGCCGCTACTGGTGTAATAATGGCAAAACCCCAGGAGCAGTTAATGCCTGTCATATATCC\nTGCAATGCTTTGCTGCAAAATAACATCGCTGATGCTGTAGCTTGTGCAAAGAGGGTTGTC\nAGTGATCCACAAGGCATTCGAGCATGGGTGGCATGGAAAAAGCACTGTCAAAACAGAGAT\nGTCAGTCAGTATGTTGAAGGTTGTGGAGTA\n\n&gt;Pne_langur\nAAGATCTTTGAAAGGTGTGAGTTGGCCAGAACTCTGAAAAAATTGGGACTGGATGGCTAC\nAAGGGAGTCAGCCTAGCAAACTGGGTGTGTTTGGCCAAATGGGAGAGTGGTTATAACACA\nGAAGCTACAAACTACAATCCTGGAGACGAAAGCACTGATTATGGGATATTTCAGATCAAT\nAGCCGCTACTGGTGTAATAATGGCAAAACCCCAGGAGCAGTTGATGCCTGTCATATATCC\nTGCAGTGCTTTGCTGCAAAACAACATCGCTGATGCTGTAGCTTGTGCAAAGAGGGTTGTC\nAGTGATCCACAAGGCGTTCGAGCATGGGTGGCATGGAGAAATCACTGTCAAAACAAAGAT\nGTCAGTCAGTACGTTAAAGGTTGTGGAGTG\n\n&gt;Mmu_rhesus\nAAGATCTTTGAAAGGTGTGAGTTGGCCAGAACTCTGAAAAGATTGGGACTGGATGGCTAC\nAGGGGAATCAGCCTAGCAAACTGGGTGTGTTTGGCCAAATGGGAGAGTAATTATAACACA\nCAAGCTACAAACTACAATCCTGGAGACCAAAGCACTGATTATGGGATATTTCAGATCAAT\nAGCCACTACTGGTGTAATAATGGCAAAACCCCAGGAGCAGTTAATGCCTGTCATATATCC\nTGCAATGCTTTGCTGCAAGATAACATCGCTGATGCTGTAACTTGTGCAAAGAGGGTTGTC\nAGTGATCCACAAGGCATTAGAGCATGGGTGGCATGGAGAAATCACTGTCAAAACAGAGAT\nGTCAGTCAGTATGTTCAAGGTTGTGGAGTG\n\n&gt;Ssc_squirrelM\nAAGGTCTTCGAAAGGTGTGAGTTGGCCAGAACTCTGAAAAGGCTTGGAATGGATGGCTAC\nAGGGGAATCAGCCTAGCAAACTGGATGTGTTTGGCCAAATGGGAGAGTGACTATAACACA\nCGTGCTACAAACTACAATCCTGGAGACCAAAGCACTGATTATGGGATATTTCAGATCAAT\nAGCCACTATTGGTGTAATAATGGCAGAACCCCAGGAGCAGTTAATGCCTGTCATATATCC\nTGCAATGCTTTGCTGCAAGATGACATCACTCAAGCTGTGGCCTGTGCAAAGAGGGTTGTC\nCGTGATCCACAAGGCATTAGAGCATGGGTGGCATGGAAAGCTCATTGTCAAAACAGAGAT\nGTCAGTCAGTATGTTCAAGGTTGTGGAGTA\n\n&gt;Cja_marmoset\nAAGGTCTTTGAAAGGTGTGAGTTGGCCAGAACTCTGAAAAGGTTTGGACTGGATGGCTAC\nAGGGGAATCAGCCTAGCAAACTGGATGTGTTTGGCCAAATGGGAGAGTGATTATAACACA\nCGTGCTACAAACTACAATCCTGGAGACCAAAGCACTGATTATGGGATATTTCAGATCAAT\nAGCCACTATTGGTGTAACAATGGCAGAACCCCAGGAGCAGTTAATGCCTGTCATATATCC\nTGCAATGCTTTGCTGCAAGATGACATCACTGAAGCTGTGGCCTGTGCAAAGAGGGTTGTC\nCGCGATCCACAAGGCATTAGGGCATGGGTGGCATGGAAAGCTCATTGTCAAAACAGAGAT\nGTCAGTCAGTATGTTCAAGGTTGTGGAGTA\n\n\n\nlysozymeSmall.fa.treefile\n\n(Hsa_Human:0.0087447996,Hla_gibbon:0.0130303081,(((Cgu/Can_colobus:0.0156654142,Pne_langur:0.0181835564):0.0280807319,Mmu_rhesus:0.0070703774):0.0147707727,(Ssc_squirrelM:0.0140657314,Cja_marmoset:0.0076397044):0.0477319527):0.0256856586);\n\n系統樹ファイルは IQ-TREE を使って推定したもの。 手元でやってもらってもいいです。\niqtree2 --version\n# IQ-TREE multicore version 2.0.7 for Linux 64-bit built Jan 21 2022\n# Developed by Bui Quang Minh, Nguyen Lam Tung, Olga Chernomor,\n# Heiko Schmidt, Dominik Schrempf, Michael Woodhams.\n\niqtree2 -s lysozymeSmall.fa -m TEST\n\n\n\n\n\n\n\n\n\n\n\n\n\n生物学的な背景\n葉を常食とする旧世界ザル (左図) で、 反芻動物に似た前胃での発酵をともなう消化を獲得\n前胃に分泌されるリゾチームが進化\nMessier and Stewart 1997",
    "crumbs": [
      "Bioinformatics",
      "PAML チュートリアル"
    ]
  },
  {
    "objectID": "bio/paml-tutorial.html#素の-paml-を動かす",
    "href": "bio/paml-tutorial.html#素の-paml-を動かす",
    "title": "PAML チュートリアル",
    "section": "素の PAML を動かす",
    "text": "素の PAML を動かす\n\nPAML website\nPAML github リポジトリ\n井上潤さんのホームページ\nPAML Beginner’s Guide\n\n\nPAML をインストールする\nいずれかのパッケージ管理ツールを介するのが楽。\nHomebrew を使う場合 brewsci/bio/ リポジトリのため、 M2 チップ以降の Mac には対応していない可能性がある。 遺伝研では apptainer (singularity) を使わなくてもすでに PAML の環境が整っている。 (c.f. which -a codeml)\n## Homebrew を使う (Mac, M2 チップ以上だと無理かも)\nbrew install brewsci/bio/paml\n\n## apt を使う (Ubuntu)\nsudo apt install paml\n\n## conda を介したインストール (共通)\nconda install -c bioconda paml\n\n## apptainer のやつを使う (遺伝研)\nls /usr/local/biotools/p/paml*\nこれらのいずれの方法も使えないときは、 ソースコードを ダウンロードして手元でビルドする。 方法は公式サイトに記載がある。\n\n\n.ctl ファイルの概要\ncodeml を動かすとき、ファイルの指定や種々のオプションの指定は、 すべてコントロールファイル (.ctl) に記述する。 見た目はこんな感じ:\n\n\nlysozymeSmall.ctl\n\n      seqfile = lysozymeSmall.fa\n     treefile = lysozymeSmall.fa.treefile\n      outfile = your_output_file\n\n        noisy = 9   * 0,1,2,3,9: how much rubbish on the screen\n      verbose = 1   * 1: detailed output, 0: concise output\n      runmode = 0   * 0: user tree;  1: semi-automatic;  2: automatic\n                    * 3: StepwiseAddition; (4,5):PerturbationNNI\n\n      seqtype = 1   * 1:codons; 2:AAs; 3:codons--&gt;AAs\n    CodonFreq = 2   * 0:1/61 each, 1:F1X4, 2:F3X4, 3:codon table\n        clock = 0   * 0: no clock, unrooted tree, 1: clock, rooted tree\n        model = 2\n                    * models for codons:\n                        * 0:one, 1:b, 2:2 or more dN/dS ratios for branches\n\n      NSsites = 0   * dN/dS among sites. 0:no variation, 1:neutral, 2:positive\n        icode = 0   * 0:standard genetic code; 1:mammalian mt; 2-10:see below\n\n    fix_kappa = 0   * 1: kappa fixed, 0: kappa to be estimated\n        kappa = 2   * initial or fixed kappa\n    fix_omega = 0   * 1: omega or omega_1 fixed, 0: estimate\n        omega = 2   * initial or fixed omega, for codons or codon-transltd AAs\n\n    fix_alpha = 1   * 0: estimate gamma shape parameter; 1: fix it at alpha\n        alpha = .0  * initial or fixed alpha, 0:infinity (constant rate)\n       Malpha = 0   * different alphas for genes\n        ncatG = 4   * # of categories in the dG or AdG models of rates\n\n        getSE = 0   * 0: don't want them, 1: want S.E.s of estimates\n RateAncestor = 0   * (1/0): rates (alpha&gt;0) or ancestral states (alpha=0)\n       method = 0   * 0: simultaneous; 1: one branch at a time\n  fix_blength = 0  * 0: ignore, -1: random, 1: initial, 2: fixed, 3: proportional\n\n\n* Specifications for duplicating results for the small data set in table 1\n* of Yang (1998 MBE 15:568-573).\n* see the tree file lysozyme.trees for specification of node (branch) labels\n\nどの解析でも共通で変更するのは seqfile, treefile, outfile の3つ。 model, NSsites, fix_omega, omega は解析に応じて変更する。\n\nseqfile\n\nDNAまたはタンパク質の配列のファイルパス。\n\ntreefile\n\n系統樹のファイルパス。tip 名は seqfile のものと一致している必要がある。\n\noutfile\n\n出力ファイルのパス。\n\nmodel\n\n系統樹の各 branch における \\omega = d_\\text{N} / d_\\text{S} の設定。\n\n\n0: 系統樹全体で均一の \\omega = d_\\text{N} / d_\\text{S} を推定。\n\n\n1: branch ごとに異なる \\omega = d_\\text{N} / d_\\text{S} を推定。\n\n\n2: treefile の branch に #, #1 などの記号を振って各記号の branch で異なる \\omega = d_\\text{N} / d_\\text{S} を推定。\n\nNSsites\n\nコドン/アミノ酸サイトごとの \\omega = d_\\text{N} / d_\\text{S} の設定。\n\n\n0: サイト間で \\omega = d_\\text{N} / d_\\text{S} が同じと仮定。branch モデルの時はこれ。\n\n\n1: Neutral\n\n\n2: Positive\n\nfix_omega\n\n\\omega = d_\\text{N} / d_\\text{S} を固定するかどうか。\n\n\n0: 初期値から最尤推定する。\n\n\n1: 初期値で固定する。\n\nomega\n\n\\omega = d_\\text{N} / d_\\text{S} の初期値。\n\n\n\n\nおおまかな流れ\n検証したいシナリオ (特定の枝で正の自然選択がある、等) を対立仮説、 そうでないと仮定するシナリオを帰無仮説としてそれぞれ .ctl を書いて codeml を動かす。\nそれぞれの仮説のパラメータ数と対数尤度が得られるので、 尤度比検定を用いて帰無仮説を棄却することで対立仮説を採択する。\nよく使われる対立仮説と帰無仮説の組み合わせは以下の表のとおり:\n\n\n\n対立仮説\n帰無仮説\n検定すること\n引用\n\n\n\n\nM2\nM1\n特定サイトにおける正の自然選択\nYang 2000\n\n\nM3\nM0\nサイト間で d_\\text{N} / d_\\text{S} が異なるか\n〃\n\n\nM8\nM7\n特定サイトにおける正の自然選択\nYang 2000\n\n\nM8\nM8a\n特定サイトにおける選択の緩和\n〃\n\n\nbsA\nbsA1\n特定の枝の特定のサイトにおける正の自然選択\nZhang 2005\n\n\nbsA\nM1\n特定の枝の特定のサイトにおける選択の緩和\nZhang 2005\n\n\nbsC\nM1\n特定のクレードの特定のサイトで d_\\text{N} / d_\\text{S} が異なるか\nYang 2002\n\n\nbsD\nM3\n特定のクレードの特定のサイトで d_\\text{N} / d_\\text{S} が異なるか\nYang 2002, Bielawski 2004\n\n\nb_free\nb_neut\n特定の枝で d_\\text{N} / d_\\text{S} が1と異なるか\nYang 2002\n\n\nb_free\nM0\n特定の枝で d_\\text{N} / d_\\text{S} が他と異なるか\nYang 2002\n\n\n\n\n\nSite モデル\n🚧 工事中 🚧\n\n\nBranch モデル\n旧世界ザルの共通祖先の枝を対象に、 正の自然選択 (d_\\text{N} / d_\\text{S} &gt; 0) を検出する。\nまず対立仮説として、注目する枝で d_\\text{N} / d_\\text{S} が異なると仮定して codeml を動かす。\n系統樹 (lysozymeSmall.fa.treefile) をエディタで編集して、 注目する枝 (i.e. d_\\text{N} / d_\\text{S} &gt; 0 を想定する枝) に #1 を振る:\n\n\n(Hsa_Human:0.0087447996,Hla_gibbon:0.0130303081,(((Cgu/Can_colobus:0.0156654142,Pne_langur:0.0181835564)#1:0.0280807319,Mmu_rhesus:0.0070703774):0.0147707727,(Ssc_squirrelM:0.0140657314,Cja_marmoset:0.0076397044):0.0477319527):0.0256856586);\n\n\n\n\n\n\n\n\n\n\n\n\n#1 を振った枝とその他の枝で d_\\text{N} / d_\\text{S} が異なる、 というシナリオの .ctl を書く:\n\n\nb_free.ctl\n\n   outfile = branch_alt  * 何でもいいけど branch モデルの対立仮説と分かるように\n     model = 2           * 記号の有無で異なる ω を推定\n   NSsites = 0           * サイト間では ω は一定\n fix_omega = 0           * ω の値を配列から推定\n     omega = 1           * 推定は ω=1 からスタート\n\n* 他のパラメータは変更なし\n\nこの .ctl を指定して codeml を実行:\ncodeml b_free.ctl\n指定した出力ファイル branch_alt を見てみる。 まずは最後の方に書かれている各枝の \\omega の値:\ntail branch_alt\ndS tree:\n(Hsa_Human: 0.011030, Hla_gibbon: 0.016794, (((Cgu/Can_colobus: 0.018929, Pne_langur: 0.022497): 0.009367, Mmu_rhesus: 0.008406): 0.018929, (Ssc_squirrelM: 0.017701, Cja_marmoset: 0.010258): 0.052331): 0.030198);\ndN tree:\n(Hsa_Human: 0.007565, Hla_gibbon: 0.011517, (((Cgu/Can_colobus: 0.012981, Pne_langur: 0.015429): 0.032838, Mmu_rhesus: 0.005765): 0.012982, (Ssc_squirrelM: 0.012140, Cja_marmoset: 0.007035): 0.035889): 0.020710);\n\nw ratios as labels for TreeView:\n(Hsa_Human #0.68581 , Hla_gibbon #0.68581 , (((Cgu/Can_colobus #0.68581 , Pne_langur #0.68581 ) #3.50573 , Mmu_rhesus #0.68581 ) #0.68581 , (Ssc_squirrelM #0.68581 , Cja_marmoset #0.68581 ) #0.68581 ) #0.68581 );\n\n\nTime used:  0:01\n期待通り、#1 を振った枝とそれ以外の枝で異なる \\omega が計算されている。 (旧世界ザルの共通祖先で \\omega = 3.50573, そのほかの枝で \\omega = 0.68581)\nもう一か所は、パラメータ数と対数尤度が記述された行:\ngrep \"lnL\" branch_alt\nlnL(ntime: 11  np: 14):   -904.636553      +0.000000\nパラメータ数が14、対数尤度が -904.636553 であることを示している。\n\n次に、帰無仮説として指定した枝の \\omega を1で固定したモデルの 当てはまりを計算する。\n.ctl の以下のパラメータを変更する:\n\n\nb_neut.ctl\n\n   outfile = branch_null  * 何でもいいけど branch モデルの帰無仮説と分かるように\n fix_omega = 1            * ω の値を固定\n     omega = 1            * ω=1\n\n* 他のパラメータは変更なし\n\nこの .ctl を指定して codeml を実行:\ncodeml b_neut.ctl\n同様に出力ファイル branch_null を見てみる。 各枝の \\omega の値は:\nw ratios as labels for TreeView:\n(Hsa_Human #0.685577 , Hla_gibbon #0.685577 , (((Cgu/Can_colobus #0.685577 , Pne_langur #0.685577 ) #1 , Mmu_rhesus #0.685577 ) #0.685577 , (Ssc_squirrelM #0.685577 , Cja_marmoset #0.685577 ) #0.685577 ) #0.685577 );\nパラメータ数と対数尤度は:\n$ grep \"lnL\" branch_null\nlnL(ntime: 11  np: 13):   -905.484183      +0.000000\nまとめると次のようになった:\n\n\n\n仮説\n注目する枝の \\omega\nパラメータ数\n対数尤度\n\n\n\n\n対立仮説\n3.50573\n14\n-904.636553\n\n\n帰無仮説\n1\n13\n-905.484183\n\n\n\n\n最後に尤度比検定を行って、 「注目する枝の \\omega が他の枝より高いようだけど、 これは選択の緩和 (\\omega=1) じゃなくて 正の自然選択　(\\omega&gt;1) だ。」 ということを統計的に主張できるかどうか確かめる。\n尤度比検定の方法はいくつかあるけど、R とか Python 使うのがいいんじゃないだろうか。 (エクセルとかでもできるらしい。)\nPython の尤度比検定の関数を使って検定する:\n\n\nlrp.py\n\nfrom scipy.stats import chi2\n\nalt_lnL = -904.636553   # 対立仮説の対数尤度\nnull_lnL = -905.484183  # 帰無の対数尤度\nlr_stat = 2 * (alt_lnL - null_lnL)\n\nalt_np = 14    # 対立仮説のパラメータ数\nnull_np = 13   # 帰無仮説のパラメータ数\ndf = alt_np - null_np\n\np_val = chi2.sf(lr_stat, df)\nprint(p_val)\n\n$ python3 lrt.py\n0.19290903422911437\n結果、尤度比検定の p-value は 0.1929 &gt; 0.05 となった。 これを解釈すると、帰無仮説を棄却することができない = 正の自然選択とは主張できないとなる。\n\n\nBranch-Site モデル\nSite モデルや Branch モデルは枝全体やサイト全体で \\omega を平均するため、 時に検出力が弱くなる。\nつまり、ある枝で特定のサイトに正の自然選択が本当に働いていたとしても、 他のサイトや枝の \\omega が小さければそれに引っ張られて \\omega &gt; 1 を検出できない。\nそこで、Branch-Site モデルは特定の枝の特定のサイトに働いた自然選択を検出する。\n使う系統樹は Branch モデルと同じ。\nまず対立仮説として、#1 を振った枝で \\omega &gt; 1 のサイトがある、 というシナリオの .ctl を書く:\n\n\nbsA.ctl\n\n   outfile = bs_alt   * 何でもいいけど branch-site モデルの対立仮説と分かるように\n     model = 2        * 記号の有無で異なる ω を推定\n   NSsites = 2        * ω &gt; 1 のサイトを仮定\n fix_omega = 0        * ω の値を配列から推定\n     omega = 1        * 推定は ω=1 からスタート\n\n* 他のパラメータは変更なし\n\nこの .ctl を指定して codeml を実行:\ncodeml bsA.ctl\n出力ファイル bs_alt を見てみる。 以下のような記述があるはず:\nMLEs of dN/dS (w) for site classes (K=4)\n\nsite class             0        1       2a       2b\nproportion       0.29433  0.35964  0.15574  0.19029\nbackground w     0.00000  1.00000  0.00000  1.00000\nforeground w     0.00000  1.00000  5.78754  5.78754\n各サイトクラスは次のように解釈する:\n\nsite class 0\n\n#1 を振った枝もそれ以外も \\omega &lt; 1 であるサイト\n\n\n今回は全サイトのうち約29%がこれにあたり、\\omega = 0 の強い純化選択をうけている。\n\nsite class 1\n\n#1 を振った枝もそれ以外も \\omega = 1 であるサイト\n\n\n今回は全サイトのうち約36%がこれにあたる。\n\nsite class 2a\n\n#1 を振った枝で \\omega &gt; 1、 それ以外で \\omega &lt; 1 であるサイト\n\n\n今回は全サイトのうち約16%がこれにあたり、#1 の枝では \\omega = 5.78754 の強い正の自然選択が働いている。\n\nsite class 2b\n\n#1 を振った枝で \\omega &gt; 1、 それ以外で \\omega = 1 であるサイト\n\n\n今回は全サイトのうち約19%がこれにあたる。\n\n\n次は Branch モデルと同じく、パラメータ数と対数尤度が記述された行:\n$ grep \"lnL\" bs_alt\nlnL(ntime: 11  np: 16):   -901.562791      +0.000000\nさらに、Branch-Site モデルではどのサイトが正の自然選択を受けているかを示す記述がある:\nBayes Empirical Bayes (BEB) analysis (Yang, Wong & Nielsen 2005. Mol. Biol. Evol. 22:1107-1118)\nPositive sites for foreground lineages Prob(w&gt;1):\n    14 R 0.795\n    21 R 0.798\n    23 I 0.799\n    37 G 0.585\n    41 R 0.713\n    50 R 0.707\n    62 R 0.583\n    87 D 0.796\n   126 Q 0.699\nBEB 法 (Bayes empirical Bayes法) により求められた、 そのサイトが \\omega &gt; 1 で正の選択下にある事後確率を示す。 この事後確率が 0.95 や 0.99 を超えていた場合に正の自然選択が働いたサイトとする論文をよく見る。\n今回はそういうサイトはなさそう。\n\n次に、帰無仮説として指定した枝のサイトの \\omega を1で固定したモデルの当てはまりを計算する。\n.ctl のパラメータを変更する:\n\n\nbsA1.ctl\n\n   outfile = bs_null  * 何でもいいけど branch-site モデルの帰無仮説と分かるように\n fix_omega = 1        * ω の値を固定\n     omega = 1        * ω=1\n\n* 他のパラメータは変更なし\n\nこの .ctl を指定して codeml を実行:\ncodeml bsA1.ctl\n同様に出力ファイル bs_null を見てみる。 サイトクラスを見ると #1 の枝の \\omega が1になっている:\nMLEs of dN/dS (w) for site classes (K=4)\n\nsite class             0        1       2a       2b\nproportion       0.26177  0.32442  0.18479  0.22902\nbackground w     0.00000  1.00000  0.00000  1.00000\nforeground w     0.00000  1.00000  1.00000  1.00000\nパラメータ数と対数尤度は:\n$ grep \"lnL\" bs_null\nlnL(ntime: 11  np: 15):   -902.301501      +0.000000\n\n最後に、同じく尤度比検定を行って、対立仮説が採択されるか確かめる:\n\n\nlrp.py\n\nfrom scipy.stats import chi2\n\nalt_lnL = -901.562791   # 対立仮説の対数尤度\nnull_lnL = -902.301501  # 帰無の対数尤度\nlr_stat = 2 * (alt_lnL - null_lnL)\n\nalt_np = 16    # 対立仮説のパラメータ数\nnull_np = 15   # 帰無仮説のパラメータ数\ndf = alt_np - null_np\n\np_val = chi2.sf(lr_stat, df)\nprint(p_val)\n\n$ python3 lrt.py\n0.22417862391381319\n結果、尤度比検定の p-value は 0.2242 &gt; 0.05 となった。 Branch-Site モデルでも、 帰無仮説を棄却することができない = 正の自然選択とは主張できない となった。",
    "crumbs": [
      "Bioinformatics",
      "PAML チュートリアル"
    ]
  },
  {
    "objectID": "bio/paml-tutorial.html#ete-を使って-paml-を動かす",
    "href": "bio/paml-tutorial.html#ete-を使って-paml-を動かす",
    "title": "PAML チュートリアル",
    "section": "ete を使って PAML を動かす",
    "text": "ete を使って PAML を動かす\n🚧 工事中 🚧",
    "crumbs": [
      "Bioinformatics",
      "PAML チュートリアル"
    ]
  },
  {
    "objectID": "bio/ncbi_download.html",
    "href": "bio/ncbi_download.html",
    "title": "ゲノムデータ取得 — NCBI から一括ダウンロード",
    "section": "",
    "text": "https://www.ncbi.nlm.nih.gov/datasets/docs/v2/download-and-install/\nrsync, wget, curl などが使えるらしい。 公式には datasets コマンドが推奨されている。",
    "crumbs": [
      "Bioinformatics",
      "ゲノムデータ取得"
    ]
  },
  {
    "objectID": "bio/ncbi_download.html#data_hub-から分類群を指定してダウンロード-gui",
    "href": "bio/ncbi_download.html#data_hub-から分類群を指定してダウンロード-gui",
    "title": "ゲノムデータ取得 — NCBI から一括ダウンロード",
    "section": "data_hub から分類群を指定してダウンロード (GUI)",
    "text": "data_hub から分類群を指定してダウンロード (GUI)\n\nhttps://www.ncbi.nlm.nih.gov/data-hub/genome/ にアクセス\nSelected taxa で分類群を指定 (例えば “Aves”, “Primates” など)\nFilters でフィルタリング\nAssembly を選択して Download\n\nDownload Table は検索結果の表\nDownload Package は file type (gff, fna, faa など) を指定してダウンロード\n\nSelect columns からゲノムサイズや Gene Content なども表示させることができる。",
    "crumbs": [
      "Bioinformatics",
      "ゲノムデータ取得"
    ]
  },
  {
    "objectID": "bio/ncbi_download.html#コマンドラインで一括ダウンロード",
    "href": "bio/ncbi_download.html#コマンドラインで一括ダウンロード",
    "title": "ゲノムデータ取得 — NCBI から一括ダウンロード",
    "section": "コマンドラインで一括ダウンロード",
    "text": "コマンドラインで一括ダウンロード\n\ndatasets コマンドを使う方法\nhttps://www.ncbi.nlm.nih.gov/datasets/docs/v2/how-tos/genomes/download-genome/\ndatasets コマンドをインストールする:\n## Linux\ncurl -o datasets 'https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/v2/linux-amd64/datasets'\nchmod +x datasets   # 実行権限を付与\n\n## Mac\ncurl -o datasets 'https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/v2/mac/datasets'\nchmod +x datasets\naccession を指定してダウンロード:\ndatasets download genome accession GCF_000001405.40 \\\n    --filename human_GRCh38_dataset.zip \\\n    --include genome\n--include でファイルを指定。デフォルトは genomic.fna。 他に gtf, gff, cds, protein, rna など。 none を指定すると data report だけ取得する。\n\n\ncurl コマンドを使う方法\ncurl -OJ https://api.ncbi.nlm.nih.gov/datasets/v2alpha/genome/accession/GCF_000001405.40/download?include_annotation_type=GENOME_FASTA,GENOME_GFF,RNA_FASTA,CDS_FASTA,PROT_FASTA,SEQUENCE_REPORT\nunclude_annotation_type= でほしいファイルを指定する。",
    "crumbs": [
      "Bioinformatics",
      "ゲノムデータ取得"
    ]
  },
  {
    "objectID": "bio/fst_hands_on.html#概要",
    "href": "bio/fst_hands_on.html#概要",
    "title": "F_\\text{st} 解析ハンズオン — 候補遺伝子・SNPの抽出",
    "section": "概要",
    "text": "概要\n\n研究室内ハンズオンの HTML 版。 未公開データを使ったもののため、一部結果を非表示にしてあります。\n\n\n目標\n他サンプルをマージした VCF ファイルからスタートして、 F_\\text{st} のマンハッタンプロットとハプロタイプのヒートマップを描く。\n\n\n事前準備\n\n遺伝研スパコンのアカウントを作成し、 ログインできる状態にする。\n手元の PC に R の解析環境を用意する。\nNCBI から bGalGal1.mat.broiler.GRCg7b の Sequence Report をダウンロードする:\n\nhttps://www.ncbi.nlm.nih.gov/datasets/genome/GCF_016699485.2/ へ\nChromosomes までスクロールして Download から取得\n\n\n\n\n材料\n\n日本鶏1品種1サンプルの VCF ファイル\n\nファイルの名前は varsites.snponly.vcf.gz\n\n\n変異がある座位のみをコール。INDEL を除いた SNP のみの VCF。\n\n\n自分のディレクトリにインデックス (.csi) と一緒にコピーする:\n\n\n使うソフトウェア\n\nVCFtools\nBCFtools\nbedtools\n\nいずれも遺伝研ではデフォルトで使える。 他のバージョンのものが良ければ apptainer 越しに使う。\nvcftools --version\n# VCFtools (0.1.16)\nbcftools --version\n# bcftools 1.13\nbedtools --version\n# bedtools v2.30.0\n\n## or use via apptainer, e.g.\napptainer exec /usr/local/biotools/v/vcftools:0.1.16--h9a82719_5 vcftools --version\n# VCFtools (0.1.16)",
    "crumbs": [
      "Bioinformatics",
      "$F_\\text{st}$ 解析ハンズオン"
    ]
  },
  {
    "objectID": "bio/fst_hands_on.html#f_textst-を計算してマンハッタンプロットを描く",
    "href": "bio/fst_hands_on.html#f_textst-を計算してマンハッタンプロットを描く",
    "title": "F_\\text{st} 解析ハンズオン — 候補遺伝子・SNPの抽出",
    "section": "F_\\text{st} を計算してマンハッタンプロットを描く",
    "text": "F_\\text{st} を計算してマンハッタンプロットを描く\n軍鶏 vs 他品種で分化しているゲノム領域を特定する。 VCFtools を使う。\n\n遺伝研での作業なので、以降の操作はシェルスクリプト (.sh) を書いて qsub してもよい。 今回は便宜上、通常のコマンドラインで実行する形で説明する。\n\n毎回 VCF を指定するのは面倒なので変数に代入して ${vcf} で使う:\nvcf=YOUR_DIR/varsites.snponly.vcf.gz\n\n2集団のサンプル名を抽出する\nbcftools query と grep を組み合わせて軍鶏とそれ以外のサンプル名を それぞれテキストファイルに格納する:\n# 軍鶏はサンプル名に `SM` を含む。これと八木戸 `YKD` を抽出。\nbcftools query -l ${vcf} | grep -E 'SM|YKD' &gt; shamo.txt\nbcftools query -l ${vcf} | grep -v -E 'SM|YKD' &gt; non-shamo.txt\n\n\nF_\\text{st} を計算する\n2集団と window-size、window-step を指定して F_\\text{st} を計算する:\nvcftools --gzvcf ${vcf} --weir-fst-pop shamo.txt --weir-fst-pop non-shamo.txt \\\n  --fst-window-size 10000 --fst-window-step 5000 --out shamo_vs_other\n--out で指定した Prefix で .windowed.weir.fst と .log の2ファイルができる。\n\n\nマンハッタンプロットを描く\nここからローカルでの作業に移る。 shamo_vs_other.windowed.weir.fst を手元にダウンロードする。 これと事前準備3で取得した sequence_report.tsv を使う。\n\n\ndraw_manhattan_plot.R\n\n## パッケージのダウンロード\ninstall.packages(\"conflicted\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"qqman\")\n\n## パッケージの読み込み\nlibrary(conflicted)  # おまじない\nlibrary(tidyverse)   # データの操作用\nlibrary(qqman)       # マンハッタンプロット用\n\n## sequence_report.tsv を読み込む:\nacc2chr= readr::read_tsv(\"sequence_report.tsv\") |&gt;\n  dplyr::rename(CHROM = `RefSeq seq accession`, chr = `Chromosome name`) |&gt;  # 列名の変更\n  dplyr::select(CHROM, chr)                                                  # 染色体のaccessionと番号のみ抽出\n\n## shamo_vs_other.windowed.weir.fst を読み込む\nfst = readr::read_tsv(\"shamo_vs_other.windowed.weir.fst\") |&gt;\n  tibble::rownames_to_column(var = \"SNP\") |&gt;\n  dplyr::left_join(acc2chr, by = \"CHROM\") |&gt;\n  dplyr::mutate(chr = readr::parse_integer(chr, na = c(\"W\", \"Z\", \"Un\", \"MT\"))) |&gt;\n  dplyr::filter(!is.na(chr))\n\n## マンハッタンプロットの描画\nqqman::manhattan(\n  fst,\n  chr = \"chr\",\n  bp = \"BIN_START\",\n  p = \"WEIGHTED_FST\",  # or \"MEAN_FST\"\n  snp = \"SNP\",\n  col = c(\"#1f78b4\", \"#a6cee3\"),\n  logp = FALSE,\n  xlab = \"Chromosome\",\n  ylab = \"Fst\"\n)\n\nqqman::manhattan() はデフォルトでは PLINK の出力ファイルである BP 列、CHR 列、P 列、SNP 列をもつデータフレームを想定する。 これ以外のデータでマンハッタンプロットの描画をするときは、引数に列名などを指定していく。\n\nchr\n\n横軸の染色体番号\n\nbp\n\n各染色体上の SNP の座位\n\np\n\n縦軸の統計量。 デフォルトの想定は GWAS 等の P-value なので p になっている。\n\nsnp\n\n各 SNP の名前。典型的なのは rs123456 とか。\n\ncol\n\n染色体の色。今回は #1f78b4 ■ と #a6cee3 ■ を使ってみる。\n\nlogp\n\n縦軸 p を対数変換するかどうか。 今回は F_\\text{st} の生の値を使うので FALSE。\n\nxlab, ylab\n\n横軸、縦軸のラベル",
    "crumbs": [
      "Bioinformatics",
      "$F_\\text{st}$ 解析ハンズオン"
    ]
  },
  {
    "objectID": "bio/fst_hands_on.html#f_textst-の高い領域に含まれる遺伝子をリストする",
    "href": "bio/fst_hands_on.html#f_textst-の高い領域に含まれる遺伝子をリストする",
    "title": "F_\\text{st} 解析ハンズオン — 候補遺伝子・SNPの抽出",
    "section": "F_\\text{st} の高い領域に含まれる遺伝子をリストする",
    "text": "F_\\text{st} の高い領域に含まれる遺伝子をリストする\n\nbedtools による重なり抽出\nマンハッタンプロットをみて、いい感じに閾値を決める。 今回 F_\\text{st} &gt; 0.3 でやってみる。\nここでまた遺伝研に戻り、bedtools を使って F_\\text{st} の高い領域とオーバーラップする遺伝子をリストする。\nAWK コマンドで F_\\text{st} &gt; 0.3 の行を抽出:\nawk -F'\\t' '$5 &gt; 0.3' shamo_vs_other.windowed.weir.fst &gt; shamo_vs_other.03.fst\n\n.fst ファイルの5列目 ($5) が WEIGHTED_FST なので、これが 0.3 より大きい行を抽出する。 この作業自体はエクセルでやっても R でやってもいい。\n\nNCBI から bGalGal1.mat.broiler.GRCg7b の GTF をダウンロードする:\n\nhttps://www.ncbi.nlm.nih.gov/datasets/genome/GCF_016699485.2/ へ\nDownload から Annotation features (GTF) のみ選択してダウンロード\n手元に取得した genomic.gtf を遺伝研に送る\n\nこのまま使ってもいいけど、9列目の Attribute の情報が多すぎる。 今回は遺伝子ID (gene_id) さえあればいいので、ここだけ残したシンプルな GFF に変えておく:\n\n\nclean_gtf.py\n\nimport argparse\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-i\", \"--infile\")\n    parser.add_argument(\"-o\", \"--outfile\")\n    args = parser.parse_args()\n\n    gtf = clean_gtf(args.infile)\n    with open(args.outfile, \"w\") as f:\n        for l in gtf:\n            f.write(\"\\t\".join(l)+\"\\n\")\n\n\ndef clean_gtf(gtf):\n    new_lines = []\n    with open(gtf) as f:\n        for l in f:\n            if l[0] == \"#\":\n                new_lines.append([l.rstrip(\"\\n\")])\n            else:\n                l = l.rstrip(\"\\n\").split(\"\\t\")\n                l[-1] = extract_gene_from_gtf(l[-1])\n                new_lines.append(l)\n    return new_lines\n\n\ndef extract_gene_from_gtf(desc):\n    descs = desc.split(\"; \")\n    descs = {i.split(\" \")[0]: i.split(\" \")[1].strip('\"') for i in descs if \" \" in i}\n    gene = descs.get(\"gene_id\", \"NA\")\n    return gene\n\n\nif __name__ == \"__main__\":\n    main()\n\npython3 clean_gtf.py -i genomic.gtf -o simple.gtf\nbedtools intersect コマンドで、.fst と .gtf のオーバーラップする領域を抽出する:\nbedtools intersect -a shamo_vs_other.03.fst -b simple.gtf -wo &gt; shamo_vs_other.03.annot.fst\n\n\n再びマンハッタンプロットの描画\nshamo_vs_other.03.annot.fst を再び手元にダウンロードして R で可視化:\n\n\ndraw_manhattan_plot.R の続き\n\ncols= c(\"CHROM\", \"BIN_START\", \"BIN_END\", \"N_VARIANTS\", \"WEIGHTED_FST\", \"MEAN_FST\")\nfst2gene = readr::read_tsv(\"./shamo_vs_other.03.annot.fst\", col_names = cols) |&gt;\n  dplyr::rename(\"gene_id\" = X15) |&gt;\n  dplyr::distinct(BIN_START, gene_id, .keep_all = TRUE) |&gt;\n  group_by(CHROM, BIN_START) |&gt;\n  summarize(gene_id = paste(gene_id, collapse = \", \"))\n\n\nfst = fst |&gt; left_join(fst2gene, by = c(\"CHROM\", \"BIN_START\"))\n\nqqman::manhattan(\n  fst,\n  chr = \"chr\",\n  bp = \"BIN_START\",\n  p = \"WEIGHTED_FST\",  # or \"MEAN_FST\"\n  snp = \"gene_id\",\n  col = c(\"#1f78b4\", \"#a6cee3\"),\n  logp = FALSE,\n  xlab = \"Chromosome\",\n  ylab = \"Fst\",\n  annotatePval = 0.3,\n  annotateTop = FALSE\n)\n\n\nannotatePval\n\n縦軸がこの値以上の点の snp を表示する。\n\n\n今回は F_\\text{st} &gt; 0.3 でやっているので 0.3 を指定\n\nannotateTop\n\nTRUE だと各染色体の Top のみを表示する。\n\n\nいったん FALSE で全部表示してみて、重なりすぎてて見にくければ TRUE\n\n\n\n\n解釈\nこうして絞り込んだ遺伝子リストから、 さらにジェノタイピングやハプロタイプ解析に回す遺伝子を探していく。\n今回、2番染色体のピークに座上する ISPD は、 軍鶏を対象とした先行研究 (Luo et al. 2020, Bendesly et al. 2024) でも得られており、有力な候補と言える。\nこの後は、ISPD の周辺領域を抽出してハプロタイプ解析を行っていく。",
    "crumbs": [
      "Bioinformatics",
      "$F_\\text{st}$ 解析ハンズオン"
    ]
  },
  {
    "objectID": "bio/fst_hands_on.html#vcf-から候補遺伝子の周辺領域を抽出",
    "href": "bio/fst_hands_on.html#vcf-から候補遺伝子の周辺領域を抽出",
    "title": "F_\\text{st} 解析ハンズオン — 候補遺伝子・SNPの抽出",
    "section": "VCF から候補遺伝子の周辺領域を抽出",
    "text": "VCF から候補遺伝子の周辺領域を抽出\n前半の F_\\text{st} 解析で候補遺伝子で抽出した ISPD の周辺領域を SNP 単位で解析していく。\n\nISPD 領域\nNCBI で ISPD のページを見ると、 2番染色体 (NC_052533.1) の 28184591..28296806 にあるらしい。\nこの前後 5000bp を VCF から抽出する:\nvcf=YOUR_DIR/varsites.snponly.vcf.gz\n\nvcftools --gzvcf ${vcf} \\\n  --chr NC_052533.1 --from-bp $((28184591-5000)) --to-bp $((28296806+5000)) \\\n  --recode --out ISPD\n--chr で染色体 accession、--from-bp/--to-bp で座位を指定して VCF の特定領域を抽出する。 --out で指定した Prefix で、ISPD.recode.vcf が生成される。",
    "crumbs": [
      "Bioinformatics",
      "$F_\\text{st}$ 解析ハンズオン"
    ]
  },
  {
    "objectID": "bio/fst_hands_on.html#ハプロタイプ解析",
    "href": "bio/fst_hands_on.html#ハプロタイプ解析",
    "title": "F_\\text{st} 解析ハンズオン — 候補遺伝子・SNPの抽出",
    "section": "ハプロタイプ解析",
    "text": "ハプロタイプ解析\n抽出した ISPD 周辺領域の VCF を手元にダウンロードして、 R で読み込む。 全領域を可視化するとプロットが横に潰れるので、F_\\text{st} が特に高い領域に絞っておく:\n\n\ndraw_haplotype_plot.R\n\nlibrary(conflicted)\nlibrary(tidyverse)\n\nispd_vcf = readr::read_tsv(\"ISPD.recode.vcf\", comment = \"##\") |&gt;  # もしくは ISPD.snpEff.vcf\n  dplyr::filter(POS &gt;= 28200001 & POS &lt;= 28215000) |&gt;\n  tidyr::pivot_longer(\n    dplyr::starts_with(\"bam/\"),\n    names_to = \"sample\",\n    values_to = \"genotype\"\n  ) |&gt;\n  dplyr::mutate(\n    POS = as.character(POS),\n    sample = stringr::str_split(sample, \"/\", simplify = TRUE)[,2],\n    genotype = stringr::str_replace(genotype, \":.+\", \"\"),\n    FORMAT = \"GT\",\n    category = dplyr::if_else(stringr::str_detect(sample, \"SM|YKD\"), 1, 0),\n    sample = forcats::fct_reorder(sample, category)\n  )\n\n\n\\Delta Allele frequency の計算と可視化\n軍鶏とその他品種のアリル頻度の差を計算する。 ここは VCF の形式によって方法が異なる。 今回は bcftools mpileup | bcftools call --ploidy 2 でバリアントコールした形式を想定している。\nこの場合、あるアリルの遺伝子型が2本とも Reference と同じ (REF/REF) であれば 0/0、 ヘテロで SNP を持つ場合 (REF/ALT) 0/1、ホモで持つ場合 (ALT/ALT) 1/1 となる。\nALT 遺伝子型のアリル頻度を、0/0 = 0, 0/1 = 0.5, 1/1 = 1 としてその平均をとって計算する:\n\n\ndraw_haplotype_plot.R の続き\n\nispd_af = ispd_vcf |&gt;\n  dplyr::select(POS, sample, genotype, category) |&gt;\n  dplyr::mutate(\n    AF = dplyr::case_when(\n      genotype == \"1/1\" ~ 0,\n      genotype == \"0/1\" ~ 0.5,\n      .default = 1),\n    category = dplyr::if_else(category == 1, \"Shamo_AF\", \"Other_AF\")\n  ) |&gt;\n  dplyr::group_by(POS, category) |&gt;\n  dplyr::summarise(mean_AF = mean(AF)) |&gt;\n  tidyr::pivot_wider(names_from = category, values_from = mean_AF) |&gt;\n  dplyr::mutate(diff_AF = abs(Shamo_AF - Other_AF))\n\nこれを ggplot::geom_col() で可視化する:\n\n\ndraw_haplotype_plot.R の続き\n\nggplot2::ggplot(ispd_af) +\n  aes(x = POS, y = diff_AF) +                      # 横軸に座位、縦軸にアリル頻度の差\n  geom_col(fill =  \"#999999\") +                    # バープロットの描画\n  labs(x = \"POS\", y = \"delta allele frequency\") +  # x軸, y軸のタイトル\n  theme_classic() +                                # シンプルなテーマで\n  theme(\n    axis.text.x = element_blank(),                 # x軸のラベルはなくす\n    axis.ticks.x = element_blank()                 # x軸の ticks もなくす\n  )\n\n\n\nハプロタイプのヒートマップ描画\n続いて、各品種の遺伝子型をヒートマップ形式で可視化する。\n\n\ndraw_haplotype_plot.R の続き\n\nggplot2::ggplot(ispd_vcf) +\n  aes(x = POS, y = sample) +                    # 横軸に座位、縦軸にサンプル\n  geom_tile(aes(fill = genotype)) +             # タイルプロット。色分けはgenotypeで。\n  scale_fill_viridis_d(option = \"cividis\") +    # 色分けの色の指定\n  labs(x = \"POS\", y = \"\", fill = \"Genotype\") +  # x軸, y軸, 色分けのタイトル\n  theme_bw() +\n  theme(\n    axis.text.x = element_blank(),              # x軸のラベルはなくす\n    axis.ticks.x = element_blank(),             # x軸のticksもなくす\n  )\n\nこのようにしてアリル頻度の集団間差が特に大きい SNP を絞り込んでいく。 snpEff などを組み合わせれば、 その中でアミノ酸変異を伴うもの、といった絞り込みも可能。",
    "crumbs": [
      "Bioinformatics",
      "$F_\\text{st}$ 解析ハンズオン"
    ]
  },
  {
    "objectID": "bio/fst_hands_on.html#pbs-の計算",
    "href": "bio/fst_hands_on.html#pbs-の計算",
    "title": "F_\\text{st} 解析ハンズオン — 候補遺伝子・SNPの抽出",
    "section": "PBS の計算",
    "text": "PBS の計算\n\n原理\n2集団の F_\\text{st} では、得られるピークがどちらの集団のアリル頻度変化によるものかが区別できない。 そこで3集団目を追加し、F_\\text{st} を枝長とみなすことで特定の集団でアリル頻度が変化した領域を特定する手法が PBS (Population Branch Statistics) である。 (Yi et al. 2010)\n3集団 (A, B, C) のペアワイズで F_\\text{st} を算出して、各2集団間の枝長を求める:\n\nT = -\\log{(1-F_\\text{st})}\n\n各集団間の枝長を T_\\text{AB}, T_\\text{BC}, T_\\text{CA}, として、 例えば集団 A の PBS を求めたければ、次のようにする:\n\nPBS_\\text{A} = \\frac{T_\\text{AB} + T_\\text{CA} - T_\\text{BC} }{2}\n\n\n\nR で実装\nPBS を算出するソフトウェアはいくつかあるが (例えば scikit-allel や kpbs)、 ここでは VCFtools の出力を使って R で PBS を計算する。\nまず、3集団の総当たりで算出した F_\\text{st} を読み込む。 ここでは仮に pop1、pop2、pop3 とする:\n## パッケージの読み込み\nlibrary(conflicted)  # おまじない\nlibrary(tidyverse)   # データの操作用\n\n## sequence_report.tsv を読み込む:\nacc2chr= readr::read_tsv(\"sequence_report.tsv\") |&gt;\n  dplyr::rename(CHROM = `RefSeq seq accession`, chr = `Chromosome name`) |&gt;  # 列名の変更\n  dplyr::select(CHROM, chr)                                                  # 染色体のaccessionと番号のみ抽出\n\n## 3集団の総当たり Fst を読み込む\nfst_pop1_pop2 = readr::read_tsv(\"pop1_vs_pop2.windowed.weir.fst\") |&gt;\n  tibble::rownames_to_column(var = \"SNP\") |&gt;\n  dplyr::left_join(acc2chr, by = \"CHROM\") |&gt;\n  dplyr::mutate(chr = readr::parse_integer(chr, na = c(\"W\", \"Z\", \"Un\", \"MT\"))) |&gt;\n  dplyr::filter(!is.na(chr))\n\nfst_pop2_pop3 = readr::read_tsv(\"pop2_vs_pop3.windowed.weir.fst\") |&gt;\n  tibble::rownames_to_column(var = \"SNP\") |&gt;\n  dplyr::left_join(acc2chr, by = \"CHROM\") |&gt;\n  dplyr::mutate(chr = readr::parse_integer(chr, na = c(\"W\", \"Z\", \"Un\", \"MT\"))) |&gt;\n  dplyr::filter(!is.na(chr))\n\nfst_pop3_pop1 = readr::read_tsv(\"pop3_vs_pop1.windowed.weir.fst\") |&gt;\n  tibble::rownames_to_column(var = \"SNP\") |&gt;\n  dplyr::left_join(acc2chr, by = \"CHROM\") |&gt;\n  dplyr::mutate(chr = readr::parse_integer(chr, na = c(\"W\", \"Z\", \"Un\", \"MT\"))) |&gt;\n  dplyr::filter(!is.na(chr))\n次に F_\\text{st} を枝長に変換する:\nt_pop1_pop2 = fst_pop1_pop2 |&gt;\n  dplyr::mutate(t_pop1_pop2 = -log(1 - WEIGHTED_FST)) |&gt;\n  dplyr::select(CHROM, chr, BIN_START, BIN_END, t_pop1_pop2)\n\nt_pop2_pop3 = fst_pop2_pop3 |&gt;\n  dplyr::mutate(t_pop2_pop3 = -log(1 - WEIGHTED_FST)) |&gt;\n  dplyr::select(CHROM, chr, BIN_START, BIN_END, t_pop2_pop3)\n\nt_pop3_pop1 = fst_pop3_pop1 |&gt;\n  dplyr::mutate(t_pop3_pop1 = -log(1 - WEIGHTED_FST)) |&gt;\n  dplyr::select(CHROM, chr, BIN_START, BIN_END, t_pop3_pop1)\n最後にデータフレームを結合し、PBS を算出する。 ここでは例として pop1 における PBS を計算する。\n## 対象の集団が含まれる T 2つを足したものから対象の集団が含まれない T を引いて2で割る\n\ndf_pbs = t_pop1_pop2 |&gt;\n  dplyr::inner_join(t_pop2_pop3, by = c(\"CHROM\", \"chr\", \"BIN_START\", \"BIN_END\")) |&gt;\n  dplyr::inner_join(t_pop3_pop1, by = c(\"CHROM\", \"chr\", \"BIN_START\", \"BIN_END\")) |&gt;\n  dplyr::mutate(pbs_pop1 = (t_pop1_pop2 + t_pop3_pop1 - t_pop2_pop3)/2)",
    "crumbs": [
      "Bioinformatics",
      "$F_\\text{st}$ 解析ハンズオン"
    ]
  },
  {
    "objectID": "bio/ddbj.html",
    "href": "bio/ddbj.html",
    "title": "遺伝研スパコン",
    "section": "",
    "text": "https://sc.ddbj.nig.ac.jp/",
    "crumbs": [
      "Bioinformatics",
      "遺伝研スパコン"
    ]
  },
  {
    "objectID": "bio/ddbj.html#ログイン",
    "href": "bio/ddbj.html#ログイン",
    "title": "遺伝研スパコン",
    "section": "ログイン",
    "text": "ログイン\nユーザーアカウントを発行したら、 ssh 接続の設定をする。\n\nhttps://sc.ddbj.nig.ac.jp/application/ssh_keys\nhttps://sc.ddbj.nig.ac.jp/application/ssh_copy_id/\n\n\n\n~/.ssh/config\n\nHost ddbj\n  IdentityFile ~/.ssh/id_ed25519\n  Hostname gw.ddbj.nig.ac.jp\n  RequestTTY yes\n  User usename",
    "crumbs": [
      "Bioinformatics",
      "遺伝研スパコン"
    ]
  },
  {
    "objectID": "bio/ddbj.html#ジョブ実行",
    "href": "bio/ddbj.html#ジョブ実行",
    "title": "遺伝研スパコン",
    "section": "ジョブ実行",
    "text": "ジョブ実行\n\nhttps://sc.ddbj.nig.ac.jp/guides/software/JobScheduler/Slurm/\nhttps://slurm.schedmd.com/documentation.html\n\n\nインタラクティブジョブ\n\n暫定的に a001, a002, a003 の3つのインタラクティブノードが用意されている。 ゲートウェイノードへ ssh ログイン後、インタラクティブノードのいずれかに ssh ログインする:\n[youraccount@local ~]$ ssh username@gw.ddbj.nig.ac.jp\n[youraccount@gw ~]$ ssh a001\n[youraccount@a001 ~]$\n後日変わると思うので、公式サイトをチェック。\n\nsrun コマンドを用いてインタラクティブジョブ用の計算ノードを要求する:\nsrun --pty bash\nAGE でいう qlogin のイメージ。\n\n\nバッチジョブ\nsbatch コマンドを使う。 基本的な流れは AGE と同じで、ジョブスクリプトを書いて qbatch example.sh するだけ:\n\n\nexample.sh\n\n#!/bin/bash\n\n#SBATCH -t 0-00:10:00\n#SBATCH --mem-per-cpu 4G\n#SBATCH -J an_example\n\npwd\n\nジョブ実行時のオプション設定は #SBATCH で渡す。 sbatch のコマンドライン引数で渡してもいい。 AGE でいう #$ -cwd (カレントディレクトリの設定) と #$ -V (環境変数の引継ぎ) は、Slurm ではデフォルトらしい。\nインタープリタの指定オプションはない (?) ので、shebang で指定する必要がある: #!/bin/bash, #!/bin/csh, #!/use/bin/python\n使いそうなオプション:\n\n-b, --bigin\n\nジョブの実行割り当て開始時間を指定するする。\n\n-D, --chdir\n\nバッチジョブのワーキングディレクトリを指定。 (デフォルトはカレントディレクトリ。)\n\n-c, --cpus-per-tasks\n\n複数のタスクがあるときに、タスクあたりに必要な CPU の数を指定する。\n\n-o, --output\n\n標準出力の出力先をファイル名で指定する。 デフォルトでは slurm-[JOBID]_[JOBインデックス].out に吐き出される。\n\n-e, --error\n\n標準エラーの出力先をファイル名で指定する。 デフォルトでは標準出力と同じファイルで、なにも指定しなければ slurm-[JOBID]_[JOBインデックス].out に吐き出される。\n\n-i, --input\n\nバッチジョブの標準入力。\n\n--export\n\nジョブに渡す環境変数を制御する。\n\n-J, --job-name\n\nジョブの名前。デフォルトではスクリプトのファイル名になる。\n\n--mem\n\nノードごとに必要なメモリの指定。単位は K, M, G, T を使う。(デフォルトは M)\n\n--mem-per-cpu\n\nCPU あたりに必要なメモリ量の指定。\n\n\nバッチジョブで使うのは1ノード1コアなので、--mem でも同じ。\n\n-t, --time\n\nジョブの実行時間を指定する。 デフォルトの単位は “minutes” で、他に “minutes:seconds”, “hours:minutes:seconds”, “days-hours”, “days-hours:minutes”, “days-hours:minutes:seconds” の形式で指定できる。\n\n\n\n\nアレイジョブ\n-a で制御する。 SLURM_ARRAY_TASK_ID, SLURM_ARRAY_TASK_COUNT などの変数を参照可能。\n例えば6個の SRA データを同時に取得する場合:\n#!/bin/bash\n\n#SBATCH -a 1-6\n\nseq_ids=(SRR030253 SRR030254 SRR030255 SRR030256 SRR030257 SRR030258)\nseq_id=${seq_ids[$SLURM_ARRAY_TASK_ID-1]}\n\nprefetch ${seq_id}\n一度に投入されるタスク数の上限は % で制御する。 (AGE でいう -tc):\n#SBATCH -a 1-1000%100  # 1から1000までの並列。同時に走る上限は100。\n\n\nパラレルジョブ\nhttps://slurm.schedmd.com/mc_support.html\nSlurm には AGE でいうパラレルジョブに直接該当する機能はない。 --nodes, --ntasks, --ntasks-per-node などを使って並列ジョブを制御する。\n\n-N, --nodes\n\nジョブに割り当てるノードの数を指定する。[最小-最大] の範囲指定も可。\n\n--spread-job\n\nジョブの割り当てをできるだけ多くのノードに均等に分散させる。\n\n-n, --ntasks\n\nジョブに割り当てる CPU コアの数を指定する。\n\n\n# 例\n#!/bin/bash\n#SBATCH --nodes 1-1\n#SBATCH --ntasks 5\n#SBATCH --mem-per-cpu 4G\n\northofinder -f ExampleData -a 5\n\nこの時ノード全体では、4G×5core=20G のメモリを使う。\n\n\n\nその他のコマンド\n\nsqueue\n\nジョブの状況を確認 (i.e. qstat)\n\nscancel [JOBID]\n\n実行中のジョブをキャンセルする (i.e. qdel)\n\nscontrol\n\nジョブの設定変更",
    "crumbs": [
      "Bioinformatics",
      "遺伝研スパコン"
    ]
  },
  {
    "objectID": "bio/ddbj.html#apptainer-singularity",
    "href": "bio/ddbj.html#apptainer-singularity",
    "title": "遺伝研スパコン",
    "section": "Apptainer (Singularity)",
    "text": "Apptainer (Singularity)\n\nhttps://sc.ddbj.nig.ac.jp/guides/software/Container/Apptainer/\nhttps://sc.ddbj.nig.ac.jp/guides/software/Container/BioContainers/\n\nバイオインフォマティクスでよく使われる解析ツールは各ソフトウェアの頭文字ごとに /usr/local/biotools/ に配置されており、インストール不要で使うことができる。\n複数のバージョン用意されている場合もある。 たとえば:\nls /usr/local/biotools/s/samtools*\n使用例:\napptainer exec /usr/local/biotools/s/samtools",
    "crumbs": [
      "Bioinformatics",
      "遺伝研スパコン"
    ]
  },
  {
    "objectID": "bio/ddbj.html#grid-engine-と-slurm-の対応",
    "href": "bio/ddbj.html#grid-engine-と-slurm-の対応",
    "title": "遺伝研スパコン",
    "section": "Grid Engine と Slurm の対応",
    "text": "Grid Engine と Slurm の対応\n\nコマンド\n\nqsub -&gt; sbatch\nqstat -&gt; squeue\nqdel -&gt; scancel\n\n\n\nオプション\nAGE:                   -&gt; Slurm:\n\n#!/bin/bash             | #!/bin/bash\n#$ -S /bin/bash         | #  Shebang でよい?\n#$ -cwd                 | #  デフォルトでカレントディレクトリ\n#$ -V                   | #  デフォルトで環境変数をすべて引き継ぐ\n#$ -l short             | #SBATCH -p &lt;partition&gt;\n#$ -l d_rt=00:10:00     | #SBATCH -t 0-00:10:00\n#$ -l s_rt=00:10:00     |\n#$ -l s_vmem=4G         | #SBATCH --mem-per-cpu 4G\n#$ -l mem_req=4G        |",
    "crumbs": [
      "Bioinformatics",
      "遺伝研スパコン"
    ]
  },
  {
    "objectID": "bio/cafe5.html",
    "href": "bio/cafe5.html",
    "title": "CAFE5 — 遺伝子ファミリーの進化解析",
    "section": "",
    "text": "CAFE のメジャーアップデート版。\nドキュメントが丁寧に書いてあるので基本的には読めば OK。",
    "crumbs": [
      "Bioinformatics",
      "CAFE5"
    ]
  },
  {
    "objectID": "bio/cafe5.html#新しい機能",
    "href": "bio/cafe5.html#新しい機能",
    "title": "CAFE5 — 遺伝子ファミリーの進化解析",
    "section": "新しい機能",
    "text": "新しい機能\n\n各遺伝子ファミリーが異なる速度で進化することを仮定したパラメータ推定を行う。\nシェルスクリプトを書く必要がなくなった。\nエラーモデルの最適化やサマリーテーブルの出力が内部で行われるようになった。 (Python スクリプトが不要になった。)",
    "crumbs": [
      "Bioinformatics",
      "CAFE5"
    ]
  },
  {
    "objectID": "bio/cafe5.html#インストール",
    "href": "bio/cafe5.html#インストール",
    "title": "CAFE5 — 遺伝子ファミリーの進化解析",
    "section": "インストール",
    "text": "インストール\n\nDownload\n\nhttps://github.com/hahnlab/CAFE5/releases から\nまたは、git clone https://github.com/hahnlab/CAFE5.git\n\n\n\nCompile\ncd CAFE5\n./configure\nmake\n実行ファイルは CAFE5/bin/ にあるので、ここに PATH を通す。\n\nmacOS の場合\nsrc/matrix_cache.cpp:2:10: fatal error: 'omp.h' file not found などコンパイラが見つからない系のエラーが出る場合があるらしい。 gcc を入れてシンボリックリンクを張る:\nbrew install gcc\nfind / -name omp.h\nln -sv path/to/omp.h /usr/local/include/\n改めて、\nmake\n\n\n\n遺伝研\napptainer にあるものを使うのが楽:\nls /usr/local/biotools/c/cafe:5*",
    "crumbs": [
      "Bioinformatics",
      "CAFE5"
    ]
  },
  {
    "objectID": "bio/cafe5.html#quick-start",
    "href": "bio/cafe5.html#quick-start",
    "title": "CAFE5 — 遺伝子ファミリーの進化解析",
    "section": "Quick Start",
    "text": "Quick Start\n\nInput\n基本的に必要なファイルは以前の CAFE と同じ。\n\n種ごと、遺伝子ファミリーごとの遺伝子数のテーブル(タブ区切り)。 OrthoFinder とか OrthoMCL とかでつくる。\n\n\ngene_families.txt\n\nDescription ID  Chicken Lizard  Mouse\nOG00001 OG00001 12  14  21\nOG00002 OG00002 9   13  5\nOG00003 OG00003 7   0   4\n\nNewick 形式の系統樹。binary, rooted, ultrametric である必要がある。 (cf. Rパッケージ ape::is.binary(), ape::is.rooted(), ape::is.ultrametric())\n\n\nspecies_tree.txt\n\n(Mouse:319.00000000,(Lizard:281.10000000,Chicken:281.10000000):37.90000000);\n\n\n\n\nCAFE5 の実行\n想定するシナリオにより、いくつかの実行方法がある:\n\n遺伝子ファミリー間で進化速度が一定であるという仮定の下で、遺伝子ファミリーの進化速度を推定:\ncafe5 -i gene_families.txt -t species_tree.txt\n遺伝子ファミリーごとの進化速度が異なるという仮定の下で、遺伝子ファミリーの進化速度を推定:\ncafe5 -i gene_families.txt -t species_tree.txt -k 3\n特定の系統で遺伝子ファミリーの進化速度が異なることを仮定する場合、 以前のバージョンと同じように \\lambda 構造を規定した Newick ファイルを用意する:\n\n\nlambda_structure.txt\n\n(Mouse:1,(Lizard:1,Chicken:2):1);  # Chickenの系統で進化速度が異なることを仮定。\n\ncafe5 -i gene_families.txt -t species_tree.txt -y lambda_structure.txt",
    "crumbs": [
      "Bioinformatics",
      "CAFE5"
    ]
  },
  {
    "objectID": "bio/cafe5.html#出力ファイル",
    "href": "bio/cafe5.html#出力ファイル",
    "title": "CAFE5 — 遺伝子ファミリーの進化解析",
    "section": "出力ファイル",
    "text": "出力ファイル\n-o で出力先を指定。 指定しなくても実行ディレクトリに result/ ディレクトリが作られてその中に格納される。\n\nmodel_asr.tre\n\n各遺伝子ファミリーごとに再構成された系統樹が書かれている。\n\n\nノード名 + _ に続く形でそのノードでの推定遺伝子数が書かれており、 有意な増減があったノードには * がふってある。\n\nmodel_family_results.txt\n\n遺伝子ファミリー、P 値、変化が有意であるかどうか (y/n) がタブ区切りで記述されている。\n\nmodel_clade_results.txt\n\n各ノードごとに遺伝子数が増加/減少したファミリーの数が書いてある。\n\nmodel_branch_probabilities.txt\n\n各ノード、各遺伝子ファミリーにおける事後確率のタブ区切りリスト\n\n\nガンマモデルの場合、有意な変化があったファミリーについてのみ書かれている。\n\nmodel_family_likelihoods.txt\n\nBase モデルでは各ファミリーごとの尤度\n\n\nGamma モデルではそれに加えて事後確率がタブ区切りで書かれている。\n\nmodel_result.txt\n\n選択されたモデルの名前、そのモデルの最終的な尤度、 遺伝子数の進化速度にあたる \\lambda などが書かれている。\n\nmodel_change.txt\n\n各遺伝子ファミリーについて、各ノードにおける親ノードからの遺伝子数の変化量が書いてある。\n\nmodel_count.txt\n\n各遺伝子ファミリーについて、各ノードにおける推定遺伝子数\n\n\n\nRapidly evolving gene famillies について\nCAFE は確率的誕生-死亡モデルの下で、 ある \\lambda 値 (単位時間当たりの遺伝子の増減) にしたがって インプットした系統樹上で遺伝子の増減をシミュレートする。\nその結果各遺伝子ファミリーの実際の遺伝子数が得られる確率が P 値として得られる。 この P 値が事前に定めた有意水準 (例えば0.05) を下回ったものが rapidly expanded/contracted gene families として得られる。",
    "crumbs": [
      "Bioinformatics",
      "CAFE5"
    ]
  },
  {
    "objectID": "bio/cafe5.html#並列化",
    "href": "bio/cafe5.html#並列化",
    "title": "CAFE5 — 遺伝子ファミリーの進化解析",
    "section": "並列化",
    "text": "並列化\n--cores オプションで指定:\ncafe5 -i gene_families.txt -t species_tree.txt --cores 5",
    "crumbs": [
      "Bioinformatics",
      "CAFE5"
    ]
  },
  {
    "objectID": "bio/cafe5.html#トラブルシューティング",
    "href": "bio/cafe5.html#トラブルシューティング",
    "title": "CAFE5 — 遺伝子ファミリーの進化解析",
    "section": "トラブルシューティング",
    "text": "トラブルシューティング\nCAFE4 のトラブルシューティングも参照。\n\n既知の問題\nOG0000001    1    2    94    1    3    2    1\nみたいに遺伝子数にとびぬけた値があると、計算が途中で止まる。 (CAFE4 のときは inf/-inf で押し通していた。)\n標準エラーでどの遺伝子ファミリーが原因か教えてくれるので、そのファミリーを除いて再解析する。",
    "crumbs": [
      "Bioinformatics",
      "CAFE5"
    ]
  },
  {
    "objectID": "archive/gollum.html",
    "href": "archive/gollum.html",
    "title": "Gollum",
    "section": "",
    "text": "Linux サーバーに gollum で wiki を立てたときの奮闘記。"
  },
  {
    "objectID": "archive/gollum.html#開発",
    "href": "archive/gollum.html#開発",
    "title": "Gollum",
    "section": "開発",
    "text": "開発\n\n開発環境\nMacOS Ventura 13.3.1\nbrew --version  # Homebrew 4.0.19\nwhich -a ruby   # /usr/bin/ruby\nruby --version  # ruby 2.6.10p210\n\n\nGollumのインストール\n\nhomebrewでrbenvをインストール\nbrew install rbenv\n最新版(安定版？)のrubyを探してインストール\nrbenv install -l\nrbenv install 3.2.2\nrbenv global 3.2.2\nrbenv init\neval \"$(rbenv init - zsh)\"  # ~/.zshrcにも記載\nWiki用のリポジトリを作って空コミット\nmkdir mywiki && cd mywiki\ngit init\ngit commit --allow-empty -m \":coffee: Create Wiki\"\nGemfile を作成して以下を記載し、コミット\nsource 'https://rubygems.org'\ngem 'commonmarker'\ngem 'gollum'\ngit add Gemfile\ngit commit -m \":sparkles: Create Gemfile\"\nここでFork版のgollumを使うように設定できるらしいが、ひとまずそのまま使ってみる。\nbundle で Gemfile を読んでパッケージを依存関係ごとインストール\nbundle install  # --localしようとしたがcommonmarkerが入らなかった\nサーバーを起動して localhost:4567 で起動確認\nbundle exec gollum"
  },
  {
    "objectID": "archive/gollum.html#設定",
    "href": "archive/gollum.html#設定",
    "title": "Gollum",
    "section": "設定",
    "text": "設定\n\n基本\n大体の設定を記述するファイルは config.rb。 まず以下のように記載して、-c で読み込んで起動。\n\n\nconfig.rb\n\nrequire 'gollum/app'\n\nwiki_options = {\n  page_file_dir: 'source',\n  css: true,\n  mathjax: false,\n  emoji: true\n}\nPrecious::App.set(:wiki_options, wiki_options)\n\nbundle exec gollum -c config.rb\n試しに localhost:4567 で閲覧して、新しいページを作ってみる:\n## Hello Freesia!\nThis is the home of mywiki on `freesia`.\n一度終了してもう一度起動すると、ちゃんとさっき作ったページが表示されている。\n\nこのmarkdownはどこにある？working directoryには見えていないけど git が追跡しているっぽい。\n手元に main ブランチと別に master ブランチが生成されていてそこにファイルがある。 (後述するが最初から master ブランチで運用した方が事故は少なそう。)\n\n\n\nBASIC認証によるパスワード設定\nconfig.rb に以下の設定を追記:\n\n\nconfig.rb\n\nmodule Precious\n  class App &lt; Sinatra::Base\n    use Rack::Auth::Basic, 'Private Wiki' do |username, password|\n      users = File.open(File.expand_path('users.json', __dir__)) do |file|\n        JSON.parse(file.read, symbolize_names: true)\n      end\n      name = username.to_sym\n      digested = Digest::SHA256.hexdigest(password)\n      if users.key?(name) && digested == users[name][:password]\n        Precious::App.set(:author, users[name])\n      end\n    end\n\n    before do\n      session['gollum.author'] = settings.author\n    end\n  end\nend\n\nユーザー情報を users.json に分離して config.rb と同じところに置いておく:\n\n\nusers.json\n\n{\n  \"user1\": {\n    \"name\": \"First User\",\n    \"email\": \"user1@example.com\",\n    \"password\": \"0b14d501a594442a01c6859541bcb3e8164d183d32937b851835442f69d5c94e\"\n    }\n}\n\necho -n \"your_password\" | sha256sum したものを”password”に渡す。 (c.f. brew install coreutils )\nログインウィンドウでは、ユーザー名に”user1”、パスワードに”your_password”を指定する。"
  },
  {
    "objectID": "archive/gollum.html#本番環境へのデプロイ-トラブルシューティングしながら",
    "href": "archive/gollum.html#本番環境へのデプロイ-トラブルシューティングしながら",
    "title": "Gollum",
    "section": "本番環境へのデプロイ (トラブルシューティングしながら)",
    "text": "本番環境へのデプロイ (トラブルシューティングしながら)\n\n本番環境\nUbuntu 22.04.2 LTS\nsudo apt update\nsudo apt install autoconf bison build-essential libssl-dev libyaml-dev libreadline-dev zlib1g-dev libncurses5-dev libffi-dev libgdbm6 libgdbm-dev coreutils\nWebサーバ Apache も入れておく:\nsudo apt install apache2\nrubyの環境を整える:\nbrew install rbenv\nrbenv install -l\nrbenv install 3.2.2\nで、rubyインストールをしようと思ったけど、 ちゃんと入れたはずの libssl-dev で怒られてrubyが入らない。\nrbenv install 3.2.2\n# To follow progress, use 'tail -f /tmp/ruby-build.20230528012904.22847.log' or pass --verbose\n# Downloading ruby-3.2.2.tar.gz...\n# -&gt; https://cache.ruby-lang.org/pub/ruby/3.2/ruby-3.2.2.tar.gz\n# Installing ruby-3.2.2...\n# ruby-build: using readline from homebrew\n# ruby-build: using libyaml from homebrew\n#\n# BUILD FAILED (Ubuntu 22.04 using ruby-build 20230512)\n#\n# Inspect or clean up the working tree at /tmp/ruby-build.20230528012904.22847.wqiJdk\n# Results logged to /tmp/ruby-build.20230528012904.22847.log\n#\n# Last 10 log lines:\n# ERROR: Ruby install aborted due to missing extensions\n# Try running `apt-get install -y libssl-dev` to fetch missing dependencies.\n#\n# Configure options used:\n#   --prefix=/home/ymat2/.rbenv/versions/3.2.2\n#   --enable-shared\n#   --with-readline-dir=/home/linuxbrew/.linuxbrew/opt/readline\n#   --with-libyaml-dir=/home/linuxbrew/.linuxbrew/opt/libyaml\n#   LDFLAGS=-L/home/ymat2/.rbenv/versions/3.2.2/lib\n#   CPPFLAGS=-I/home/ymat2/.rbenv/versions/3.2.2/include\n仕方ないのでhomebrewで入れることに。 (後述するが非推奨のやりかた。あとで rbenv で入れなおした。)\nbrew info ruby\nbrew install ruby\n\n\nリポジトリのクローンとテスト\ngit clone mywiki && cd mywiki\nbundle install\nrugged のインストールでこける。 この記事を参考に、\nbrew reinstall gcc\nbrew install cmake\n再度 bundle install で依存関係ごとgollumを入れる。\nbundle exec gollum -c config.rb\n\n\nsystemd で自動的に開始\nsudo nano /etc/systemd/system/gollum.service\n[Unit]\nDescription=Gollum wiki server\nAfter=network.target\n\n[Service]\nType=simple\nUser=MYNAME\nWorkingDirectory=/path/to/your/labwiki\nExecStart=/home/linuxbrew/.linuxbrew/lib/ruby/gems/3.2.0/bin/bundle exec gollum -c config.rb -b /wiki --allow-uploads dir\nRestart=on-abort\nStandardOutput=file:/var/log/gollum.log\nStandardError=file:/var/log/gollum.log\n\n[Install]\nWantedBy=multi-user.target\nsudo systemctl start gollum.service\nsudo systemctl enable gollum.service\nhomebrew で入れた ruby を使ったせいか、bundle はフルパスを指定しないと動かない。\nhttp://freesia.net:4567 でアクセス。\n\n\nポート番号なしでアクセス\n:4567 で動いているのを :80/wiki に転送する。\n\nApacheの設定ファイル /etc/apache2/sites-available/gollum-wiki.conf をつくる。\n\n\n/etc/apache2/sites-available/gollum-wiki.conf\n\nProxyRequests Off\n&lt;Proxy *&gt;\n  Order deny,allow\n  Allow from all\n&lt;/Proxy&gt;\n&lt;Location /wiki&gt;\n  ProxyPass http://localhost:4567/wiki\n  ProxyPassReverse http://localhost:4567/wiki\n&lt;/Location&gt;\n\nつくった設定ファイルを有効化してApacheを再起動する。\nsudo a2ensite gollum-wiki.conf\nsudo systemctl restart apache2\napache2が再起動しない。Proxyが機能していない？\nsudo systemctl restart apache2\n# Job for apache2.service failed because the control process exited with error code.\n# See \"systemctl status apache2.service\" and \"journalctl -xeu apache2.service\" for details.\n\nsystemctl status apache2.service\n# × apache2.service - The Apache HTTP Server\n#     Loaded: loaded (/lib/systemd/system/apache2.service; enabled; vendor preset: enabled)\n#     Active: failed (Result: exit-code) since Mon 2023-05-29 05:39:49 EDT; 8s ago\n#       Docs: https://httpd.apache.org/docs/2.4/\n#     Process: 1821 ExecStart=/usr/sbin/apachectl start (code=exited, status=1/FAILURE)\n#         CPU: 14ms\n\n# May 29 05:39:49 Freesia systemd[1]: Starting The Apache HTTP Server...\n# May 29 05:39:49 Freesia systemd[1]: apache2.service: Control process exited, code=exited, status=1/FAILURE\n# May 29 05:39:49 Freesia systemd[1]: apache2.service: Failed with result 'exit-code'.\n# May 29 05:39:49 Freesia systemd[1]: Failed to start The Apache HTTP Server.\n# May 29 05:39:49 Freesia apachectl[1824]: AH00526: Syntax error on line 1 of /etc/apache2/sites-enabled/gollum-wiki.conf:\n# May 29 05:39:49 Freesia apachectl[1824]: Invalid command 'ProxyRequests', perhaps misspelled or defined by a module not included in the server configuration\n# May 29 05:39:49 Freesia apachectl[1821]: Action 'start' failed.\n# May 29 05:39:49 Freesia apachectl[1821]: The Apache error log may have more information.\nsudo a2enmod proxy して再度 sudo systemctl restart apache2\nInternal Server Error\nhttp://freesia.net/wiki にアクセスするとサーバー内部のエラーとのことで、エラーログを見てみる:\nless /var/log/apache2/error.log\n[Mon May 29 05:43:03.180681 2023] [proxy:warn] [pid 1886:tid 140102133675584] [client 10.33.25.141:62101]\nAH01144: No protocol handler was valid for the URL /wiki (scheme 'http').\nIf you are using a DSO version of mod_proxy, make sure the proxy submodules are included in the configuration using LoadModule.\nsudo a2enmod proxy_http して再度 sudo systemctl restart apache2\nhttp://freesia.net/wiki でアクセスできることを確認\n\n\n\nrbenv で入るrubyを使う\nhomebrew で ruby を入れると、bundle をフルパス指定しなければいけないうえに、 アップデートの度にバージョンが変わって使いづらい。\n最新版の ruby が入らないのはおそらく openssl の問題のよう。 homebrew で入れた openssl には 1.1.1 と 3.1.0 があって、rbenv が参照しているのは前者っぽい。\nrbenv でインストールする ruby のバージョンを落としてみる:\nrbenv install 3.0.6\n入った。念のため homebrew の ruby は消してバージョンを反映:\nbrew uninstall ruby\nrbenv global 3.0.6\neval \"$(rbenv init - zsh)\"  # .bash_localへ\nrbenv 版の ruby を使って wiki 再設定:\ncd /path/to/wiki\nbundle install\nいったん gollum-wiki を停止:\nsudo systemctl stop gollum.service\n設定ファイル /etc/systemd/system/gollum.service を書き換える。\n\nbundle だけでは同じく認識してくれなかった。\nrbenv で入れた bundle へのフルパスを書いて解決。 バージョン番号が入っていない点で及第点とするか。\n\n[Unit]\nDescription=Gollum wiki server\nAfter=network.target\n\n[Service]\nType=simple\nUser=ymat2\nWorkingDirectory=/home/ymat2/Desktop/project/mywiki\nExecStart=/home/ymat2/.rbenv/shims/bundle exec gollum -c config.rb -b /wiki --allow-uploads dir\nRestart=on-abort\nStandardOutput=file:/var/log/gollum.log\nStandardError=file:/var/log/gollum.log\n\n[Install]\nWantedBy=multi-user.target\ngollum-wiki を再起動:\nsudo systemctl daemon-reload\nsudo systemctl start gollum.service\n\n\nbranch を main で動くように調整しようとした\n\nhttps://zenn.dev/noid11/articles/9112566f0737a2c9f7b7\nhttps://github.com/gollum/gollum/issues/1813\n\ngollum はデフォルトでは master ブランチで動くようになっている。 なので main ブランチで動かしつつファイルをアップロードしたりするとわざわざ master ブランチが作られる。 これを main で動くように設定を変更する。\nrequire 'gollum/app'\n\nwiki_options = {\n  page_file_dir: 'source',\n  ref: main,\n  css: true,\n  mathjax: false,\n  emoji: true\n}\nPrecious::App.set(:wiki_options, wiki_options)\n動かん:\nsudo systemctl status gollum.service\n# × gollum.service - Gollum wiki server\n#      Loaded: loaded (/etc/systemd/system/gollum.service; enabled; vendor preset: enabled)\n#      Active: failed (Result: exit-code) since Wed 2023-05-31 02:34:19 EDT; 313ms ago\n#     Process: 28556 ExecStart=/home/ymat2/.rbenv/shims/bundle exec gollum -c config.rb -b /wiki --allow-uploads dir (code=exited, status=1/FAILURE)\n#    Main PID: 28556 (code=exited, status=1/FAILURE)\n#         CPU: 1.628s\n#\n# May 31 02:34:18 Freesia systemd[1]: Started Gollum wiki server.\n# May 31 02:34:19 Freesia systemd[1]: gollum.service: Main process exited, code=exited, status=1/FAILURE\n# May 31 02:34:19 Freesia systemd[1]: gollum.service: Failed with result 'exit-code'.\n# May 31 02:34:19 Freesia systemd[1]: gollum.service: Consumed 1.628s CPU time.\nコマンドラインオプションで渡してみる:\n[Unit]\nDescription=Gollum wiki server\nAfter=network.target\n\n[Service]\nType=simple\nUser=MYNAME\nWorkingDirectory=/path/to/your/labwiki\nExecStart=/home/linuxbrew/.linuxbrew/lib/ruby/gems/3.2.0/bin/bundle exec gollum -c config.rb -b /wiki --allow-uploads dir --ref main ./\nRestart=on-abort\nStandardOutput=file:/var/log/gollum.log\nStandardError=file:/var/log/gollum.log\n\n[Install]\nWantedBy=multi-user.target\n効かん:\nsudo systemctl status gollum.service\n# ● gollum.service - Gollum wiki server\n#      Loaded: loaded (/etc/systemd/system/gollum.service; enabled; vendor preset: enabled)\n#      Active: active (running) since Wed 2023-05-31 02:35:01 EDT; 19s ago\n#    Main PID: 28590 (ruby)\n#       Tasks: 1 (limit: 4284)\n#      Memory: 79.5M\n#         CPU: 1.640s\n#      CGroup: /system.slice/gollum.service\n#              └─28590 ruby -x /home/ymat2/.rbenv/versions/3.0.6/bin/gollum -c config.rb -b /wiki --allow-uploads dir\n#\n# May 31 02:35:01 Freesia systemd[1]: Started Gollum wiki server.\n# May 31 02:35:14 Freesia systemd[1]: gollum.service: Current command vanished from the unit file, execution of the command list won't be resumed.\nあきらめてブランチの名前を master に変更した。"
  },
  {
    "objectID": "archive/gollum.html#misc.",
    "href": "archive/gollum.html#misc.",
    "title": "Gollum",
    "section": "Misc.",
    "text": "Misc.\nrbenv は ruby のバージョン管理、bundle は ruby のパッケージ管理をしてくれる。\nGemfile は Ruby プロジェクトにおける依存関係を管理するファイル。 bundle が読む。"
  },
  {
    "objectID": "archive/cafe.html",
    "href": "archive/cafe.html",
    "title": "CAFE — 遺伝子ファミリーの進化解析",
    "section": "",
    "text": "Computational Analysis of gene Family Evolution\n遺伝子ファミリーサイズの進化（系統樹上のどのノードで、いくつ遺伝子が増減したか）を、 MCMC 法で推定するプログラム。\n基本的な動かし方は、入力となるシェルスクリプトを書いて CAFE に渡す、という形になる。 このシェルスクリプトを書く過程で、 OrthoFinder の出力である Orthogroups.GeneCount.tsv と 種の系統樹 (Species_Tree/SpeciesTree_rooted.txt) が必要。"
  },
  {
    "objectID": "archive/cafe.html#インストール",
    "href": "archive/cafe.html#インストール",
    "title": "CAFE — 遺伝子ファミリーの進化解析",
    "section": "インストール",
    "text": "インストール\n\n作者たちの github から最新版の CAFE をダウンロードして、 適当なディレクトリに置く。(例えば ~/bin/)\n解凍したら CAFE ディレクトリまで cd して configure & make:\ncd PATH_TO_CAFE\n./configure\nmake\nPATH を通して動作確認:\ncafe  # ctrl+C"
  },
  {
    "objectID": "archive/cafe.html#使い方",
    "href": "archive/cafe.html#使い方",
    "title": "CAFE — 遺伝子ファミリーの進化解析",
    "section": "使い方",
    "text": "使い方\n\nこんな感じのシェルスクリプトを書く\n\n\nexample.sh\n\n#! cafe\n# version\n# date\nload -i data/example.tab -t 10 -l logfile.txt -p 0.05\ntree (((chimp:6,human:6):81,(mouse:17,rat:17):70):6,dog:93)\nlambda -s -t (((1,1)1,(2,2)2)2,2)\nreport resultfile\n\n\nload\n\n基本的なオプション。\n\n\n-i 種/遺伝子ファミリーごとの遺伝子数のテーブル\n\n\n-t スレッド数。使っているコンピュータに合わせる。\n\n\n-l ログファイルの名前\n\n\n-p 遺伝子数の増減が急速であるとする有意水準\n\n\n-filter は全種の共通祖先における遺伝子数が0であると推定される遺伝子ファミリーを除くオプション。 これをつける場合は load 行より上に tree 行を書く。\n\ntree\n\nroot から各種までの距離が同じである (ultrametric) 系統樹。\n\nlambda\n\n単位時間あたりの遺伝子数の増減速度 \\lambda の設定\n\n\n\\lambda を指定する場合は -l、自動推定する場合は -s\n\n\n-t で \\lambda 構造を設定。 系統樹上の遺伝子増減速度が同じだと考えられる枝を同じ数字にする。 全枝で同じだと仮定する場合すべて1にする。 系統樹の枝長の部分を書き換えればいい。\n\nreport\n\n出力ファイルの名前\n\n\n\n\nインプットとなるテーブル (example.tab) を用意する\nOrthoFinder の出力である Orthogroups.GeneCount.tsv などを基に、 CAFE の入力ファイルとして加工する。基本的には、\n\nDescription 列、ID 列を作る。\n全種の遺伝子数が同じである遺伝子ファミリーを除く。\n1種の遺伝子数が100を超える遺伝子ファミリーを除く。\n\nを満たしていればどう作ってもいい。 例えば:\n\n\n\nDescription\nID\nChicken\nLizard\nMouse\n\n\n\n\nOG00001\nOG00001\n12\n14\n21\n\n\nOG00002\nOG00002\n9\n13\n5\n\n\nOG00003\nOG00003\n7\n0\n4\n\n\n\n\n\nultrametric な系統樹を用意する\nTimeTree などから取得すると楽。 OrthoFinder の出力系統樹を使う場合、遺伝的距離に基づく系統樹であるため、 ultrametric に加工する必要がある。\nR の ape などを使うと便利:\n## spAとspBが3.6~4.6億年前に分岐したという情報から全体の分岐年代を推定する。\n\nlibrary(ape)\n\ntree = read.tree(\"tree.txt\")\nmrca = getMRCA(tree, tip=c('spA', 'spB')) #分岐年代推定に使うノードの指定\ntree2 = chronopl(\n  tree,\n  100000,\n  age.min = 36,  # 推定分岐年代の最小値(MYA)\n  age.max = 46,  # 推定分岐年代の最大値(MYA)\n  node = mrca,   # getMRCAで指定したノード\n  S = 1,\n  tol = 1e-20,\n  CV = FALSE,\n  eval.max = 500,\n  iter.max = 500\n  )\nis.ultrametric(tree2)  # ultrametricかどうか確認\nwrite.tree(tree2, file = \"tree_ultrametric.nwk\")  # ultrametric系統樹の保存\n\n注意点\n\ntip は遺伝子数のテーブルの列名に合わせる。\n\n\nbootstrap などの余計な要素は消しておく。\n\n\n枝長は少数でも構わないが、1以上のできるだけ小さい枝長になるように約分する。 (大きすぎるとエラーになるっぽい。)\n\n\n\n\nCAFEを実行する\nシェルスクリプトが用意できたら、次のコマンドで CAFE を実行する。\ncafe example.sh\n\n\n出力ファイルを加工する\nCAFE の実行に成功すると、report で指定した名前の .rep ファイルが出てくる。 このままだと見づらいため、公式のスクリプトを使って加工する。\n\nhttps://github.com/hahnlab/cafe_tutorial に行き、コードをダウンロードして解凍する。 (Code▼ から。) report ファイルのあるディレクトリに置いておくと便利。\n次のコマンドで report ファイルを加工する。4つのファイルが出力される。\n\npython cafe_tutrial/python_scripts/cafetutorial_report_analysis.py -i resultfile.rep -o cafe_summary\n\n-i\n\nCAFE の出力ファイル。\n\n-o\n\n加工して生成されるファイル (4つ) の prefix。\n\n\n\ncafe_summary_fams.txt\ncafe_summary_anc.txt\ncafe_summary_pub.txt\ncafe_summary_node.txt"
  },
  {
    "objectID": "archive/cafe.html#トラブルシューティング",
    "href": "archive/cafe.html#トラブルシューティング",
    "title": "CAFE — 遺伝子ファミリーの進化解析",
    "section": "トラブルシューティング",
    "text": "トラブルシューティング\n\nFailed to load tree from provided string (branch length missing)\n\n系統樹の枝長に0が含まれているとダメ。自分は該当するノードを除外した。\n\nNo species ‘anolis_carolinensis’ was found in the tree\n\n系統樹を読み込む際に内部で tip name を書き換えているようで、 長すぎる種名やアンダースコアが原因と思われるエラー。 tip name を短く書き換える。 (Anolis_carolinensis -&gt; AnoCar とか)\n\nLambda values were not set. Please set lambda values with the lambda or lambdamu command.\n\n\\lambda を自動推定する際に、系統樹の枝長がでかい数字だとこうなるっぽい。 できるだけ短くなるように約分する？"
  },
  {
    "objectID": "archive/index.html",
    "href": "archive/index.html",
    "title": "Archived contents",
    "section": "",
    "text": "CAFE\n\n\nGollum\n\n\nNo matching items"
  },
  {
    "objectID": "bio/clusterProfiler.html",
    "href": "bio/clusterProfiler.html",
    "title": "clusterProfiler — R でエンリッチメント解析",
    "section": "",
    "text": "https://bioconductor.org/packages/release/bioc/html/clusterProfiler.html\nエンリッチメント解析には大きく二つの方法がある:",
    "crumbs": [
      "Bioinformatics",
      "clusterProfiler"
    ]
  },
  {
    "objectID": "bio/clusterProfiler.html#go-enrichment-analysis",
    "href": "bio/clusterProfiler.html#go-enrichment-analysis",
    "title": "clusterProfiler — R でエンリッチメント解析",
    "section": "GO enrichment analysis",
    "text": "GO enrichment analysis\n\nドキュメントページ\nGO とは\n\nGO (Gene Ontology) は、ある遺伝子がどんな機能を持っているかを共通の語彙でタグづけしたもの。 もっとも大きく分けて以下の3つの分類がある:\n\nBiological Process (BP)\n\n遺伝子産物がどんな生物学的機能やパスウェイに属するか\n\nCellular Component (CC)\n\n遺伝子産物が細胞内のどこに局在するか\n\nMolecular Function (MF)\n\n遺伝子産物が分子としてどういう機能をもつか\n\n\nGO の情報は別途ダウンロードする。例えばヒトなら:\nBiocManager::install(\"org.Hs.eg.db\")\nlibrary(org.Hs.eg.db)\n\nGO over-representation analysis\ndata(geneList, package = \"DOSE\")  # サンプルデータ\ngene = names(geneList)[abs(geneList) &gt; 2]\n\nego = enrichGO(\n  gene,\n  OrgDb = org.Hs.eg.db,\n  keyType = \"ENTREZID\",\n  ont = \"MF\",\n  pvalueCutoff = 0.05,\n  pAdjustMethod = \"BH\",\n  universe = geneList,\n  qvalueCutoff = 0.2,\n  minGSSize = 10,\n  maxGSSize = 500,\n  readable = FALSE,\n  pool = FALSE\n)\nego_result = ego@result\nView(ego_result)\n\nont\n\n\"BP\", \"CC\", \"MF\", \"ALL\" から選ぶ。\n\npvalueCutoff, qvalueCutoff\n\nそれぞれ与えた P 値、Q 値以下の GO を表示する。\n\n\nここで設定してもいいけど、ここはとりあえず 1 にしておいて、 ego@result を格納してから |&gt; dplyr::filter(qvalue &lt; 0.1) とかする方が柔軟では。\n\nuniverse\n\nバックグラウンドの遺伝子ベクタ\n\n\n指定しないときは OrgDb の全遺伝子が使われる。\n\nminGSSize, maxGSSize\n\nいくつ以上/以下の遺伝子が紐づく GO までを使う。\n\nreadable\n\nTRUE にすると ENTREZID を遺伝子シンボルに変換する。\n\n\n\n\nGO Gene Set Enrichment Analysis\ndata(geneList, package = \"DOSE\")\n# 渡す `geneList` はスコアの降順で並んでいる必要がある。\n\nego = gseGO(\n  geneList,\n  ont = \"BP\",\n  OrgDb = org.Hs.eg.db,\n  keyType = \"ENTREZID\",\n  exponent = 1,\n  minGSSize = 10,\n  maxGSSize = 500,\n  eps = 1e-10,\n  pvalueCutoff = 0.05,\n  pAdjustMethod = \"BH\",\n  verbose = TRUE,\n  seed = FALSE,\n  by = \"fgsea\",\n  scoreType = \"pos\"\n)\nego_result = ego@result\nView(ego_result)\n\nscoreType\n\n\"pos\" ならソートした上位、\"neg\" なら下位に濃縮する GO をみる。 (ドキュメントには載ってない？)",
    "crumbs": [
      "Bioinformatics",
      "clusterProfiler"
    ]
  },
  {
    "objectID": "bio/clusterProfiler.html#kegg-enrichment-analysis",
    "href": "bio/clusterProfiler.html#kegg-enrichment-analysis",
    "title": "clusterProfiler — R でエンリッチメント解析",
    "section": "KEGG enrichment analysis",
    "text": "KEGG enrichment analysis\n\nドキュメントページ\nKEGG とは\n\nKEGG (Kyoto Encyclopedia of Genes and Genomes) は、 主にモデル生物における遺伝子やタンパク質の分子間ネットワークに関する情報を体系化したデータベース。\n利用可能な生物種を探す:\nsearch_kegg_organism('hsa', by = 'kegg_code')\nsearch_kegg_organism('Homo sapiens', by = 'scientific_name')\nKEGG Organisms のページから探してもいい。\nGO エンリッチメント解析と同様に、 興味のある遺伝子/ない遺伝子で区切る解析 (over-representation) と、 なんらかのスコアに基づいてソートした時に上位に濃縮するパスウェイを調べる解析 (gene set enrichment) がサポートされている。\n\nKEGG pathway over-representation analysis\ndata(geneList, package = \"DOSE\")  # サンプルデータ\ngene &lt;- names(geneList)[abs(geneList) &gt; 2]\n\nkk &lt;- enrichKEGG(\n  gene,\n  organism = \"hsa\",\n  keyType = \"kegg\",\n  pvalueCutoff = 0.05,\n  pAdjustMethod = \"BH\",\n  universe = geneList,\n  minGSSize = 10,\n  maxGSSize = 500,\n  qvalueCutoff = 0.2,\n  use_internal_data = FALSE\n)\nkk_result = kk@result\nView(kk_result)\n\n\nKEGG pathway gene set enrichment analysis\ndata(geneList, package = \"DOSE\")\n\nkk &lt;- gseKEGG(\n  geneList,\n  organism = \"hsa\",\n  keyType = \"kegg\",\n  exponent = 1,\n  minGSSize = 10,\n  maxGSSize = 500,\n  eps = 1e-10,\n  pvalueCutoff = 0.05,\n  pAdjustMethod = \"BH\",\n  verbose = FALSE,\n  use_internal_data = FALSE,\n  seed = FALSE,\n  by = \"fgsea\",\n  scoreType = \"pos\"\n)\nkk_result = kk@result\nView(kk_result)",
    "crumbs": [
      "Bioinformatics",
      "clusterProfiler"
    ]
  },
  {
    "objectID": "bio/clusterProfiler.html#setreadable",
    "href": "bio/clusterProfiler.html#setreadable",
    "title": "clusterProfiler — R でエンリッチメント解析",
    "section": "setReadable",
    "text": "setReadable\nenrichGO() 以外の関数には readable オプションがない。\nENTREZID のままだとどの遺伝子か分かりにくい。 setReadable は org.Hs.eg.db とかから ID と gene_symbol の対応を取得して変換する。\nlibrary(org.Hs.eg.db)\nkk2 = kk |&gt; setReadable(OrgDb = org.Hs.eg.db, keyType = \"ENTREZID\")",
    "crumbs": [
      "Bioinformatics",
      "clusterProfiler"
    ]
  },
  {
    "objectID": "bio/clusterProfiler.html#可視化",
    "href": "bio/clusterProfiler.html#可視化",
    "title": "clusterProfiler — R でエンリッチメント解析",
    "section": "可視化",
    "text": "可視化\n\nhttps://yulab-smu.top/biomedical-knowledge-mining-book/enrichplot.html\nhttps://yulab-smu.top/biomedical-knowledge-mining-book/clusterprofiler-kegg.html#visualize-enriched-kegg-pathways\n\ndotplot(kk2, showCategory = 10, title = \"Enriched Pathways\" , split = \".sign\")\n# とか\ncnetplot(kk2, showCategory = 5, categorySize = \"pvalue\")\n# とか\nパスウェイの図が欲しければ pathview とか:\nlibrary(\"pathview\")\npathview(\n  gene.data = geneList,\n  pathway.id = \"hsa04110\",\n  species = \"hsa\",\n  limit = list(gene = max(abs(geneList)), cpd = 1)\n)",
    "crumbs": [
      "Bioinformatics",
      "clusterProfiler"
    ]
  },
  {
    "objectID": "bio/ete-toolkit.html",
    "href": "bio/ete-toolkit.html",
    "title": "ETE Toolkit — ete-evol による配列解析",
    "section": "",
    "text": "ETE Toolkit は系統樹データを扱うための Python フレームワーク。\nその中の ete-evol は CODEML や SLR の実行を手助けする Python 製コマンドラインツール。\nパッケージとして import して Python スクリプトの中で使うこともできる。",
    "crumbs": [
      "Bioinformatics",
      "ETE Toolkit"
    ]
  },
  {
    "objectID": "bio/ete-toolkit.html#installation",
    "href": "bio/ete-toolkit.html#installation",
    "title": "ETE Toolkit — ete-evol による配列解析",
    "section": "Installation",
    "text": "Installation\ncodeml と slr がインストールされて PATH が通っている必要がある。 (使わない方は入っていなくても解析はできる。)\n\nete4\n# pip3 install lap  # if needed\npip3 install https://github.com/etetoolkit/ete/archive/ete4.zip\n\n\nete3\nete-evol は外部ツールに依存するため、 conda を使ってインストールすることが推奨されている:\nconda create -n ete3 python=3\nconda activate ete3\nconda install -c etetoolkit ete3 ete_toolchain\nete3 build check\nconda activate ete3\nconda を介さないインストール:\npip3 install cython bottle brotli numpy scipy PyQt5\npip3 install ete3\nete3 upgrade-external-tools   # codeml, slrをここからインストールすることもできる\n\n\n遺伝研\nls /usr/local/biotools/e/ete*\n2023/09/11時点で ete2 と ete3 が利用可能。 でもちゃんと動かなそう？ (バージョンによるかも。)",
    "crumbs": [
      "Bioinformatics",
      "ETE Toolkit"
    ]
  },
  {
    "objectID": "bio/ete-toolkit.html#基本的な使い方",
    "href": "bio/ete-toolkit.html#基本的な使い方",
    "title": "ETE Toolkit — ete-evol による配列解析",
    "section": "基本的な使い方",
    "text": "基本的な使い方\nete3 evol -t tree_file --alg fasta_file -o outdir/ --models models --cpu N\n\n-t\n\n系統樹ファイルのパス\n\n--alg\n\nアライメントファイルのパス\n\n-o\n\n出力先ディレクトリ。この中にモデルの名前でサブディレクトリが作られる。\n\n--cpu\n\nコア数\n\n--models\n\n\n\n\nModel\nDescription\ntype\nCitation\n\n\n\n\nM0\nnegative-selection\nnull\nYang 2000\n\n\nM1\nrelaxation\nsite\n〃\n\n\nM2\npositive-selection\n〃\n〃\n\n\nM3\ndiscrete\n〃\n〃\n\n\nM4\nfrequencies\n〃\n〃\n\n\nM5\ngamma\n〃\n〃\n\n\nM6\n2 gamma\n〃\n〃\n\n\nM7\nrelaxation\n〃\n〃\n\n\nM8\npositive-selection\n〃\n〃\n\n\nM8a\nrelaxation\n〃\n〃\n\n\nM9\nbeta and gamma\n〃\n〃\n\n\nM10\nbeta and gamma + 1\n〃\n〃\n\n\nM11\nbeta and normal &gt; 1\n〃\n〃\n\n\nM12\n0 and 2 normal &gt; 2\n〃\n〃\n\n\nM13\n3 normal &gt; 0\n〃\n〃\n\n\nSLR\npositive/negative selection\n〃\nMassingham 2005\n\n\nbsA\npositive-selection\nbranch-site\nZhang 2005\n\n\nbsA1\nrelaxation\n〃\n〃\n\n\nbsB\npositive-selection\n〃\nYang 2002\n\n\nbsC\ndifferent-ratios\n〃\n〃\n\n\nbsD\ndifferent-ratios\n〃\nYang 2002, Bielawski 2004\n\n\nb_free\npositive-selection\nbranch\nYang 2002\n\n\nb_neut\nrelaxation\n〃\n〃\n\n\nfb\nfree-ratios\n〃\n〃\n\n\nfb_anc\nfree-ratios\n〃\n〃\n\n\n\n\n\n\nMarking trees\n--mark で指定する。スペースで繋ぐことで複数の指定もできる。 2種をカンマで繋ぐ。カンマ3つだと共通祖先からの全ての枝を、カンマ2つだと共通祖先の枝のみ。\n\n--mark Human_EDN,,,Hylobates_EDN,Macaq_EDN,,,Papio_EDN\n\n\n\n--mark Macaq_ECP,,Macaq2_ECP,Human_ECP,,Goril_ECP\n\n\n\n\n画像引用元: http://etetoolkit.org/documentation/ete-evol/\n\n\nTesting evolutionary models\n対立仮説と帰無仮説のモデルを --test に渡すことで仮説検定ができる。 例えば M2 vs M1 でサイトモデルの検定をするには、\nete3 evol -t tree_file --alg fasta_file --models M2 M1 --tests M2,M1 -o outdir/\nのように書く。\n対数尤度や p-value は標準出力されるので、 これらが欲しければリダイレクトして取っておく必要がある？ ( &gt; output.txt )\n\nモデルの組み合わせ\n\n\n\n対立仮説\n帰無仮説\n検定すること\n引用\n\n\n\n\nM2\nM1\n特定サイトにおける正の自然選択\nYang 2000\n\n\nM3\nM0\nサイト間でdN/dSが異なるか\n〃\n\n\nM8\nM7\n特定サイトにおける正の自然選択\nYang 2000\n\n\nM8\nM8a\n特定サイトにおける選択の緩和\n〃\n\n\nbsA\nbsA1\n特定の枝の特定のサイトにおける正の自然選択\nZhang 2005\n\n\nbsA\nM1\n特定の枝の特定のサイトにおける選択の緩和\nZhang 2005\n\n\nbsC\nM1\n特定のクレードの特定のサイトでdN/dSが異なるか\nYang 2002\n\n\nbsD\nM3\n特定のクレードの特定のサイトでdN/dSが異なるか\nYang 2002, Bielawski 2004\n\n\nb_free\nb_neut\n特定の枝でdN/dSが1と異なるか\nYang 2002\n\n\nb_free\nM0\n特定の枝でdN/dSが他と異なるか\nYang 2002\n\n\n\nb_free vs b_neut の検定は P 値とフォアグラウンド枝の \\omega = d_\\text{N} / d_\\text{S} の値によって複数の解釈がある。 (ここについてはドキュメントの記載が間違っている気もする。)\n\nP &gt; 0.05 の場合、Relaxed selection の可能性がある。 統計的に主張するには b_neut を対立仮説にして帰無仮説 b_free を棄却する必要あり？\nP &lt; 0.05, ω &lt; 1 の場合、フォアグラウンド枝でのより強い純化選択の可能性がある。 統計的に主張するには b_free vs M0 で \\omega の比較が必要？\nP &lt; 0.05, ω &gt; 1 の場合、正の自然選択を主張できる。",
    "crumbs": [
      "Bioinformatics",
      "ETE Toolkit"
    ]
  },
  {
    "objectID": "bio/gwas.html",
    "href": "bio/gwas.html",
    "title": "GWAS — Genome Wide Association Study",
    "section": "",
    "text": "疾患や特定の表現型などと統計的に相関する遺伝子変異を網羅的に探索する手法。\n最近のレビュー: Uffelmann et al. 2021",
    "crumbs": [
      "Bioinformatics",
      "GWAS"
    ]
  },
  {
    "objectID": "bio/gwas.html#softwares",
    "href": "bio/gwas.html#softwares",
    "title": "GWAS — Genome Wide Association Study",
    "section": "Softwares",
    "text": "Softwares\nよく使われる GWAS ソフトウェアとして PLINK と GCTA があるが、今回は PLINK を使う。 バイナリ版のダウンロードページはこちら。\n遺伝研スパコンで使う場合、Apptainer にある:\nls /usr/local/biotools/p/plink*",
    "crumbs": [
      "Bioinformatics",
      "GWAS"
    ]
  },
  {
    "objectID": "bio/gwas.html#tutorial",
    "href": "bio/gwas.html#tutorial",
    "title": "GWAS — Genome Wide Association Study",
    "section": "Tutorial",
    "text": "Tutorial\nhttps://www.cog-genomics.org/plink/2.0/assoc\n多サンプルマージ済みの VCF ファイルからスタートする。\n\nSNP サイトを抽出する\nbcftools view -v snps -m2 -M2 -Oz file.vcf.gz &gt; file.snp.vcf.gz\nbcftools index file.snp.vcf.gz\n\n\nPCA (主成分分析) をおこなう\n\nGWAS では SNP 以外の変数を共変量として組み込むことがある。 集団構造の主成分はこの典型で、 例えば平均的に体サイズの大きい集団 A と小さい集団 B がいるときに、 本当は体サイズと無関係だが集団 A と B で分化している座位を 体サイズ関連の SNP として検出してしまう可能性がある。 このような偽陽性を補正するために、 集団構造のデータを共変量として組み込む。 (Price et al. 2006)\n\nまず連鎖不平衡にあるアリルを刈り取る:\nplink2 --vcf file.snp.vcf.gz \\\n  --allow-extra-chr \\\n  --double-id \\\n  --set-missing-var-ids @:# \\\n  --maf 0.05 \\\n  --indep-pairwise 50 10 0.2 \\\n  --out file.plink\n\nplink2 --vcf file.snp.vcf.gz \\\n  --allow-extra-chr \\\n  --double-id \\\n  --set-missing-var-ids @:# \\\n  --extract file.plink.prune.in \\\n  --make-bed \\\n  --out file.plink\n.bed、.bim、.fam の3種類のファイルが出てくれば OK。 PLINK の詳しい使い方については省略する。\n\n--maf 0.05 はマイナーアレル頻度 0.05 未満の座位を取り除く。\n--indep-pairwise 50 10 0.2 は 10 SNPs のステップサイズで 50 SNPs のウィンドウ内にある r^2 &gt; 0.2 で連鎖不平衡にある SNP を取り除く。\n\nPCAを実行:\nplink2 --bfile file.plink --pca --allow-extra-chr --double-id --out file.pca\n.eigenvec、.eigenval の2種類のファイルが出てきたら OK。\n\n\n表現型データのファイルを用意する\nhttps://www.cog-genomics.org/plink/2.0/input#pheno\nGWAS に用いる表現型のデータを用意する。 .fam と同じ形式のタブ/スペース区切りで、1列目に “Family ID”、 2列目に “Individual ID”、3列目以降に表現型データを記載したファイルにする。\n例えば3列目に体重のような連続値データ、4列目に病気の有無のようなバイナリデータの場合:\n\n\nfile.pheno\n\n#FID  IID BM  Disease\npopA  sample1 56.3  2\npopA  sample2 50.1  2\npopA  sample3 61.3  1\npopB  sample4 59.9  1\npopB  sample5 53.6  2\npopB  sample6 49.8  1\n︙\n\n\nバイナリデータは、2がケース群、1がコントロール群として扱われる。\nFID, IID, phenotype の順ならヘッダーなしでも3列目が自動的に使われる。\n\n\n\nGWAS を実行する\nPLINK1 と PLINK2 で方法が異なる。以下は PLINK2 の場合。\nplink2 --bfile file.plink \\\n  --allow-extra-chr \\\n  --out file.gwas \\\n  --pheno file.pheno \\\n  --pheno-name Disease \\\n  --covar file.pca.eigenvec \\\n  --covar-name PC1-PC2 \\\n  --covar-variance-standardize \\\n  --glm skip-invalid-pheno firth-fallback hide-covar \\\n  --adjust \\\n  --ci 0.95\nこの通り実行すると、 file.gwas.$phrno-name.glm.$model.hybrid と file.gwas.$phrno-name.glm.$model.hybrid.adjusted の2種類のファイルができる。\n\n--pheno: 上で作った表現型ファイル\n--pheno-name: 使用する表現型の列名 (--pheno-col-nums で列番号での指定も可)\n--covar: PCA の出力ファイル\n--covar-name: どの主成分を共変量として使うか。PC10 まで全部使うなら PC1-PC10。\n--covar-variance-standardize: 共変量のスケーリングを行う\n--glm: 相関解析のモデル。バイナリデータには --logistic、 連続値データには --linear が勝手に使われるが、直接指定してもいい。\n\nskip-invalid-pheno: 共変量 (ここでは PCA) と表現型の共線性があると判断されると、解析が止まる。 これを避けてひとまず解析を押し通すオプション。\nfirth-fallback: バイナリの表現型に対してロジスティック回帰を行うときのモデル [no-firth(PLINK1 のデフォルト)/firth-fallback(デフォルト)/firth]\nhide-covar: 出力ファイルに共変量の情報を出さない。(主にファイルサイズ削減のため)\n\n--adjust: 多重補正をおこなう\n--ci 0.95: 信頼区間\n\n\n\n可視化\n非常にファイルサイズが大きいので、 例えば遺伝研スパコンで作業制定て手元に結果を取り寄せるときは あらかじめ使う列だけ抽出しておくのも手:\n# 最低でも染色体、座位、SNP の ID、P 値があればいい\ncat file.gwas.Disease.glm.logistic.hybrid | awk -F '\\t' '{print $1 \"\\t\" $2 \"\\t\"　$3 \"\\t\" $18}' &gt; gwas-result.txt\n\n以降、Rでの作業\nqqman ライブラリを使う。\n(染色体アクセッションの変換のために sequence_report.tsv を使用している。 F_\\text{st} 解析ハンズオンも参照。)\nlibrary(conflicted)\nlibrary(tidyverse)\nlibrary(qqman)\n\n## sequence_report を準備:\nacc2chr= readr::read_tsv(\"sequence_report.tsv\") |&gt;\n  dplyr::rename(CHROM = `RefSeq seq accession`, chr = `Chromosome name`) |&gt;\n  dplyr::select(CHROM, chr)\n\n## GWAS の結果を読み込む:\ngwas_result = readr::read_tsv(\"out/gwas-result.txt\") |&gt;\n  dplyr::rename(CHROM = \"#CHROM\") |&gt;\n  dplyr::inner_join(acc2chr, by = \"CHROM\") |&gt;\n  dplyr::filter(!chr %in% c(\"Z\", \"W\", \"MT\", \"Un\")) |&gt;\n  dplyr::mutate(chr = as.integer(chr))\nQQ-plot の描画:\nqqman::qq(gwas_result$P)\nマンハッタンプロットの描画:\nqqman::manhattan(gwas_result, chr = \"chr\", bp = \"POS\", p = \"P\", snp = \"ID\")",
    "crumbs": [
      "Bioinformatics",
      "GWAS"
    ]
  },
  {
    "objectID": "bio/orthofinder.html",
    "href": "bio/orthofinder.html",
    "title": "OrthoFinder",
    "section": "",
    "text": "複数種の遺伝子配列を、共通の1遺伝子に由来するパラログ + オーソログのグループ (Orthogroup; OG) に分類する。",
    "crumbs": [
      "Bioinformatics",
      "OrthoFinder"
    ]
  },
  {
    "objectID": "bio/orthofinder.html#usage",
    "href": "bio/orthofinder.html#usage",
    "title": "OrthoFinder",
    "section": "Usage",
    "text": "Usage\n解析したい種の遺伝子の配列 (Fasta ファイル) を 1つのディレクトリ (ex. fasta_dir/) に用意して-fに渡すだけ。\northofinder -f fasta_dir",
    "crumbs": [
      "Bioinformatics",
      "OrthoFinder"
    ]
  },
  {
    "objectID": "bio/orthofinder.html#出力",
    "href": "bio/orthofinder.html#出力",
    "title": "OrthoFinder",
    "section": "出力",
    "text": "出力\n出力は -f に渡したディレクトリ中に Result_*date* ディレクトリが作られてその中に入る。 以下は ver2.5.2 の例。\nPhylogenetic_Hierarchical_Orthogroups/\n\nSingle_Copy_Orthologue_Sequences/\n\nOG ごとのシングルコピーオーソログの配列\n\nOrthogroup_Sequences/\n\n全部の OG ごとの配列\n\n\nComparative_Genomics_Statistics/\n\n\nDuplications_per_Orthogroup.tsv\n\nOGごとの重複（*）の数\n\n\n\nOrthologuesStats_Totals.tsv\n\n1種対1種のオーソログの数\n\n\n\nOrthologuesStats_{one-to-many/many2one/many2many}.tsv\n\n1種対多種, 多種対1種, 多種対多種のオーソログの数\n\n\n\nStatistics_PerSpecies.tsv\n\n種ごとのオーソログの数に関する要約統計\n\n\n\nDuplications_per_Species_Tree_Node.tsv\n\n種ごとの重複の数\n\n\n\nOrthogroups_SpeciesOverlaps.tsv\n\nOrthologuesStats_Totals と同じ？\n\n\n\nStatistics_Overall.tsv\n\n全体の要約統計\n\n\n\nPhylogenetically_Misplaced_Genes\n\nSpecies_Tree/\n\n種の系統樹 (.txt)\n\n\nGene_Duplication_Events/\n\n\nDuplication.tsv\n\nOG ごとにどのノードでどの遺伝子とどの遺伝子が重複したかが書かれてる\n\n\n\nSpeciesTree_Gene_Duplications_0.5_Support.txt\n\n種の系統樹と若干違う？\n\n\n\nOrthogroups/\n\n\nOrthogroups.GeneCount.tsv\n\nOG × 種ごとの遺伝子数\n\n\n\nOrthogroups.tsv/.txt\n\nOG × 種ごとの遺伝子名\n\n\n\nOrthogroups_SingleCopyOrthologues.txt\n\nシングルコピー OG 名\n\n\n\nOrthogroups_UnassignedGenes.tsv\n\n1種しかいない OG 名\n\n\n\n\nPutative_Xenologs\n\n水平伝播したと推定される遺伝子 (あれば)\n\nWorkingDirectory/\n\nBlast などの中間ファイルが圧縮されて入っている。\n\n\nSpeciesIDs.txt は再解析 (後述) をする際に必要\n\nGene_Trees/\n\nOG ごとの遺伝子系統樹 (.txt) が入ってる。\n\n\nOrthologues/\n\n\nOrthologues_*種名*\n\n1種対1種のオーソログが書かれてる。\n\n\n\nResolved_Gene_Trees\n\nOG ごとの種分化を考慮した系統樹。4遺伝子以上の OG についてしか書かれていない。\n\n\n\n\nUnassigned gene と Species-specific Orthogroup\n両方とも系統特異的な遺伝子であると考えられ、 Unassigned gene はそのうちシングルトンであるもの (自身の中にもパラログが存在しない)、 Species-specific Orthogroup はそのうち重複遺伝子であるもの。 系統特異的な重複とは異なる。",
    "crumbs": [
      "Bioinformatics",
      "OrthoFinder"
    ]
  },
  {
    "objectID": "bio/orthofinder.html#種の追加除外",
    "href": "bio/orthofinder.html#種の追加除外",
    "title": "OrthoFinder",
    "section": "種の追加/除外",
    "text": "種の追加/除外\n\n種の追加を行う場合\n追加したい種の Fasta ファイルが入ったディレクトリを用意して、-f で指定:\northofinder -b /Result_*/WorkingDirectory -f new_fasta_directory\n結果は /WorkingDirectory/OrthoFinder/Result_*Date*/ に出力される。\n\n\n種を除外する場合\n/Result_*/WorkingDirectory/ にある SpeciesIDs.txt を編集し、 除外する種を # でコメントアウトする。その上で、\northofinder -b /Result_*/WorkingDirectory\nを実行する。 -f で追加ディレクトリを指定しつつ追加と除外を同時に行うことも可能。",
    "crumbs": [
      "Bioinformatics",
      "OrthoFinder"
    ]
  },
  {
    "objectID": "bio/orthofinder.html#遺伝研",
    "href": "bio/orthofinder.html#遺伝研",
    "title": "OrthoFinder",
    "section": "遺伝研",
    "text": "遺伝研\nbiotools にある:\nls /usr/local/biotools/o/orthofinder*\n\n並列化\n種数にもよるが全種×全種で blast する都合上かなりメモリを食うので、 medium に並列で投げることをおすすめする。 下記は5スロットで投げる例。\n#$ -S /bin/bash\n#$ -cwd\n#$ -pe def_slot 5\n#$ -l medium\n#$ -l s_vmem=64G\n#$ -l mem_req=64G\n\nmodule load singularity\nsingularity exec /usr/local/biotools/o/orthofinder:%ver orthofinder -f dir -t 5 -a 5",
    "crumbs": [
      "Bioinformatics",
      "OrthoFinder"
    ]
  },
  {
    "objectID": "bio/rerconverge.html#インストール",
    "href": "bio/rerconverge.html#インストール",
    "title": "RERconverge",
    "section": "インストール",
    "text": "インストール\nhttps://github.com/nclark-lab/RERconverge/wiki/Install\nバイナリ版のインストールが推奨されている。 Mac で使う場合はまずバイナリ版インストールを試してみる。 バイナリ版インストールで問題があったり、Windows や Linux で使う場合はソースコード版を試す。 (それでもダメなら一応 Docker イメージもあるっぽい。)\n\nMac\n\nバイナリ版のインストール\n\ndevtools が必要:\ninstall.packages(\"devtools\")\nlibrary(devtools)\nGithub からパッケージをインストール。 これを実行すると、RERconverge 本体のインストールは失敗するけど、 他の依存パッケージは入ってくるらしい:\ndevtools::install_github(\"nclark-lab/RERconverge\")\nちなみに依存パッケージは以下。これらを個別にインストールすれば 2. は不要？:\ndevtools\nRColorBrewer\ngplots\nphytools\ngeiger\nknitr\nRcppArmadillo\nweights\nphangorn\nリリースページから 最新版のバイナリ版パッケージをダウンロードしてターミナルでインストールコマンドを実行:\nR CMD INSTALL Mac_Big_Sur_R_4.0.0.RERconverge_0.1.0.tgz\n※ ファイル名の通り最新版 (2023-11-18時点) が BigSur の R 4.0.0 用なので、 そうじゃない Mac&R でちゃんと動くかは不明。\nちゃんと入ったかテスト:\nlibrary(RERconverge)\n\n\n\nソースコード版のインストール\n\n新しい gfortran (gcc) を入れておく:\nxcode-select --install  # if needed\nbrew install gcc\nMakevars でコンパイラの設定をする:\n素の Mac に RERconverge を入れようとすると、おそらく gfortran 関連で警告やエラーが出る。 Makevars を書いて homebrew で入れた gfortran を使うように設定する。\nまず ~/.R/Makevars をつくる (すでにあれば不要):\nmkdir ~/.R\ntouch ~/.R/Makevars\ngfortran の PATH とライブラリの場所を確認:\nwhich gfortran\n# /usr/local/bin/gfortran\nls -al /usr/local/lib/gcc/current\n# 略\nMakevars に以下を記述:\nFC=/usr/local/bin/gfortran\nF77=/usr/local/bin/gfortran\nFLIBS=-L/usr/local/lib/gcc/current\ndevtools のインストール:\ninstall.packages(\"devtools\")\nGithub からパッケージをインストール。 コンパイラ周りをちゃんと設定しておけば入るはず:\ndevtools::install_github(\"nclark-lab/RERconverge\")\n\n\nMakevars は Rcpp で使う C++ などのコンパイラの設定をするためのファイル。 公式ドキュメントや、 メタルさんのサイト、 津田さんのサイト も参照\n\n\n\n\nWindows\n\nRtools を入れておく。\n依存パッケージのインストール:\ndevtools\nRColorBrewer\ngplots\nphytools\ngeiger\nknitr\nRcppArmadillo\nweights\nphangorn\nRERconverge のインストール:\ndevtools::install_github(\"nclark-lab/RERconverge\")",
    "crumbs": [
      "Bioinformatics",
      "RERconverge"
    ]
  },
  {
    "objectID": "bio/rerconverge.html#概要",
    "href": "bio/rerconverge.html#概要",
    "title": "RERconverge",
    "section": "概要",
    "text": "概要\nhttps://github.com/nclark-lab/RERconverge/blob/master/vignettes/ にチュートリアルあり\nRERconverge は主に以下の機能を実装している:\n\n遺伝子系統樹の推定\n相対進化速度の計算\n相対進化速度と表現型の相関解析\nエンリッチメント解析\n\n遺伝子系統樹の推定やエンリッチメント解析は、RERconverge 以外の方法でもできる。 そのほか、途中途中で解析に必要なファイルは別個に用意しても良い。",
    "crumbs": [
      "Bioinformatics",
      "RERconverge"
    ]
  },
  {
    "objectID": "bio/rerconverge.html#遺伝子系統樹の推定",
    "href": "bio/rerconverge.html#遺伝子系統樹の推定",
    "title": "RERconverge",
    "section": "遺伝子系統樹の推定",
    "text": "遺伝子系統樹の推定\nRERconverge は遺伝子ごとに推定した系統樹を使い、 ある遺伝子のある枝の枝長が全遺伝子の平均的な枝長に対して長いか短いかを基に相対進化速度を推定する。\n\nNewick フォーマット\n全遺伝子のトポロジーが同じ\nnode ラベルなし、tip ラベルは全遺伝子で共通\n\nである必要がある。\n別の系統樹推定ソフトウェアでやる場合は、トポロジー指定機能とかを使う。 最終的には、下のように遺伝子名と Newick がタブ区切りになった1つのファイルを作れば OK:\nGene_A (human:0.01,(chimp:0.0012,(gorilla:0.0078, orangutan:0.0037):0.0003):0.0053);\nGene_B (human:0.0094,(chimp:0.0038,(gorilla:0.001, orangutan:0.0038):0.00032):0.0005);\nGene_C (human:0.0032,(chimp:0.0054,(gorilla:0.07, orangutan:0.0012):0.0023):0.0023);\n︙\nRERconverge にも、遺伝子系統樹推定のための関数が実装されている。 必要なのは各遺伝子のアライメントファイルと種の系統樹。\nestimatePhangornTreeAll(\n  alnfiles = NULL,\n  alndir = NULL,\n  pattern = NULL,\n  treefile,\n  output.file = NULL,\n  submodel = \"LG\",\n  type = \"AA\",\n  format = \"fasta\",\n  k = 4,\n  ...\n)\n\nalnfiles/alndir (どちらかで指定)\n\nアライメントファイルの PATH のベクター、またはアライメントファイルのあるディレクトリ\n\npattern\n\n正規表現でファイルを指定できる\n\n\ne.g. \"*.pep.fa\"\n\ntreefile\n\n「この系統樹のトポロジーを使う」とする master tree の PATH\n\n\n種の系統樹を使うのが無難か\n\noutput.file\n\n出力先\n\n\n上で説明した遺伝子名と Newick のタブ区切りテキストができる\n\nsubmodel\n\n系統樹推定に使う置換モデル。phangorn::pml() に渡される。 デフォルトは LG モデル。\n\n\nsee ?phangorn::pml()\n\ntype\n\nアミノ酸なら AA, 塩基なら DNA\n\nformat\n\nデフォルトは FASTA フォーマット\n\n\n\nAmbiguousなアミノ酸残基を表す B, Z, J は読んでくれない。X で置換しとくとか？",
    "crumbs": [
      "Bioinformatics",
      "RERconverge"
    ]
  },
  {
    "objectID": "bio/rerconverge.html#相対進化速度の計算",
    "href": "bio/rerconverge.html#相対進化速度の計算",
    "title": "RERconverge",
    "section": "相対進化速度の計算",
    "text": "相対進化速度の計算\n系統樹ファイルの読み込み:\ntreesObj = RERconverge::readTrees(\n  file,\n  max.read = NA,\n  masterTree = NULL,\n  minTreesAll = 20,\n  reestimateBranches = F,\n  minSpecs = NULL\n)\n\nfile\n\nestimatePhangornTreeAll とかでつくった系統樹ファイル\n\nmax.read\n\n読み込む遺伝子の数を制限。全遺伝子やるなら指定しなくていい。\n\nmasterTree\n\n相対進化速度の計算の基準となる master tree。\n\n\nこの関数自体も master tree を推定するので、基本的には指定しないで OK。\n\nminTreeAll\n\nmasterTree の推定に使う遺伝子の最低数。\n\nminSpec\n\nある遺伝子をもっている種の数がこれより少ない遺伝子を除く。\n\n\n相対進化速度の計算:\nRERmat = getAllResiduals(\n  treesObj,\n  cutoff = NULL,\n  transform = \"sqrt\",\n  weighted = T,\n  useSpecies = NULL,\n  min.sp = 10,\n  scale = T,\n  doOnly = NULL,\n  maxT = NULL,\n  scaleForPproj = F,\n  mean.trim = 0.05,\n  plot = T\n)\n\ntreeObj\n\nreadTree で読み込んだ系統樹オブジェクト\n\ntransform\n\n平方根 (“sqrt”) または対数 (“log”) で枝長を変換する。“none” だとそのまま使う。\n\nweighted/scale\n\n平均の枝長が長いほど相対進化速度の分散が大きいというバイアスを補正するアプローチ\n\n\nc.f. Partha et al. 2019\n\nmin.sp\n\nある遺伝子をもっている種数の最低数",
    "crumbs": [
      "Bioinformatics",
      "RERconverge"
    ]
  },
  {
    "objectID": "bio/rerconverge.html#相対進化速度と表現型の相関解析",
    "href": "bio/rerconverge.html#相対進化速度と表現型の相関解析",
    "title": "RERconverge",
    "section": "相対進化速度と表現型の相関解析",
    "text": "相対進化速度と表現型の相関解析\n\n二値的形質との相関解析\n水棲/陸生、地中生/地上生、飛ぶ/飛ばないみたいなバイナリな形質を対象にした解析\nフォアグラウンドの種を指定する:\ntree = foreground2Tree(\n  foreground,\n  treesObj,\n  plotTree = T,\n  clade = c(\"ancestral\", \"terminal\", \"all\"),\n  weighted = F,\n  transition = \"unidirectional\",\n  useSpecies = NULL\n)\n\nforeground\n\n全種のうち、フォアグラウンド (興味のある表現型をもつ側) の種のベクタ\n\ntreesObj\n\nRERconverge::readTrees で読み込んだ系統樹\n\nclade\n\n3種類の方法がある。\n\n\nancestral は共通祖先の枝1本のみをフォアグラウンドにする。 形質が獲得されたと想定される枝。\n\n\nterminal は各種に向かう末端の枝のみをフォアグラウンドにする。\n\n\nall は共通祖先から各種までの枝すべてをフォアグラウンドにする。 形質が獲得されてからずーっとかかっている選択を検出するイメージ。\n\nweighted\n\nclade = \"all\"/\"terminal\" のときに、例えば共通祖先から末端まで3回の分岐がある種と 1回も分岐していない種がいたら、前者の各枝の重み付けを1/3する。\n\ntransition = c(\"bidirectional\", \"unidirectional\")\n\nいちど形質が獲得されてからの喪失を想定するかどうか\n\n\n表現型のベクタを作成:\ncarP = tree2Paths(tree, treesObj, binarize = NULL, useSpecies = NULL, categorical = F)\n\ntree\n\nforeground2Tree() で作ったフォアグラウンド情報の系統樹\n\ntreesObj\n\nRERconverge::readTrees() で読み込んだ系統樹\n\n\n表現型との相関解析:\nres = correlateWithBinaryPhenotype(\n  RERmat,\n  charP,\n  min.sp = 10,\n  min.pos = 2,\n  weighted = \"auto\"\n)\n\nRERmat\n\ngetAllResiduals() で計算した相対進化速度のマトリクス\n\nchaP\n\ntree2Paths() でつくった表現型ベクタ\n\nmin.sp\n\nある遺伝子をもっている種数の最低数\n\nmin.pos\n\nある遺伝子をもっているフォアグラウンド種の最低数\n\n\ncorrelateWithBinaryPhenotype() は、各遺伝子を行、 以下の統計量を列とするデータフレームを返す。\n\nRho\n\n関係の正負 (フォアグラウンドで加速/保存) を示す Pearson correlation\n\nN\n\n相対進化速度が算出された枝の数\n\nP\n\n相関解析のP値\n\np.adj\n\n多重補正後のP値。BH法を使っている。\n\n\n\n\n連続形質との相関解析\n体サイズ、寿命など連続的な数値データの形質を対象にした解析\n表現型の名前付きベクタをつくる。データフレームとかを用意しておくと楽。例えば:\ndf = data.frame(\n  species = c(\"spA\", \"spB\", \"spC\"),\n  body_mass = c(\"10\", \"20\", \"30\")\n ) |&gt;\n tibble::column_to_rownames(\"species\")\ntip.vals = df$body_mass\nnames(tip.vals) = rownames(df)\nで、\ncharP = char2Paths(\n  tip.vals,\n  treesObj,\n  altMasterTree = NULL,\n  metric = \"diff\",\n  se.filter = -1,\n  ...\n)\n\ntip.vals\n\n一個前で作った表現型ベクタ\n\ntreeObj\n\nRERconverge::readTrees() で読み込んだ系統樹\n\nmetric\n\ninternal_branch の表現型をどうするか\n\n\ndiff は枝の前後の祖先形質の差、mean は平均値、last は末端側の値をつかう。\n\n\n表現型との相関解析:\nres = correlateWithContinuousPhenotype(\n  RERmat,\n  charP,\n  min.sp = 10,\n  winsorizeRER = 3,\n  winsorizetrait = 3\n)\nRERmat, charP, min.sp は binary の時と同じ\n\nwinsorizeRER/winsorizetrait\n\n相対進化速度/表現型の値の top/worst の N 種ずつを、N+1 番目の値に変換する。\n\n\n相関解析が極端な外れ値の影響を受けることを避けるためのオプション\n\n\n返ってくるのは binary と同じデータフレーム",
    "crumbs": [
      "Bioinformatics",
      "RERconverge"
    ]
  },
  {
    "objectID": "bio/rerconverge.html#エンリッチメント解析",
    "href": "bio/rerconverge.html#エンリッチメント解析",
    "title": "RERconverge",
    "section": "エンリッチメント解析",
    "text": "エンリッチメント解析\nウィルコクソンの順位和検定を使ったエンリッチメント解析の機能が実装されている。 もちろん topGO や clusterProfiler を使ってもいい。\n.gmt ファイルをダウンロードする:\nhttps://www.gsea-msigdb.org/gsea/login.jsp\n.gmt ファイルを読み込む:\nannots=read.gmt(\"gmtfile.gmt\")\nannotlist=list(annots)\nnames(annotlist)=\"MSigDBpathways\"\n相関解析の結果を加速度合い/保存度合いの順に並べる:\nstats = RERconverge::getStat(res)\nres は correlateWithBinaryPhenotype() や correlateWithContinuousPhenotype() の結果。 sign(Rho) × -log(P) をやってスコア順に並べる。\nエンリッチメント解析:\nenrichment = fastwilcoxGMTall(stats, annotlist, outputGeneVals=T, num.g=10)\n\nstats\n\nRERconverge::getStat() で並べた遺伝子\n\nannotlist\n\nread.gmt() で読み込んだパスウェイのリスト",
    "crumbs": [
      "Bioinformatics",
      "RERconverge"
    ]
  },
  {
    "objectID": "cli/apt.html#usage",
    "href": "cli/apt.html#usage",
    "title": "apt — Debian 系 Linux パッケージマネージャ",
    "section": "Usage",
    "text": "Usage\n\nsudo apt update\n\nパッケージ一覧を更新\n\nsudo apt upgrade\n\nインストール済みのソフトウェアを更新\n\n\n必要に応じて依存パッケージをインストールすることがある。 (古い apt-get だと新規インストールは起こらない。)\n\nsudo apt install パッケージ\n\nパッケージのダウンロード\n\nsudo apt remove パッケージ\n\nパッケージの削除\n\nsudo apt purge パッケージ\n\n設定ファイルを含め、パッケージを完全削除\n\nsudo apt autoremove\n\n更新に伴い、必要なくなった依存パッケージを削除\n\napt search 検索キーワード\n\nパッケージの検索\n\napt list --upgradable\n\n更新可能なパッケージ一覧を表示\n\napt list --installed\n\nインストール済みのパッケージ一覧を表示\n\napt show パッケージ\n\nパッケージの詳細を表示\n\n\nおまけ:\napt moo\n           (__)\n           (oo)\n     /------\\/\n    / |    ||\n   *  /\\---/\\\n      ~~   ~~\n...\"Have you mooed today?\"...",
    "crumbs": [
      "開発環境",
      "apt"
    ]
  },
  {
    "objectID": "cli/apt.html#apt-get-apt-cache",
    "href": "cli/apt.html#apt-get-apt-cache",
    "title": "apt — Debian 系 Linux パッケージマネージャ",
    "section": "apt-get, apt-cache",
    "text": "apt-get, apt-cache\napt はパッケージの管理を担う apt-get と検索を担う apt-cache の統合を図るコマンド。 それぞれのコマンドの対応は以下のようになっている。\napt-get update             -&gt;  apt update\napt-get upgrade            -&gt;  apt upgrade\napt-get dist-upgrade       -&gt;  apt full-upgrade\napt-get install package    -&gt;  apt install package\napt-get remove package     -&gt;  apt remove package\napt-get autoremove         -&gt;  apt autoremove\napt-cache search string    -&gt;  apt search string\napt-cache policy package   -&gt;  apt list -a package\napt-cache show package     -&gt;  apt show package\napt-cache showpkg package  -&gt;  apt show -a package",
    "crumbs": [
      "開発環境",
      "apt"
    ]
  },
  {
    "objectID": "cli/hugo.html",
    "href": "cli/hugo.html",
    "title": "HUGO — Go 製静的サイトジェネレータ",
    "section": "",
    "text": "https://gohugo.io/about/\nマークダウンで書いたファイルから HTML を生成し、静的ウェブサイトを構築するフレームワーク。 本サイトも以前は HUGO でビルドしていた。 (現在は Quarto に移行)",
    "crumbs": [
      "開発環境",
      "HUGO"
    ]
  },
  {
    "objectID": "cli/hugo.html#インストール",
    "href": "cli/hugo.html#インストール",
    "title": "HUGO — Go 製静的サイトジェネレータ",
    "section": "インストール",
    "text": "インストール\nMac なら homebrew、Ubuntu なら apt で一発:\n## homebrew\nbrew install hugo\n\n## apt\nsudo apt install hugo",
    "crumbs": [
      "開発環境",
      "HUGO"
    ]
  },
  {
    "objectID": "cli/hugo.html#quick-start",
    "href": "cli/hugo.html#quick-start",
    "title": "HUGO — Go 製静的サイトジェネレータ",
    "section": "Quick Start",
    "text": "Quick Start\n\nサイトの骨組みを作る。\nmkdir path_to_site\ncd path_to_site\nhugo new site .\n生成される content/ ディレクトリの中に記事を書いていく。\nhugo new content/about.md\n\n\nabout.md\n\n---\ntitle: \"デモページ\"\ndate: 2022-11-03T22:09:12+09:00\n---\n\nこれは**テストページ**です。\n\nサーバーを走らせて http://localhost:1313/about にアクセス。\nhugo server -D -w .",
    "crumbs": [
      "開発環境",
      "HUGO"
    ]
  },
  {
    "objectID": "cli/hugo.html#commands",
    "href": "cli/hugo.html#commands",
    "title": "HUGO — Go 製静的サイトジェネレータ",
    "section": "Commands",
    "text": "Commands\n\nhugo new site\nウェブサイトの骨組みを作る。\n\nconfig.toml\n\n設定ファイル\n\n\nversion 0.110.0 以降、config.toml に代わって hugo.toml というファイル名が推奨されている。\n\ncontent/\n\nこの中にマークダウンでページを書いていく。\n\npublic/\n\n後述の hugo コマンドを走らせたときに HTML ファイルがこの中に生成される。\n\nstatic/\n\n画像、CSS、Javascript などの置き場。\n\nthemes/\n\nサイトの見た目を決めるテーマを入れる。 https://themes.gohugo.io/ から好きなテーマを選んで git clone する。\n\n\n自分で作ってもいい。(c.f. https://github.com/ymat2/hugo-theme-mindoc)\n\n\n\n\nhugo new\n新しいページを作る。 archetype/ や theme/、layout/ 内の default.md からヘッダーが生成される。\n---\ntitle: \"{{ replace .Name \"-\" \" \" | title }}\"\ndate: {{ .Date }}\ndraft: true\n---\n\n\nhugo server\nサイトをビルドしてサーバーを起動する。 http://localhost:1313 で閲覧できる。\n\n-D\n\ndraft: true のファイルも含めて公開\n\n-w\n\nファイルの変更をすぐに反映する。\n\n-p 1234\n\nポート番号の指定。デフォルトは1313。\n\n\n\n\nhugo\npublic/ に HTML を生成する。 Github Pages でホストする場合、この中身を公開する。",
    "crumbs": [
      "開発環境",
      "HUGO"
    ]
  },
  {
    "objectID": "cli/hugo.html#github-actions-による自動デプロイ",
    "href": "cli/hugo.html#github-actions-による自動デプロイ",
    "title": "HUGO — Go 製静的サイトジェネレータ",
    "section": "Github Actions による自動デプロイ",
    "text": "Github Actions による自動デプロイ\n\n参考: https://sat8bit.github.io/posts/hugo-with-github-pages/\nHUGO 公式: https://gohugo.io/hosting-and-deployment/hosting-on-github/\nGithub Pages: &gt;https://docs.github.com/ja/pages/getting-started-with-github-pages/about-github-pages&gt;\n\n\nGithub で ユーザ名.github.io という名のリポジトリを作成\nローカルにサイトを構築して git init:\nhugo new site &lt;username&gt;.github.io && cd &lt;username&gt;.github.io\ngit init\ngit commit -m \"Create site\"\ngit remote add origin https://github.com/&lt;username&gt;/&lt;username&gt;.github.io.git\ngit branch -M main\ngit push -u origin main\ncontents/ にページを作成:\nhugo new contents/index.md\necho \"hello, world!\" &gt; contents/index.md\nActions の設定\ngit push をトリガーに、自動でビルドコマンドを走らせて gh-pages ブランチにページを生成するように Actions を設定する。\n.github/workflows/gh-pages.yml に以下のように記述する。\n\n\n.github/workflows/gh-pages.yml\n\nname: GitHub Pages\n\non:\n    push:\n        branches:\n            - main  # Set a branch name to trigger deployment\n    pull_request:\n\njobs:\n    deploy:\n        runs-on: ubuntu-22.04\n        steps:\n            - uses: actions/checkout@v3\n                with:\n                    submodules: true  # Fetch Hugo themes (true OR recursive)\n                    fetch-depth: 0    # Fetch all history for .GitInfo and .Lastmod\n\n            - name: Setup Hugo\n                uses: peaceiris/actions-hugo@v2\n                with:\n                    hugo-version: 'latest'\n\n            - name: Build\n                run: hugo\n\n            - name: Deploy\n                uses: peaceiris/actions-gh-pages@v3\n                # If you're changing the branch from main,\n                # also change the `main` in `refs/heads/main`\n                # below accordingly.\n                if: ${{ github.ref == 'refs/heads/main' }}\n                with:\n                    github_token: ${{ secrets.GITHUB_TOKEN }}\n                    publish_dir: ./public",
    "crumbs": [
      "開発環境",
      "HUGO"
    ]
  },
  {
    "objectID": "cli/quarto.html#インストール",
    "href": "cli/quarto.html#インストール",
    "title": "Quarto — 書類・スライド作成からウェブサイト構築まで",
    "section": "インストール",
    "text": "インストール\nhttps://quarto.org/docs/get-started/\n上のページから Quarto CLI をダウンロードする。 RStudio でつかうときは既に同梱されているので不要。\nコマンドラインからやってももちろん OK:\n## Mac なら homebrew で\nbrew install --cask quarto\n\n## WSL/Linux では deb を落としてくるのが正攻法？\nsudo curl -LO https://quarto.org/download/latest/quarto-linux-amd64.deb\n# sudo apt-get install gdebi-core  # if needed\nsudo gdebi quarto-linux-amd64.deb\nJupyter, RStudio, VSCode など好きなエディタで作業する。 VSCode で使う時は Quarto 拡張機能を入れておく。",
    "crumbs": [
      "開発環境",
      "Quarto"
    ]
  },
  {
    "objectID": "cli/quarto.html#まずは骨格をつくる",
    "href": "cli/quarto.html#まずは骨格をつくる",
    "title": "Quarto — 書類・スライド作成からウェブサイト構築まで",
    "section": "まずは骨格をつくる",
    "text": "まずは骨格をつくる\nhttps://quarto.org/docs/websites/\n_quarto.yml という名前の config ファイルでほとんどを管理する。 WEB サイト用のディレクトリを作って _quarto.yml を用意:\nmkdir my-website\ncd my-website\ntouch _quarto.yml\nエディタによっては Quarto のプロジェクトを作るボタンでこの辺の骨組みを自動で作ってくれる。\n_quarto.yml はとりあえず以下のように記述:\n\n\n_quarto.yml\n\nproject:\n  type: website\n\nwebsite:\n  title: \"My Website\"\n\nformat:\n  html:\n    theme: cosmo\n\n続いて index.qmd というファイルを作ってマークダウンで内容を書いてみる:\ntouch index.qmd\n\n\nindex.qmd\n\n---\ntitle: \"This is my website\"\nformat: html\n---\n\nHello, world.\n\nMy *name* is **Yuki** ***Matsuda***.\n\nI like\n\n- Sushi\n- Ra-men\n- Coffee\n\n--- で囲まれた部分にはタイトル、著者、フォーマットなどのメタデータを記述する。 より詳しくはドキュメントを参照。\nここまでできたら作ったファイルを HTML に変換して閲覧してみる:\nquarto preview\n# もしくは\nquarto render\n# もしくは\n# 各エディタの \"Preview\" や \"Render\" のボタン\n\nquarto preview\n\nlocalhost が立ち上がるので、ブラウザで閲覧\n\nquarto render\n\n(デフォルトでは) _site/ というディレクトリが作られてその中に index.html ができる。 ダブルクリックして見てみる。",
    "crumbs": [
      "開発環境",
      "Quarto"
    ]
  },
  {
    "objectID": "cli/quarto.html#適当にカスタムしてみる",
    "href": "cli/quarto.html#適当にカスタムしてみる",
    "title": "Quarto — 書類・スライド作成からウェブサイト構築まで",
    "section": "適当にカスタムしてみる",
    "text": "適当にカスタムしてみる\n_quarto.yml や 各 .qmd のヘッダーでいろいろカスタムできる。 例えば:\n\n\n_quarto.yml\n\nproject:\n  type: website\n  output-dir: docs  # HTML の出力先を指定\n\nwebsite:\n  title: \"My Website\"\n\nformat:\n  html:\n    theme: darkly   # ダークテーマにしてみる\n\n\noutput-dir\n\n例えば GitHub Pages を使うなら docs という名前が便利だったりする。\n\n\nrender 時になくても勝手に作られる。\n\ntheme\n\nサイトの見た目がいくつか選べる。詳しくはここから。\n\n\nCSS や SCSS を書いて自分でカスタマイズすることもできる。 例えば: https://github.com/ymat2/slides/blob/main/static/",
    "crumbs": [
      "開発環境",
      "Quarto"
    ]
  },
  {
    "objectID": "cli/quarto.html#サブディレクトリを作ってサイドバーに反映させる",
    "href": "cli/quarto.html#サブディレクトリを作ってサイドバーに反映させる",
    "title": "Quarto — 書類・スライド作成からウェブサイト構築まで",
    "section": "サブディレクトリを作ってサイドバーに反映させる",
    "text": "サブディレクトリを作ってサイドバーに反映させる\nhttps://quarto.org/docs/websites/website-navigation.html\nページが増えてくると、セクションごとにディレクトリを分けておきたい。 それぞれのページにサイドバーのドロップダウンからアクセスする、みたいなことも簡単にできる。\nまずはディレクトリを分けていくつかページを作る。例えば:\nmy-website/\n├── _quarto.yml\n├── index.qmd\n├── dir1/\n│   ├── page1.qmd\n│   └── page2.qmd\n└── dir2/\n    ├── page3.qmd\n    └── page4.qmd\n次に、_quarto.yml に sidebar の設定をする:\n\n\n_quarto.yml\n\nproject:\n  type: website\n  output-dir: docs  # HTMLの出力先を指定\n\nwebsite:\n  title: \"My Website\"\n  sidebar:\n    contents: auto  # 細かく指定もできるけどとりあえず任せる\n\nformat:\n  html:\n    theme: cosmo\n\n改めて quarto render して docs/index.html を見てみると、 ページの横にサイドバーが表示されて各ページにアクセスできる。",
    "crumbs": [
      "開発環境",
      "Quarto"
    ]
  },
  {
    "objectID": "cli/quarto.html#スライドも作ってみる",
    "href": "cli/quarto.html#スライドも作ってみる",
    "title": "Quarto — 書類・スライド作成からウェブサイト構築まで",
    "section": "スライドも作ってみる",
    "text": "スライドも作ってみる\nhttps://quarto.org/docs/presentations/revealjs/\nQuarto では、revealjs という JavaScript のフレームワークを使って HTML をスライドっぽく表示する。\n_quarto.yml にスライド用の設定を追記:\n\n\n_quarto.yml\n\nproject:\n  type: website\n  output-dir: docs  # HTMLの出力先を指定\n\nwebsite:\n  title: \"My Website\"\n  sidebar:\n    contents: auto  # 細かく指定もできるけどとりあえず任せる\n\nformat:\n  html:\n    theme: cosmo\n  revealjs:\n    theme: default\n    scrollable: true\n    history: false\n\n\ntheme\n\nHTML 同様にいくつかテーマが用意されている。\n\n\nもちろん自分で CSS を書いてカスタム可能\n\nscrollable\n\n縦に長いスライドをスクロールして閲覧できるように。\n\nhistory\n\nデフォルトの true だとブラウザバックでスライド単位の移動になって不快。 かならず false にする。\n\n\nスライド用のディレクトリを作ってファイルを作ってみる:\nmy-website/\n├── _quarto.yml\n├── index.qmd\n├── dir1/\n│   ├── page1.qmd\n│   └── page2.qmd\n├── dir2/\n│   ├── page3.qmd\n│   └── page4.qmd\n└── slides/\n    └── sample-slide.qmd\nsample-slide.qmd:\n\n\nsample-slide.qmd\n\n---\ntitle: \"サンプルスライド\"\nformat: revealjs\n---\n\n## ここにタイトル\n\nスライドでは、`##` で書く `&lt;h2&gt;` タグごとに1ページになる。\n\n## これは次のスライド\n\n基本的な\n\n- マークダウンの\n- **記法**は\n- 同じ。\n\n詳しくは[デモスライド](https://quarto.org/docs/presentations/revealjs/demo/#/title-slide)や\nその[ソースコード](https://github.com/quarto-dev/quarto-web/blob/main/docs/presentations/revealjs/demo/index.qmd)を\n見てみる。\n\nもう一度 quarto render してスライドを見てみる。",
    "crumbs": [
      "開発環境",
      "Quarto"
    ]
  },
  {
    "objectID": "cli/quarto.html#公開する",
    "href": "cli/quarto.html#公開する",
    "title": "Quarto — 書類・スライド作成からウェブサイト構築まで",
    "section": "公開する",
    "text": "公開する\nhttps://quarto.org/docs/publishing/\nデプロイ先に合わせる。 手元で閲覧する分には index.html を開けばよい。\n例えば GitHub Pages にホストさせる場合、 my-website をリポジトリとして push して docs の中身を公開する設定をすればよい。\nこの辺の面倒を見てくれる quarto publish というコマンドもある。",
    "crumbs": [
      "開発環境",
      "Quarto"
    ]
  },
  {
    "objectID": "cli/ssh.html",
    "href": "cli/ssh.html",
    "title": "SSH — Secure Shell",
    "section": "",
    "text": "リモートのマシンに安全に接続し、管理するためのツール。",
    "crumbs": [
      "開発環境",
      "SSH"
    ]
  },
  {
    "objectID": "cli/ssh.html#クライアント-ssh-する側-の設定",
    "href": "cli/ssh.html#クライアント-ssh-する側-の設定",
    "title": "SSH — Secure Shell",
    "section": "クライアント ( ssh する側) の設定",
    "text": "クライアント ( ssh する側) の設定\n\n公開鍵の作成と登録\n公開鍵と秘密鍵を作成:\nssh-keygen -t ed25519\n# Generating public/private ed25519 key pair.\n# Enter file in which to save the key:\n# Enter passphrase (empty for no passphrase):\n# Enter same passphrase again:\n\n-t (rsa/ecdsa/ed25519/etc.)\n\n作成する鍵の種類の指定。\n\n\ned25519 の他に dsa, ecdsa, ecdsa-sk, ed25519-sk, rsa など\n\n-f filename\n\n鍵のファイル名の指定。デフォルトは ~/.ssh/id_鍵タイプ\n\n\n公開鍵をサーバーに登録する。方法はそれぞれ:\n\nサイトに登録する場合などは公開鍵をコピー&ペースト\n## 公開鍵のコピー\ncat ~/.ssh/id_ed25519.pub | pbcopy\nコマンドで送る場合 (PasswordAuthentication yes である必要がある):\ncat id_ed25519.pub | ssh ユーザー名@ipアドレス \"mkdir ~/.ssh; cat&gt;&gt;~/.ssh/authorized_keys\"\n\nパーミッションの確認:\nls -al ~/.ssh\n# total 28\n# drwxr-xr-x  2 yukimatsu yukimatsu 4096 May 10 16:51 .\n# drwxr-x--- 16 yukimatsu yukimatsu 4096 May 29 16:06 ..\n# -rw-------  1 yukimatsu yukimatsu  342 May 10 16:51 config\n# -rw-------  1 yukimatsu yukimatsu  411 Apr 25 17:30 id_ed25519\n# -rw-r--r--  1 yukimatsu yukimatsu   96 Apr 25 17:30 id_ed25519.pub\n# -rw-------  1 yukimatsu yukimatsu 2320 May  1 12:45 known_hosts\n# -rw-------  1 yukimatsu yukimatsu 1484 May  1 12:40 known_hosts.old\n公開鍵 .pub 以外はユーザー本人だけが読み書きできる設定( -rw------- )にする:\nchmod 600 ~/.ssh/config\n\n\n~/.ssh/config の設定\n一般的な接続方法:\nssh username@example.com    # 毎回打つのは面倒！\nそこで .ssh/config に以下のような設定を追記:\n\n\n~/.ssh/config\n\nHost hoge\n    Hostname example.com                 # ホスト名(@のうしろ)\n    User username                        # ユーザー名\n    IdentityFile ~/.ssh/id_ed25519_hoge  # 秘密鍵への PATH\n\nこうすると以下の二つは等価:\nssh username@example.com\nssh hoge\nrsync でリモートに接続するときも記述を省略できて便利:\nrsync -auvz src/ username@example.com:dest/\nrsync -auvz src/ hoge:dest/",
    "crumbs": [
      "開発環境",
      "SSH"
    ]
  },
  {
    "objectID": "cli/ssh.html#サーバー-ssh-される側-の設定",
    "href": "cli/ssh.html#サーバー-ssh-される側-の設定",
    "title": "SSH — Secure Shell",
    "section": "サーバー (ssh される側) の設定",
    "text": "サーバー (ssh される側) の設定\nopenssh-server をインストールして起動を確認:\nsudo apt -y install openssh-server\nsudo systemctl status sshd.service  # Active: active (running) となっていれば起動している。\nこの状態でいったん同一 LAN 内の別のマシンから ssh してみる:\nssh ユーザー名@ipアドレス\n#\n#\n# Are you sure you want to continue(yes/no/[fingerprint])? yes\n# ユーザー名@ipアドレス's password:\n\n/etc/ssh/sshd_config の設定\nopenssh-server をインストールしたことで設定ファイルが /etc/ssh/ に生成される。 これを編集することでどの接続を許可してどれを弾くかを設定する。\n\n\n/etc/ssh/sshd_config\n\n# ssh公開鍵の種類を指定する。\nHostKey /etc/ssh/ssh_host_rsa_key\nHostKey /etc/ssh/ssh_host_ecdsa_key\nHostKey /etc/ssh/ssh_host_ed25519_key\n# ルートユーザーとしてのログインを禁止する。\nPermitRootLogin prohibit-password\n# SSHサーバーへの認証の最大試行回数を制限する。\nMaxAuthTries 5\n# 公開鍵による接続を許可する。\nPubkeyAuthentication yes\n# パスワードによる接続を許可する。公開鍵の登録を終えたら`no`に変える。\nPasswordAuthentication yes\n# 空のパスワードでの接続を無効にする。\nPermitEmptyPassword no\n# キーボードインタラクティブ認証を無効にする。公開鍵で接続する場合は無効にしたほうが良い。\nKbdInteractiveAuthentication no",
    "crumbs": [
      "開発環境",
      "SSH"
    ]
  },
  {
    "objectID": "cli/vscode.html",
    "href": "cli/vscode.html",
    "title": "Visual Studio Code",
    "section": "",
    "text": "https://code.visualstudio.com/",
    "crumbs": [
      "開発環境",
      "Visual Studio Code"
    ]
  },
  {
    "objectID": "cli/vscode.html#wsl-で使う場合",
    "href": "cli/vscode.html#wsl-で使う場合",
    "title": "Visual Studio Code",
    "section": "WSL で使う場合",
    "text": "WSL で使う場合\nhttps://learn.microsoft.com/ja-jp/windows/wsl/tutorials/wsl-vscode\n\nVSCode 本体と拡張機能のインストール\nhttps://code.visualstudio.com/download\n\nVSCode を (WSL ではなく) Windows にインストールする。\nインストール中に “追加タスクの選択” が求められたときは、 “PATH への追加” オプションをオンにする。\nRemote Development 拡張機能をインストールする。\n\nRemote Development 拡張機能なしで WSL にアクセスすることは非推奨とされている。\n\n\nLinux ディストリビューションの更新と必要なパッケージのインストール\nsudo apt update\nsudo apt install wget ca-certificates\n\n\nプロジェクトを開く\nWSL から code . 、 もしくは VSCode から ControlShiftP でコマンドパレットを開いて “WSL: Connect to WSL” を選択。\nなお、WSL から VSCode を立ち上げた場合、 ログインシェルの設定 (~/.bash_profile, ~/.zprofile)は読まれない。\n\n\n環境設定\nVSCode 本体は Windows のものなのでユーザー設定も Windows 側。 WSL で使う場合これを WSL 用の設定が上書きする。\n\n拡張機能は .vscode/extensions/\n環境設定は /AppData/Roaming/Code/User/settings.json\nキーボードショートカットは /AppData/Roaming/Code/User/keybindings.json\n\nWSL で VSCode を使う場合、ユーザーホームに .vscode-server/ が作られてこの中で設定をいじったりする。\n\n拡張機能は .vscode-server/extensions/\n環境設定は .vscode-server/data/Machine/settings.json",
    "crumbs": [
      "開発環境",
      "Visual Studio Code"
    ]
  },
  {
    "objectID": "cli/vscode.html#mac-で使う場合",
    "href": "cli/vscode.html#mac-で使う場合",
    "title": "Visual Studio Code",
    "section": "Mac で使う場合",
    "text": "Mac で使う場合\n\nVSCode のインストール\nhttps://code.visualstudio.com/download\n\nMac 版の VSCode をダウンロードして解凍\nVisual Studio Code.app を /Applications フォルダに移動\n\n\n\nterminal から VSCode を起動する設定\ncode の実行ファイルは /Applications/Visual Studio Code.app/Contents/Resources/app/bin/code にある。 ここに $PATH を通せばいい。\n\n公式のやり方\n\nVSCode を起動してコマンドパレットを開き (CommandShiftP)、 “shell” と検索して出てくる “Shell Command: Install ‘cpde’ command in PATH” をクリック。\n\n\nこれで上記の実行ファイル PATH が /usr/local/bin/ にシンボリックリンクされる。\n\nもしくは\n\n.zshrc とかに上記の PATH を通す。\n\n\n\n\n環境設定\nMac の VSCode の環境設定ファイルは /Library/application Support/Code/User/settings.json にある。",
    "crumbs": [
      "開発環境",
      "Visual Studio Code"
    ]
  },
  {
    "objectID": "cli/vscode.html#拡張機能",
    "href": "cli/vscode.html#拡張機能",
    "title": "Visual Studio Code",
    "section": "拡張機能",
    "text": "拡張機能\n\nSSH\nhttps://code.visualstudio.com/docs/remote/ssh-tutorial\nマシン自体に SSH の設定をしてあれば、 拡張機能をインストールするだけで SSH ホストのファイルにアクセスできる。 コマンドパレットを開いて “ssh” で検索し、“Romote-SSH: Connect to host…” を選択して接続先を選ぶだけ。\nWSL で使う場合すでに Remote で使っている扱いになるからか SSH できない…?\n\nこれは Windows 側のホームを参照してコマンドプロンプトから ssh しようとするかららしい。\n解決策を調べてみると鍵を Windows ホームに置くとか出るけどほんとにそれでええんか？\nWSL で動かしてるときは WSL のホームを参照する、みたいな設定できないだろうか。\n\nこれは偉大な先人たちが試しているけどどうも settings.json の設定では無理らしい。\nwindows 側に .bat おいて wsl の ssh 使わせれば行けるらしいがそこまでするのは気が引ける。\n\nということで WSL のホームにある ~/.ssh/ を Windows 側のホームにコピーしてしのぐ。\n\n\n\nQuarto\nhttps://quarto.org/docs/tools/vscode.html\n\n準備\n\nVSCode に Quarto の拡張機能をインストールする。\nQuarto CLI をマシンにインストールする。\n## Mac なら homebrew で\nbrew install --cask quarto\n\n## WSL は .deb を落としてくるのが正攻法？\nsudo curl -LO https://quarto.org/download/latest/quarto-linux-amd64.deb\n# sudo apt-get install gdebi-core  # if needed\nsudo gdebi quarto-linux-amd64.deb\n\n\n\nRender\n右上の Render ボタンから。 もしくは Control/CommandShiftK。\n\n\n\nR\n\nR に languageserver を入れる。\ninstall.packages(\"languageserver\")\nVSCode に R の拡張機能を入れる。\n環境設定ファイルに追記:\n\n\nsettings.json\n\n{\n  \"r.sessionWatcher\": true\n}\n\n\n\nkeybindings.json\n\n# ctrl+enterでコマンドをターミナルに送るための設定\n[\n  {\n    \"key\": \"ctrl+enter\",\n    \"command\": \"workbench.action.terminal.runSelectedText\",\n    \"when\": \"editorTextFocus\"\n  }\n]\n\nコマンドパレットを開いて “R: Create R terminal”",
    "crumbs": [
      "開発環境",
      "Visual Studio Code"
    ]
  },
  {
    "objectID": "python/0_install.html",
    "href": "python/0_install.html",
    "title": "Python 環境構築",
    "section": "",
    "text": "Python を使うための環境構築に関するメモ。",
    "crumbs": [
      "Python",
      "Python 環境構築"
    ]
  },
  {
    "objectID": "python/0_install.html#ガイドライン",
    "href": "python/0_install.html#ガイドライン",
    "title": "Python 環境構築",
    "section": "ガイドライン",
    "text": "ガイドライン\n\nPython と Anaconda\nPython パッケージをどう利用するかに、大きく2つの方法 (流派?) がある。\n\npip を使って The Python Package Index (PyPI) から取得する。\nconda を使って Anaconda から取得する。\n\n\nAnaconda はデータサイエンスや科学技術計算のためのさまざまなツールやライブラリの実行環境。 パッケージ管理も仮想環境も全部担う。\n\nPyPI と Anaconda の併用は困難。 特に同じパッケージを pip と conda の両方で入れるのは避けたほうがいいらしい。 プログラミング入門の場合は PyPI、データサイエンス・科学技術計算には Anaconda が推奨されている。",
    "crumbs": [
      "Python",
      "Python 環境構築"
    ]
  },
  {
    "objectID": "python/0_install.html#python-のインストール",
    "href": "python/0_install.html#python-のインストール",
    "title": "Python 環境構築",
    "section": "Python のインストール",
    "text": "Python のインストール\n\nMacOS\nMacOS 用のインストーラか、 Homebrew を使う。\n# Homebrew による python インストール\n# Homebrew 自体のインストールは割愛\n\nberw install python3\n\n# 複数バージョンのインストール\nbrew install python@3.7  # バージョンを指定してインストール\nln -s /usr/local/opt/python@3.7/bin/python3.7 /usr/local/bin/python3.7  # /usr/local/bin/ にシンボリックリンク\n\n\nWindows\n\nhttps://www.python.jp/install/windows/index.html\nhttps://learn.microsoft.com/ja-jp/windows/python/beginners\nhttps://docs.python.org/ja/3/using/windows.html\n\nWindows用のインストーラを使う。 最初に出てくるウィンドウで “Add PATH” にチェックを入れる。\nWindows の場合、Microsoft ストアからインストールする方法もある。 初学者向けには推奨されているが、 ディレクトリやレジストリへのアクセス制限があるため使いようによっては不具合の原因になる。\n\n\nUbuntu\nsudo apt update\nsudo apt install build-essential libbz2-dev libdb-dev \\\n  libreadline-dev libffi-dev libgdbm-dev liblzma-dev \\\n  libncursesw5-dev libsqlite3-dev libssl-dev \\\n  zlib1g-dev uuid-dev tk-dev\nダウンロードページからソースコードをダウンロードして解凍、ビルド:\ntar xJf Python-3.x.y.tar.xz\ncd Python-3.x.y\n./configure\nmake\nsudo make install\nデフォルトでは usr/local/bin にインストールされる。\n\nUbuntuの pip\nsudo apt install python3-pip\nOS 標準の Python 環境のパッケージ管理は pip ではなく apt を介して行うのが安全。 apt との衝突を避けるためか、Ubuntu 標準の pip は sudo なしで実行すると --user つきで実行された扱いになってパッケージは ~/.local/ にインストールされる。\n\n\n\npyenv によるインストール\npyenv は複数バージョンの Python を切り替えながら利用するためのツール。 Python x.y.z のマイナーバージョンまで切り替えて使えるが、そこまで必要か？という説もある。\n\n必要に応じてビルド環境の用意\npyenv のインストール:\ngit clone https://github.com/pyenv/pyenv.git ~/.pyenv\n# or\nbrew install pyenv\n環境設定:\n~/.bash_profile など\nexport PYENV_ROOT=\"$HOME/.pyenv\"\nexport PATH=\"$PYENV_ROOT/bin:$PATH\"\neval \"$(pyenv init -)\"\nバージョンを探してインストール:\npyenv install --list\npyenv install 3.11.3\nバージョンを切り替える:\npyenv global 3.11.3  # システム全体で切り替え\npyenv local 3.11.3   # 実行したディレクトリのみで切り替え",
    "crumbs": [
      "Python",
      "Python 環境構築"
    ]
  },
  {
    "objectID": "python/0_install.html#pyenv",
    "href": "python/0_install.html#pyenv",
    "title": "Python 環境構築",
    "section": "Pyenv",
    "text": "Pyenv\nhttps://github.com/pyenv/pyenv\nPython のバージョン管理ツール。 python3.x.y, python2.x.y などのバージョンごとのインストール、管理のほか、 conda 環境も Pyenv 越しに用意することができる。\n\nよく使うコマンド\n\npyenv --version\n\npyenv 自体のバージョンを確認\n\npyenv version\n\nいま指定されている Python のバージョンを表示する。\n\npyenv versions\n\n利用可能な Python のバージョン一覧を表示する。(c.f. $PYENV_ROOT/versions/*)\n\n\nいま指定されているバージョンには * がついている。\n\npyenv install -l/--list\n\nインストール可能なすべてのバージョンを表示する。\n\n\ngrep で絞ったり。(e.g. pyenv install -l | grep \"miniconda\")\n\npyenv install &lt;version&gt;\n\n指定したバージョンをインストールする。\n\npyenv rehash\n\n新規インストール時に必要な処理らしい。shims をなんとかする。ドキュメントなし。\n\npyenv uninstall &lt;version&gt;\n\n指定したバージョンをアンインストールする。\n\npyenv global &lt;version&gt;\n\nグローバルな python のバージョンを指定する。\n\n\npyenv global 3.7.0 2.7.15 のように python2 と python3 をそれぞれ指定することもできる。\n\npyenv local &lt;version&gt;\n\nローカルなプロジェクトで使う python のバージョンを指定する。\n\n\n解除する時は pyenv local --unset",
    "crumbs": [
      "Python",
      "Python 環境構築"
    ]
  },
  {
    "objectID": "python/0_install.html#pip",
    "href": "python/0_install.html#pip",
    "title": "Python 環境構築",
    "section": "pip",
    "text": "pip\nPyPI(The Python Package Index) に公開されている Python パッケージを管理するコマンド。\npython3 -m pip など、バージョンや現在使っている環境を明示した使い方が 推奨されている。\n\nよく使うコマンド\n\npip3 install &lt;package&gt;\n\nパッケージのインストール\n\n\nローカルインストールは -e/--editable が便利: pip3 install -v -e /path/to/pkg\n\npip3 uninstall &lt;package&gt;\n\nパッケージのアンインストール\n\npip3 list\n\nインストール済みパッケージの表示\n\n\noutdated なパッケージをまとめて更新:\npip3 list -o | tail -n +3 | awk '{ print $1 }' | xargs pip3 install -U",
    "crumbs": [
      "Python",
      "Python 環境構築"
    ]
  },
  {
    "objectID": "python/0_install.html#venv",
    "href": "python/0_install.html#venv",
    "title": "Python 環境構築",
    "section": "venv",
    "text": "venv\nプロジェクトごとに専用の Python 実行環境を作成する。\n\nプロジェクトを作成する:\nmkdir proj\ncd proj\n仮想環境を作成する:\npython3 -m venv .venv\n仮想環境へ切り替える:\nsource .venv/bin/activate\n# or\n. .venv/bin/activate\n(.venv) $\nターミナル先頭に (.venv) と表示され、仮想環境での実行状態になる。\n(.venv) $ deactivate  # 仮想環境の終了\nパッケージのインストール:\n仮想環境中でインストールしたパッケージはその環境内でのみ使用できる。 requirements.txt を使った環境のコピーも可能。\npython3 -m pip install pandas\npython3 -m pip freeze &gt; requirements.txt     # パッケージ一覧を書き出し\npython3 -m pip install -r requirements.txt   # まとめてインストール\n仮想環境でのパッケージのインストール先は .venv/lib/python3.11/site-packages/ になる。 バイナリ実行ファイルは .venv/bin/ にあり、python3, pip もここに PATH が通る。",
    "crumbs": [
      "Python",
      "Python 環境構築"
    ]
  },
  {
    "objectID": "python/0_install.html#uv",
    "href": "python/0_install.html#uv",
    "title": "Python 環境構築",
    "section": "uv",
    "text": "uv\n上記すべてをお世話してくれる Rust 製コマンドラインツールの uv という選択肢もある。\nPython 自体のインストールは uv python install、 パッケージ管理は uv tool や uv add、 仮想環境込みのプロジェクト管理は uv init など。",
    "crumbs": [
      "Python",
      "Python 環境構築"
    ]
  },
  {
    "objectID": "python/argparse.html",
    "href": "python/argparse.html",
    "title": "ArgumentParser — コマンドライン引数の実装",
    "section": "",
    "text": "Python プログラム実行時にコマンドライン引数を受け取る処理を簡単に実装できる標準ライブラリ。 sys とかでも似たことは実現できるけど使い勝手と可読性は argparse の方が圧倒的にいい。",
    "crumbs": [
      "Python",
      "ArgumentParser"
    ]
  },
  {
    "objectID": "python/argparse.html#基本的な使い方",
    "href": "python/argparse.html#基本的な使い方",
    "title": "ArgumentParser — コマンドライン引数の実装",
    "section": "基本的な使い方",
    "text": "基本的な使い方\nimport argparse\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(\"--input\")          # オプション引数\nparser.add_argument(\"-o\", \"--output\")   # ハイフン1つの省略形も追加できる\nparser.add_argument(\"arg1\")             # ポジション引数\nparser.add_argument(\"arg2\", help=\"２つ目のポジション引数\")  # --helpしたときの説明を書いておける\n\nargs = parser.parse_args()\n\nprint(\"arg1=\"+args.arg1)\nprint(\"arg2=\"+args.arg2)\nprint(\"arg3=\"+args.input)\nprint(\"arg4=\"+args.output)\n実行する:\npython3 test.py hoge fuga --input koke -o piyo\n# arg1=hoge\n# arg2=fuga\n# arg3=koke\n# arg4=piyo\nポジション引数は順番通りならどこでもいい:\npython3 test.py hoge --input koke -o piyo fuga\n# arg1=hoge\n# arg2=fuga\n# arg3=koke\n# arg4=piyo\n-h, --help でヘルプを表示:\npython3 test.py -h\n# usage: test.py [-h] [--input INPUT] [-o OUTPUT] arg1 arg2\n#\n# positional arguments:\n#   arg1\n#   arg2                  ２つ目のポジション引数\n#\n# optional arguments:\n#   -h, --help            show this help message and exit\n#   --input INPUT\n#   -o OUTPUT, --output OUTPUT",
    "crumbs": [
      "Python",
      "ArgumentParser"
    ]
  },
  {
    "objectID": "python/argparse.html#ポジション引数",
    "href": "python/argparse.html#ポジション引数",
    "title": "ArgumentParser — コマンドライン引数の実装",
    "section": "ポジション引数",
    "text": "ポジション引数\nparser.add_argument(\"argN\") とすると必須引数扱いになり、指定しないとエラーになる。",
    "crumbs": [
      "Python",
      "ArgumentParser"
    ]
  },
  {
    "objectID": "python/argparse.html#オプション引数",
    "href": "python/argparse.html#オプション引数",
    "title": "ArgumentParser — コマンドライン引数の実装",
    "section": "オプション引数",
    "text": "オプション引数\n\nデフォルト値と型の指定\nオプション引数は指定しないと None が入る。 これ以外にデフォルト値を設定したり、データ型を指定することができる。\nparser.add_argument(\"-n\", \"--number\", type=float, default=0.0)\n異なる型を指定するとエラーになる(int -&gt; float は勝手に変換される):\npython3 test.py --number hoge\n# test.py: error: argument --number: invalid float value: 'hoge'\n\n\nあらかじめ引数の選択肢を設定\nparser.add_argument(\"-l\", \"--letter\", choices=[\"hoge\", \"fuga\", \"piyo\"])\n選択肢以外の引数を指定するとエラーになる。\n\n\n複数個の引数を受け取る\nparser.add_argument(\"-a\", \"--alphabet\", nargs=\"*\")\nargs = parser.parse_args()\nprint(args.alphabet)\n受け取った引数はリストになって利用できる:\npython3 test.py --alphabet A G X\n# ['A', 'G', 'X']\n\n\nオプション引数を必須引数にする\nparser.add_argument(\"-n\", \"--need\", requied=True)",
    "crumbs": [
      "Python",
      "ArgumentParser"
    ]
  },
  {
    "objectID": "python/evoltree.html",
    "href": "python/evoltree.html",
    "title": "EvolTree — Python で dN/dS 解析",
    "section": "",
    "text": "EvolTree は、ETE toolkit の ete-evol を Python スクリプトの中で動かすための拡張クラス。",
    "crumbs": [
      "Python",
      "EvolTree"
    ]
  },
  {
    "objectID": "python/evoltree.html#installation",
    "href": "python/evoltree.html#installation",
    "title": "EvolTree — Python で dN/dS 解析",
    "section": "Installation",
    "text": "Installation\nete-toolkit を参照",
    "crumbs": [
      "Python",
      "EvolTree"
    ]
  },
  {
    "objectID": "python/evoltree.html#準備",
    "href": "python/evoltree.html#準備",
    "title": "EvolTree — Python で dN/dS 解析",
    "section": "準備",
    "text": "準備\n系統樹とアライメントを読み込む:\nfrom ete3 import EvolTree\n\ntree = EvolTree(\n  \"((Hylobates_lar,(Gorilla_gorilla,Pan_troglodytes)),Papio_cynocephalus);\",\n  binpath = path_to_codeml\n)\ntree.link_to_alignment(\"\"\"\n  &gt;Hylobates_lar\n  ATGGCCAGGTACAGATGCTGCCGCAGCCAGAGCCGGAGCAGATGTTACCG\n  CCAGAGCCGGAGCAGATGTTACCGCCAGAGGCAAAGCCAGAGTCGGAGCA\n  GATGTTACCGCCAGAGCCAGAGCCGGAGCAGATGTTACCGCCAGAGACAA\n  AGAAGTCGGAGACGAAGGAGGCGGAGCTGCCAGACACGGAGGAGAGCCAT\n  GAGGTGT---CGCCGCAGGTACAGGCTGAGACGTAGAAGCTGTTACCACA\n  TTGTATCT\n  &gt;Papio_cynocephalus\n  ATGGCCAGGTACAGATGCTGCCGCAGCCAGAGCCGAAGCAGATGCTATCG\n  CCAGAGCCGGAGCAGATGTAACCGCCAGAGACAGAGCCAAAGCCGGAGAA\n  GCTGCTATCGCCAGAGCCAAAGCCGGAGCAGATGTTACCGCCAGAGACAG\n  AGAAGTCGTAGACGAAGGAGGCGACGCTGCCAGACACGGAGGAGAGCCAT\n  GAGGTGCTTCCGCCGCAGGTACAGGCTGAGGCGTAGGAGGCCCTATCACA\n  TCGTGTCT\n  &gt;Gorilla_gorilla\n  ATGGCCAGGTACAGATGCTGTCGCAGCCAGAGCCGCAGCAGATGTTACCG\n  GCAGAGCCGGAGCAGGTGTTACCGGCAGAGACAAAGCCAGAGCCGGAGCA\n  GATGCTACCGGCAGAGCCAAAGCCGGAGCAGGTGTTACCGGCAGAGACAA\n  AGAAGTCGCAGACGTAGGCGGAGGAGCTGCCAGACACGGAGGAGAGCCAT\n  GAGGTGCTGCCGCCGCAGGTACAGACTGAGACGTAGAAGACCCTATCATA\n  TTGTATCT\n  &gt;Pan_troglodytes\n  ATGGCCAGGTACAGATGCTGTCGCAGCCAGAGCCGGAGCAGATGTTACCG\n  GCAGAGACGGAGCAGGTGTTACCGGCAAAGGCAAAGCCAAAGTCGGAGCA\n  GATGTTACCGGCAGAGCCAGAGACGGAGCAGGTGTTACCGGCAAAGACAA\n  AGAAGTCGCAGACGAAGGCGACGGAGCTGCCAGACACGGAGGAGAGCCAT\n  GAGGTGCTGCCGCCGCAGGTACAGACTGAGACGTAAAAGATGTTACCATA\n  TTGTATCT\n\"\"\")\ntree.workdir = \"/path_to/my_working_directory/\"\nbinpath は何も指定しないと ete3 と同じ PATH を探しにいって怒られる。 (codeml に PATH を通していても。)",
    "crumbs": [
      "Python",
      "EvolTree"
    ]
  },
  {
    "objectID": "python/evoltree.html#共通",
    "href": "python/evoltree.html#共通",
    "title": "EvolTree — Python で dN/dS 解析",
    "section": "共通",
    "text": "共通\n\ntree.mark_tree(node_ids, marks)\n\nbranch モデルや branch-site モデルに使う系統樹のマーキングをする。\n\n\nnode_ids、marks には、同じ長さのリストを渡す。\n\n\n(例) tree.mark_tree([2,3], marks=[\"#1\", \"#2\"])\n\ntree.run_model(model_name)\n\nbinpath で指定した codeml でモデルを推定する。\n\n\nモデルの種類については ete-evol を参照。\n\ntree.get_evol_model(model_name)\n\n推定したモデルのパラメータなどが入った Model オブジェクトを返す。\n\ntree.get_most_likely(altn, null)\n\n対立仮説 vs 帰無仮説での尤度比検定の P 値を返す。",
    "crumbs": [
      "Python",
      "EvolTree"
    ]
  },
  {
    "objectID": "python/evoltree.html#site-モデル",
    "href": "python/evoltree.html#site-モデル",
    "title": "EvolTree — Python で dN/dS 解析",
    "section": "Site モデル",
    "text": "Site モデル\nM2 vs M1 で正の自然選択が働いたサイトを検出:\ntree.run_model(\"M1\")    # 帰無仮説\ntree.run_model(\"M2\")    # 対立仮説\n\nm2 = tree.get_evol_model(\"M2\")\npval = tree.get_most_likely(\"M2\", \"M1\")\n\nif pval &lt; 0.05:\n  for site in range(len(m2.sites[\"BEB\"][\"aa\"])):\n    if m2.sites[\"BEB\"][\"p2\"][site] &gt; 0.95:\n      print(\"Positively selected site %s at position: %s, with probability: %s\" % (model2.sites['BEB']['aa'][site], site+1, model2.sites['BEB']['p2'][site]))\nelse:\n  print(\"Model M1 is not rejected.\")\nmodel.sites[\"BEB\"] には BEB 法 (Bayes empirical Bayes 法) により求められたサイトごとのパラメータが入っている。\nmodel.sites[\"BEB\"][\"p2\"] はそのサイトが \\omega &gt; 1 で正の選択下にある事後確率であり、 一般的にはこの事後確率が0.95や0.99を超えていた場合に正の選択が働いたサイトとする。",
    "crumbs": [
      "Python",
      "EvolTree"
    ]
  },
  {
    "objectID": "python/evoltree.html#branch-モデル",
    "href": "python/evoltree.html#branch-モデル",
    "title": "EvolTree — Python で dN/dS 解析",
    "section": "Branch モデル",
    "text": "Branch モデル\ntree.mark_tree() が node_id でしか動かないのが少し不便。 tip 名でうまく指定できるように関数を書く:\ndef get_node_ids(tree, names: list[str]) -&gt; list[int]:\n  node_ids = [ leaf.node_id for leaf in tree if leaf.name in names ]\n  return node_ids\n\ndef get_mrca_node_ids(tree, names: list[str]) -&gt; list[int]:\n  node_ids = [ get_node(tree, name) for name in names ]\n  anc = tree.get_common_ancestor(node_ids)\n  return [anc.node_id]\nGorilla_gorilla と Pan_troglodytes の共通祖先の枝を指定:\nnode_ids = get_mrca_node_ids(tree, [\"Gorilla_gorilla\", \"Pan_troglodytes\"])\ntree.mark_tree(node_ids, marks=['#1']*len(node_ids))\nprint(tree.write())\n# ((Hylobates_lar,(Gorilla_gorilla,Pan_troglodytes) #1),Papio_cynocephalus);\nb_free vs M0 で特定の枝で \\omega が異なるかを検定:\ntree.run_model(\"b_free\")\ntree.run_model(\"M0\")\n\nb_free = tree.get_evol_model(\"b_free\")\npval = tree.get_most_likely(\"b_free\", \"M0\")\n\ndef get_omega(tree, model):\n  \"\"\"\n  b_free から ω を取得するのもちょっとメンドいので関数書いちゃう\n  \"\"\"\n  mark2omega = {}\n  result = tree.get_evol_model(model)\n  for attr in result.branches.values():\n    mark = attr.get('mark')\n    omega = attr.get('w')\n    mark2omega[mark] = omega\n  return mark2omega\n\nif pval &lt; 0.05:\n  wfgb = get_omega(tree, \"b_free\")[\" #1\"]\n  wbgb = get_omega(tree, \"b_free\")[\" #0\"]\n  print(\"Foreground branches evolving at omega value of %s significantly diferent from %s.' % (wfrg, wbkg)\")\nelse:\n  print(\"Model b_neut is not rejected.\")\n正の選択かどうか調べたければ b_free vs b_neut をやって wfgb &gt; 1 かどうかをみる。",
    "crumbs": [
      "Python",
      "EvolTree"
    ]
  },
  {
    "objectID": "python/evoltree.html#branch-site-モデル",
    "href": "python/evoltree.html#branch-site-モデル",
    "title": "EvolTree — Python で dN/dS 解析",
    "section": "Branch-site モデル",
    "text": "Branch-site モデル\nBranch モデルの時と同じ枝で、 bsA vs bsA1 で正の選択が働いたサイトを検出:\ntree.run_model('bsA')\ntree.run_model('bsA1')\n\npval = tree.get_most_likely('bsA', 'bsA1')\nbsA = tree.get_evol_model('bsA')\n\nif pval &lt; 0.05:\n  for site in range(len(bsA.sites[\"BEB\"][\"aa\"])):\n    if bsA.sites[\"BEB\"][\"p2\"][site] &gt; 0.95:\n      print(\"Positively selected site %s at position: %s, with probability: %s\" % (bsA.sites['BEB']['aa'][site], site+1, bsA.sites['BEB']['p2'][site]))\nelse:\n  print(\"Model bsA1 is not rejected.\")",
    "crumbs": [
      "Python",
      "EvolTree"
    ]
  },
  {
    "objectID": "python/python-tips.html#main-関数",
    "href": "python/python-tips.html#main-関数",
    "title": "Python 小技メモ",
    "section": "main() 関数",
    "text": "main() 関数\nPython コードで以下のように main() という関数を定義してその中に処理を書き、最後に実行する書き方。 回りくどく見えるがいくつかメリットがある。\n\n処理全体の流れを把握しやすい。\n関数の定義を後ろに書ける。\n意図しない変数の衝突を回避する。\n\ndef main():\n    # 何らかの処理\n\nif __name__ == \"__main__\":\n    main()\n\n最後の if のブロックは何？\nif __name__ == \"__main__\": の記述は、 このスクリプト自体が Python スクリプトとして実行された場合 (python3 hoge.py という形で実行された場合) に以降の処理を実行することを意味している。\n例えば、モジュールとしてほかのスクリプトから読み込まれた場合は 勝手に実行されると困るのでそれを防いでいる。",
    "crumbs": [
      "Python",
      "Python 小技メモ"
    ]
  },
  {
    "objectID": "python/python-tips.html#不定個の引数をとる関数の定義",
    "href": "python/python-tips.html#不定個の引数をとる関数の定義",
    "title": "Python 小技メモ",
    "section": "不定個の引数をとる関数の定義",
    "text": "不定個の引数をとる関数の定義\n引数に * や ** をつける。 1つだとタプル、2つだと辞書に格納される。 慣例的に *args, **kwargs が使われている。\ndef sum_some_numbers(*args):\n  return sum(args)\n\nprint(sum_some_numbers(1,2,3,4))\n# 10\ndef en2ja(**kwargs):\n  for k,v in kwargs.items():\n    print(k, \"means\", v)\n\nen2ja(cat=\"neko\", dog=\"inu\", mouse=\"nezumi\")\n# cat means neko\n# dog means inu\n# mouse means nezumi",
    "crumbs": [
      "Python",
      "Python 小技メモ"
    ]
  },
  {
    "objectID": "python/python-tips.html#いつも忘れるlistのソート",
    "href": "python/python-tips.html#いつも忘れるlistのソート",
    "title": "Python 小技メモ",
    "section": "いつも忘れるlistのソート",
    "text": "いつも忘れるlistのソート\n\nsort() はメソッド、破壊的\nsorted() は関数、非破壊的\n\nsort() は元のリストそのものを並び替える:\n&gt;&gt;&gt; l = [3, 4, 1, 5, 2]\n&gt;&gt;&gt; l.sort(reversed = False)\n&gt;&gt;&gt; l\n[1, 2, 3, 4, 5]\nsorted() は元のリストはそのままで、要素を並び替えた新しいリストを返す:\n&gt;&gt;&gt; l = [3, 4, 1, 5, 2]\n&gt;&gt;&gt; ll = sorted(l, reverse = False)\n&gt;&gt;&gt; ll\n[1, 2, 3, 4, 5]\n&gt;&gt;&gt; l\n[3, 4, 1, 5, 2]\n\n文字数や絶対値でソート\n&gt;&gt;&gt; l = [\"ccc\", \"c\", \"cc\"]\n&gt;&gt;&gt; l.sort(key = len)\n&gt;&gt;&gt; l\n['c', 'cc', 'ccc']\n\n&gt;&gt;&gt; l = [3, -4, 1, 5, -2]\n&gt;&gt;&gt; sorted(l)\n[-4, -2, 1, 3, 5]\n&gt;&gt;&gt; sorted(l, key =　abs)\n[1, -2, 3, -4, 5]",
    "crumbs": [
      "Python",
      "Python 小技メモ"
    ]
  },
  {
    "objectID": "python/python-tips.html#辞書型-keyerror-への対処",
    "href": "python/python-tips.html#辞書型-keyerror-への対処",
    "title": "Python 小技メモ",
    "section": "辞書型 — KeyError への対処",
    "text": "辞書型 — KeyError への対処\n通常、辞書型で存在しないキーを検索するとエラーが返ってくる:\n&gt;&gt;&gt; dict = {\"one\":1, \"two\":2, \"three\":3}\n&gt;&gt;&gt; print(dict[\"four\"])\nKeyError: 'four'\n辞書型を使っていると、存在しないキーを指定した時も柔軟にやってほしいと思うことがよくある。 そこで get() メソッド:\n&gt;&gt;&gt; dict = {\"one\":1, \"two\":2, \"three\":3}\n&gt;&gt;&gt; print(dict.get(\"four\"))\nNone\ndict.get(key) で存在しないキーを引数にすると None が返ってくる。 さらに偉いのは、返ってくる値を第二引数に指定できる。\n&gt;&gt;&gt; dict = {\"one\":1, \"two\":2, \"three\":3}\n&gt;&gt;&gt; print(dict.get(\"four\", \"No such a key\"))\nNo such a key",
    "crumbs": [
      "Python",
      "Python 小技メモ"
    ]
  },
  {
    "objectID": "python/python-tips.html#pdf2pptx-pdf-から-powerpoint-スライドへの簡易変換",
    "href": "python/python-tips.html#pdf2pptx-pdf-から-powerpoint-スライドへの簡易変換",
    "title": "Python 小技メモ",
    "section": "pdf2pptx — PDF から PowerPoint スライドへの簡易変換",
    "text": "pdf2pptx — PDF から PowerPoint スライドへの簡易変換\nPDF をページごとにパワーポイントのスライドに貼り付けて使いたい、という単純な操作が、 既存の方法だとページごとにスクショして貼る、という原始的な方法くらいしかなかった。\npdf2pptx は pdf2pptx input という単純なコマンドで PDF の各ページを PNG イメージとしてパワポに貼り付ける。\npython3 -m pip install pdf2pptx\npdf2pptx --help\npdf2pptx hoge.pdf\n\n-o, --output\n\n出力ファイルの指定。デフォルトは入力ファイルの拡張子 .pptx 。\n\n-r, --resolution\n\n1inch あたりのドット数で解像度を指定。 デフォルトは300だが150とかでも十分可読でファイルサイズも抑えられる。\n\n-q, --quiet\n\nログの非表示\n\n--from\n\nPDF の何ページ目からパワポに変換するか。\n\n--count\n\nPDF の何ページ分パワポに変換するか。",
    "crumbs": [
      "Python",
      "Python 小技メモ"
    ]
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#今日やること",
    "href": "slides/git-circle/git-vol2.html#今日やること",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "今日やること",
    "text": "今日やること\n\n前回の復習\ngit status と git log に慣れる\nリモートリポジトリの変更を手元に反映させる\nあえて競合を起こしてそれを解決してみる（時間があれば）\n\n\n参考\n\n過去の牧野研での git 講習資料\n\n\ngit 公式リファレンス\n\n\nkaito256さん: Github演習"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#前回やったこと",
    "href": "slides/git-circle/git-vol2.html#前回やったこと",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "前回やったこと",
    "text": "前回やったこと\n\ngit  をインストールする。\nGithub  に個人アカウントをつくる。\nGitの初期設定をする: ~/.gitconfig\nSSHの設定をする: ~/.ssh/"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#前回の復習-手元のプロジェクトをgitで管理する",
    "href": "slides/git-circle/git-vol2.html#前回の復習-手元のプロジェクトをgitで管理する",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "前回の復習: 手元のプロジェクトをGitで管理する",
    "text": "前回の復習: 手元のプロジェクトをGitで管理する\n\n適当なディレクトリを作ってテキストファイル README.md を新規作成する:\nmkdir new_project && cd new_project\necho Hello, world! &gt; README.md\nローカルリポジトリをつくる:\ngit init\nローカルリポジトリに README.md をコミットする。\n最初は git status や git log で頻繁に確認すると安心。\ngit status\ngit add README.md  # README.mdをindexに登録\ngit status\ngit commit -m \"Create README.md\" # コミットメッセージを添えてコミット\ngit status\ngit log"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#前回の復習-手元のプロジェクトをgithubで管理する",
    "href": "slides/git-circle/git-vol2.html#前回の復習-手元のプロジェクトをgithubで管理する",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "前回の復習: 手元のプロジェクトをGithubで管理する",
    "text": "前回の復習: 手元のプロジェクトをGithubで管理する\n\nGitHubアカウントページの右上の “+” から “New repository” を選択する。\n適当なリポジトリ名（基本は手元と同じ）をつけて “Create repository” を押す。\n手順が表示されるので基本的にそれに従う:\ngit remote add origin https://github.com/USER_NAME/new_project.git  # リモートリポジトリを紐づける\ngit remote -v               # ちゃんと紐づいたか確認\n# git branch -M main        # ブランチの名前をmainに\ngit push -u origin main     # リモートにpush\ngit status\n “Private” リポジトリの場合、SSHで紐付けしないと下り( fetch, pull )でもパスワードを聞かれる。\nリポジトリのページを更新して README.md が見えるか確認する。"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#前回の復習-既存のリポジトリを手元に落としてくる",
    "href": "slides/git-circle/git-vol2.html#前回の復習-既存のリポジトリを手元に落としてくる",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "前回の復習: 既存のリポジトリを手元に落としてくる",
    "text": "前回の復習: 既存のリポジトリを手元に落としてくる\n\nGitHub上の適当なリポジトリをひとつ選ぶ。 (e.g., https://github.com/ymat2/practice_git)\n右の方の &lt;&gt;Code▼ ボタンを押す。\nSSHではなくHTTPSを選択し、URLをコピー。\ngit clone https://github.com/ymat2/practice-git.git\n中身を眺めてみる:\ncd practice-git\nls -al\ngit log\n\n\n\nclone はどんな時に使う?\n\n他人の作ったソフトウェアをインストールして使うとき\n\n\n新しいPCで最初に作業を始めるとき\n\n\netc."
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#準備運動-git-status-と-git-log-に慣れる",
    "href": "slides/git-circle/git-vol2.html#準備運動-git-status-と-git-log-に慣れる",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "準備運動:　git status と git log に慣れる",
    "text": "準備運動:　git status と git log に慣れる\nまずは何もしていない状態で git status & git log\ngit status\n# On branch main\n# Your branch is up to date with 'origin/main'.\n#\n# nothing to commit, working tree clean\n\ngit log --oneline --graph   # 1コミット1行で, グラフィカルに\n# * 36d0617 (HEAD -&gt; main, origin/main) Create README.md\n\norigin\n\nリモートリポジトリのこと。\n\n\norigin/main はリモートリポジトリのmainブランチ。\n\nHEAD\n\nいま見ているブランチ/commitを指す目印。\n\n\n基本的には「手元の最新のcommit」を表す。"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#準備運動-git-status-と-git-log-に慣れる-1",
    "href": "slides/git-circle/git-vol2.html#準備運動-git-status-と-git-log-に慣れる-1",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "準備運動:　git status と git log に慣れる",
    "text": "準備運動:　git status と git log に慣れる\nREADME.md をさらに編集してみる:\n# Hello, world!\nThis is a practice of `git`.\n\ngit status すると:\ngit status\n# On branch main\n# Your branch is up to date with 'origin/main'.\n#\n# Changes not staged for commit:\n#   (use \"git add &lt;file&gt;...\" to update what will be committed)\n#   (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n#   modified:   README.md\n#\n# no changes added to commit (use \"git add\" and/or \"git commit -a\")"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#準備運動-git-status-と-git-log-に慣れる-2",
    "href": "slides/git-circle/git-vol2.html#準備運動-git-status-と-git-log-に慣れる-2",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "準備運動:　git status と git log に慣れる",
    "text": "準備運動:　git status と git log に慣れる\nREADME.md をindexに加える:\ngit add README.md\n\nここでも git status :\ngit status\n# On branch main\n# Your branch is up to date with 'origin/main'.\n#\n# Changes to be committed:\n#   (use \"git restore --staged &lt;file&gt;...\" to unstage)\n#   modified:   README.md\n↑ 「間違えて add しちゃった」って時は git restore --staged README.md すればいい。"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#準備運動-git-status-と-git-log-に慣れる-3",
    "href": "slides/git-circle/git-vol2.html#準備運動-git-status-と-git-log-に慣れる-3",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "準備運動:　git status と git log に慣れる",
    "text": "準備運動:　git status と git log に慣れる\nREADME.md の変更をコミットする:\ngit commit -m \"Update README.md\"\n# [main 0f1a686] Update README.md\n#  1 file changed, 2 insertions(+), 1 deletion(-)\n\nここで git status & git log:\ngit status\n# On branch main\n# Your branch is ahead of 'origin/main' by 1 commit.\n#   (use \"git push\" to publish your local commits)\n#\n# nothing to commit, working tree clean\n\ngit log --oneline --graph\n# * 0f1a686 (HEAD -&gt; main) Update README.md     &lt;- HEAD(ローカル)はここに移動\n# * 36d0617 (origin/main) Create README.md      &lt;- origin(リモート)はまだここ"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#準備運動-git-status-と-git-log-に慣れる-4",
    "href": "slides/git-circle/git-vol2.html#準備運動-git-status-と-git-log-に慣れる-4",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "準備運動:　git status と git log に慣れる",
    "text": "準備運動:　git status と git log に慣れる\n最後に git push:\ngit push\n\ngit log で確認:\ngit log --oneline --graph\n# * 0f1a686 (HEAD -&gt; main, origin/main) Update README.md        &lt;- originも追いついた\n# * 36d0617 Create README.md\n\n「あれ、いまどういう状態だっけ？」\n↓\n常に git status, git log を確認する癖をつける。"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#休憩-質問タイム",
    "href": "slides/git-circle/git-vol2.html#休憩-質問タイム",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "休憩 & 質問タイム",
    "text": "休憩 & 質問タイム\n今日やること\n\n前回の復習\ngit status と git log に慣れる\nリモートリポジトリの変更を手元に反映させる\nあえて競合を起こしてそれを解決してみる（時間があれば）"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#リモートリポジトリの変更を手元に反映させる",
    "href": "slides/git-circle/git-vol2.html#リモートリポジトリの変更を手元に反映させる",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "リモートリポジトリの変更を手元に反映させる",
    "text": "リモートリポジトリの変更を手元に反映させる\n複数人で同じリポジトリを使う場合や、 個人で複数のマシンを使って開発する場合など、 別のひと/マシンが push した変更を手元に取り寄せるという操作が必要になる。\ngit fetch + git merge や git pull といったコマンドで、 リモートリポジトリの変更を手元に反映させる。"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#リモートリポジトリの変更を手元に反映させる-1",
    "href": "slides/git-circle/git-vol2.html#リモートリポジトリの変更を手元に反映させる-1",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "リモートリポジトリの変更を手元に反映させる",
    "text": "リモートリポジトリの変更を手元に反映させる\n\ngit fetch\n\nリモートリポジトリの変更をローカルリポジトリに取り込む。\n\n\nこの時点では .git/ 内だけが変更されているため、手元のファイルはそのまま。\n\ngit merge\n\nローカルリポジトリの内容を、手元のファイルに反映する。\n\n\n\ngit pull は git fetch と git merge を一気にやるコマンド。"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#実際にやってみる",
    "href": "slides/git-circle/git-vol2.html#実際にやってみる",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "実際にやってみる",
    "text": "実際にやってみる\n\nリモートでの変更を再現するために、Githubページ上で README.md を編集する。\n\nREADME.md をクリック -&gt; 右上のペンマーク 🖊 から編集画面に入る。\n“This line is edited online.” など適当に編集して、右上の Commit changes を押す。\n表示されるウィンドウはとりあえずそのままで Commit changes\n変更されていることを確認する。\n\n\n\n\nその変更を fetch でローカルリポジトリに取り寄せる:\ngit fetch\n\ngit log --oneline --graph --all    # コミット全部\n# * 47d354f (origin/main) Update README.md      &lt;- origin(リモート)の変更が.git/に反映された\n# * 0f1a686 (HEAD -&gt; main) Update README.md     &lt;- HEAD(ローカル)はまだここ\n# * 36d0617 Create README.md"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#実際にやってみる-1",
    "href": "slides/git-circle/git-vol2.html#実際にやってみる-1",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "実際にやってみる",
    "text": "実際にやってみる\n\nmerge で手元のファイルに反映する:\ngit merge\n# Fast-forward\n#  README.md | 2 ++\n#  1 file changed, 2 insertions(+)\n\ngit log --oneline --graph\n# * 47d354f (HEAD -&gt; main, origin/main) Update README.md    &lt;- HEADがoriginに追いついた\n# * 0f1a686 Update README.md\n# * 36d0617 Create README.md\n\n\n🔰 練習: もう一度リモートで編集して git pull で一気に反映する。"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#head-を-origin-に追いつかせるマージ",
    "href": "slides/git-circle/git-vol2.html#head-を-origin-に追いつかせるマージ",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "HEAD を origin に追いつかせるマージ",
    "text": "HEAD を origin に追いつかせるマージ\n手元のファイルに変更がない場合、fetch してきた origin に追いつくだけでいい。 このようなマージをfast-forward(早送り) マージという。\n\n(このあとFast-Forwardじゃないマージも出てきます。)"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#ここから先は時間があれば進む",
    "href": "slides/git-circle/git-vol2.html#ここから先は時間があれば進む",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "ここから先は時間があれば進む",
    "text": "ここから先は時間があれば進む"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#fast-forwardじゃないマージ",
    "href": "slides/git-circle/git-vol2.html#fast-forwardじゃないマージ",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "Fast-Forwardじゃないマージ",
    "text": "Fast-Forwardじゃないマージ\n手元のファイルも変更していた場合、fetch してきた origin に追いつくのではなく、 分岐した両者を再び1つにするマージが必要。\nこのようなマージをnon-fast forward マージという。"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#手元でもファイルを変更していたらどうなるの",
    "href": "slides/git-circle/git-vol2.html#手元でもファイルを変更していたらどうなるの",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "手元でもファイルを変更していたらどうなるの??",
    "text": "手元でもファイルを変更していたらどうなるの??\n「別のファイルの変更」や「同じファイルの別の箇所の変更」である場合、non-fast forward マージで両方の変更を取り入れる。\n\n\n手元の変更:\n## 第1章\n私はネコである。\n\n## 第2章\nあなたもネコである。\n↓\n## 第1章\n私はイヌである。\n\n## 第2章\nあなたもネコである。\n\nリモートの変更:\n## 第1章\n私はネコである。\n\n## 第2章\nあなたもネコである。\n↓\n## 第1章\n私はネコである。\n\n## 第2章\nあなたもイヌである。\n\n\n↓\ngit fetch + git merge\n↓\n\n## 第1章\n私はイヌである。\n\n## 第2章\nあなたもイヌである。"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#手元でもファイルを変更していたらどうなるの-1",
    "href": "slides/git-circle/git-vol2.html#手元でもファイルを変更していたらどうなるの-1",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "手元でもファイルを変更していたらどうなるの??",
    "text": "手元でもファイルを変更していたらどうなるの??\n「同じファイルの同じ箇所の変更」である場合、conflict が発生する。\n\n\n手元の変更:\n## 第1章\n私はネコである。\n\n## 第2章\nあなたもネコである。\n↓\n## 第1章\n私はイヌである。\n\n## 第2章\nあなたもネコである。\n\nリモートの変更:\n## 第1章\n私はネコである。\n\n## 第2章\nあなたもネコである。\n↓\n## 第1章\n私はサルである。\n\n## 第2章\nあなたもネコである。\n\n\n↓\ngit fetch + git merge\n↓\n\ngit merge\n# Auto-merging README.md\n# CONFLICT (content): Merge conflict in README.md\n# Automatic merge failed; fix conflicts and then commit the result."
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#conflictを解消する",
    "href": "slides/git-circle/git-vol2.html#conflictを解消する",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "conflictを解消する",
    "text": "conflictを解消する\nconflict が生じたファイル( README.md )を開いてみるとこんな風になっている。\n## 第1章\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n私はイヌである。\n=======\n私はサルである。\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; refs/remotes/origin/main\n\n## 第2章\nあなたもネコである。\n\n======= を挟んで、\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD は手元での変更\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; refs/remotes/origin/main はリモートからの変更\n\nを示している。"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#conflictを解消する-1",
    "href": "slides/git-circle/git-vol2.html#conflictを解消する-1",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "conflictを解消する",
    "text": "conflictを解消する\nファイルを編集して conflict を解消する。例えば:\n## 第1章\n私はイヌであるし、サルでもある。\n\n## 第2章\nあなたもネコである。\n\nこの変更をコミットしてリモートにも反映する:\ngit add README.md\ngit commit -m \"Solve a conflict\"\ngit push"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#とにかく使ってみる",
    "href": "slides/git-circle/git-vol2.html#とにかく使ってみる",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "とにかく使ってみる",
    "text": "とにかく使ってみる\n🔰 練習1: 先ほどつくった README.md を編集して複数行の内容にする。できたらコミットしてプッシュ。\n\n🔰 練習2: 手元とリモートで異なる行を編集する。git fetch してから git merge してみる。\n\n手元: 編集したらコミット\nリモート: 編集したらCommit changes\n\n\n🔰 練習3: 手元とリモートで同じ行に異なる編集をする。\n\nまずは手元ではコミットせずに git fetch してから git merge してみる。どんなメッセージが出る？"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#余談-fast-forward-onlyの設定",
    "href": "slides/git-circle/git-vol2.html#余談-fast-forward-onlyの設定",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "余談: Fast-forward onlyの設定",
    "text": "余談: Fast-forward onlyの設定\ngit merge でリモートとローカルの両方の変更を取り込んだ場合、“merge commit”が自動的につくられる。\ngit log --oneline --graph\n# *   03899a3 Merge remote-tracking branch 'refs/remotes/origin/main'\n# |\\                                                    ↑ マージコミット\n# | * 798b869 Edit line.5\n# * | 16117cc Edit line.2\n# |/\n# * 335b76a Some commit"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#余談-fast-forward-onlyの設定-1",
    "href": "slides/git-circle/git-vol2.html#余談-fast-forward-onlyの設定-1",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "余談: Fast-forward onlyの設定",
    "text": "余談: Fast-forward onlyの設定\ngit pull をした時は、「どういう方法でマージするか」を設定していないと自動的なmergeも起こらない。\nhint: You have divergent branches and need to specify how to reconcile them.\nhint: You can do so by running one of the following commands sometime before\nhint: your next pull:\nhint:\nhint:   git config pull.rebase false  # merge (the default strategy)\nhint:   git config pull.rebase true   # rebase\nhint:   git config pull.ff only       # fast-forward only\nhint:\nhint: You can replace \"git config\" with \"git config --global\" to set a default\nhint: preference for all repositories. You can also pass --rebase, --no-rebase,\nhint: or --ff-only on the command line to override the configured default per\nhint: invocation.\nfatal: Need to specify how to reconcile divergent branches.\n\nそこで、「fast-forwardでのmergeのみを試みる。」という設定をしておく。"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#余談-fast-forward-onlyの設定-2",
    "href": "slides/git-circle/git-vol2.html#余談-fast-forward-onlyの設定-2",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "余談: Fast-forward onlyの設定",
    "text": "余談: Fast-forward onlyの設定\n\n方法1\n\n--ff-only オプション付きで git pull する。\ngit pull --ff-only\n\n方法2\n\n~/.gitconfig に --ff-only の設定をする。\ngit config --global pull.ff only\nもしくは\n\n\n~/.gitconfig\n\n[pull]\n    ff = only"
  },
  {
    "objectID": "slides/git-circle/git-vol2.html#余談2-その他の-git-便利機能",
    "href": "slides/git-circle/git-vol2.html#余談2-その他の-git-便利機能",
    "title": "Git 基本操作② — fetch, merge, pull",
    "section": "余談2: その他の git 便利機能",
    "text": "余談2: その他の git 便利機能\n\n「あのファイルとこのファイル、どこが変わったんだっけ」\n\ngit diff\n\n「間違えて〇〇しちゃった、取り消したい」\n\ngit reset\n\n「ソースコードは管理したいけど、データや画像は外に出したくないな」\n\n.gitignore\n\n\n\n\nsee more\n\ngit 公式リファレンス"
  },
  {
    "objectID": "slides/lt/ggtree.html#rで系統樹を扱う",
    "href": "slides/lt/ggtree.html#rで系統樹を扱う",
    "title": "Rで系統樹を扱う",
    "section": "Rで系統樹を扱う",
    "text": "Rで系統樹を扱う\n進化生物学の研究において、系統樹を扱う機会は多い。\nここでは、Rで系統樹を可視化する際に便利な ggtree の使い方を紹介する。"
  },
  {
    "objectID": "slides/lt/ggtree.html#必要なパッケージのインストール",
    "href": "slides/lt/ggtree.html#必要なパッケージのインストール",
    "title": "Rで系統樹を扱う",
    "section": "必要なパッケージのインストール",
    "text": "必要なパッケージのインストール\nape をCRANから、ggtree を bioconductor からインストールする。\ninstall.packages(\"ape\")\nlibrary(ape)\n\nif (!require(\"BiocManager\", quietly = TRUE))\n  install.packages(\"BiocManager\")\nBiocManager::install(\"ggtree\")\nlibrary(ggtree)"
  },
  {
    "objectID": "slides/lt/ggtree.html#newickフォーマットとr-ape-におけるオブジェクト",
    "href": "slides/lt/ggtree.html#newickフォーマットとr-ape-におけるオブジェクト",
    "title": "Rで系統樹を扱う",
    "section": "newickフォーマットとR (ape) におけるオブジェクト",
    "text": "newickフォーマットとR (ape) におけるオブジェクト"
  },
  {
    "objectID": "slides/lt/ggtree.html#r標準の-plot-でも可視化はできる",
    "href": "slides/lt/ggtree.html#r標準の-plot-でも可視化はできる",
    "title": "Rで系統樹を扱う",
    "section": "R標準の plot() でも可視化はできる",
    "text": "R標準の plot() でも可視化はできる\n\nset.seed(1)               # シードを設定\ntr = ape::rtree(n = 10)   # 系統樹を生成\nplot(tr)                  # 可視化"
  },
  {
    "objectID": "slides/lt/ggtree.html#ggtree-で系統樹を可視化する",
    "href": "slides/lt/ggtree.html#ggtree-で系統樹を可視化する",
    "title": "Rで系統樹を扱う",
    "section": "ggtree で系統樹を可視化する",
    "text": "ggtree で系統樹を可視化する\n基本的な使い方は ggplot() と同じで、 + を使って指示を重ねていく。\nset.seed(1)                    # シードを設定\ntr = ape::rtree(n = 10)        # 系統樹を生成\nggtree::ggtree(tr)             # 枝のみ描画\n# geom_tiplab() +              # tip(先端)のラベルを表示\n# geom_nodelab(aes(label = node), hjust = -0.2, node = \"internal\")   # 内部ノードを表示"
  },
  {
    "objectID": "slides/lt/ggtree.html#ggtree-で系統樹を可視化する-1",
    "href": "slides/lt/ggtree.html#ggtree-で系統樹を可視化する-1",
    "title": "Rで系統樹を扱う",
    "section": "ggtree で系統樹を可視化する",
    "text": "ggtree で系統樹を可視化する\n基本的な使い方は ggplot() と同じで、 + を使って指示を重ねていく。\nset.seed(1)                    # シードを設定\ntr = ape::rtree(n = 10)        # 系統樹を生成\nggtree::ggtree(tr)             # 枝のみ描画\n  geom_tiplab()                # tip(先端)のラベルを表示\n# geom_nodelab(aes(label = node), hjust = -0.2, node = \"internal\")   # 内部ノードを表示"
  },
  {
    "objectID": "slides/lt/ggtree.html#ggtree-で系統樹を可視化する-2",
    "href": "slides/lt/ggtree.html#ggtree-で系統樹を可視化する-2",
    "title": "Rで系統樹を扱う",
    "section": "ggtree で系統樹を可視化する",
    "text": "ggtree で系統樹を可視化する\n基本的な使い方は ggplot() と同じで、 + を使って指示を重ねていく。\nset.seed(1)                    # シードを設定\ntr = ape::rtree(n = 10)        # 系統樹を生成\nggtree::ggtree(tr)             # 枝のみ描画\n  geom_tiplab() +              # tip(先端)のラベルを表示\n  geom_nodelab(aes(label = node), hjust = -0.2, node = \"internal\")   # 内部ノードを表示"
  },
  {
    "objectID": "slides/lt/ggtree.html#系統樹の形状も様々に変えることができる",
    "href": "slides/lt/ggtree.html#系統樹の形状も様々に変えることができる",
    "title": "Rで系統樹を扱う",
    "section": "系統樹の形状も様々に変えることができる",
    "text": "系統樹の形状も様々に変えることができる\nset.seed(1)                    # シードを設定\ntr = ape::rtree(n = 10)        # 系統樹を生成\nggtree::ggtree(tr, layout = \"rectangular\")  # デフォルト\nggtree::ggtree(tr, layout = \"circular\")\nggtree::ggtree(tr, layout = \"dendrogram\")\nggtree::ggtree(tr, layout = \"slanted\")\nggtree::ggtree(tr, layout = \"ellipse\")\nggtree::ggtree(tr, layout = \"roundrect\")\nggtree::ggtree(tr, layout = \"inward_circular\")\nggtree::ggtree(tr, layout = \"radial\")\nggtree::ggtree(tr, layout = \"ape\")\nggtree::ggtree(tr, layout = \"fan\", open.angle = 120)\nggtree::ggtree(tr, layout = \"equal_angle\")\nggtree::ggtree(tr, layout = \"daylight\")\nggtree::ggtree(tr, layout = \"rectangular\", branch.length = 'none')\nggtree::ggtree(tr, layout = 'circular', branch.length = 'none')\nggtree::ggtree(tr, layout = \"dendrogram\", branch.length = 'none')\nそれぞれの形状は次ページへ"
  },
  {
    "objectID": "slides/lt/ggtree.html#系統樹の形状も様々に変えることができる-1",
    "href": "slides/lt/ggtree.html#系統樹の形状も様々に変えることができる-1",
    "title": "Rで系統樹を扱う",
    "section": "系統樹の形状も様々に変えることができる",
    "text": "系統樹の形状も様々に変えることができる"
  },
  {
    "objectID": "slides/lt/ggtree.html#系統樹のあしらい",
    "href": "slides/lt/ggtree.html#系統樹のあしらい",
    "title": "Rで系統樹を扱う",
    "section": "系統樹のあしらい",
    "text": "系統樹のあしらい\n線のデザインを変えたり、nodeやtipにしるしを付けたりすることができる。\nset.seed(1)                    # シードを設定\ntr = ape::rtree(n = 7)         # 系統樹を生成\n\n## 線の色、太さ、種類を変える\nggtree::ggtree(tr, color = \"darkorange\", size = 2, linetype = \"dotted\")\n\n## nodeにしるしをつける\nggtree::ggtree(tr) + geom_nodepoint(color = \"#009E73\", alpha = 0.5, size = 5)\n\n## tipに印をつける\nggtree::ggtree(tr) + geom_tippoint(color = \"#0072B2\", shape = 16, size = 5)"
  },
  {
    "objectID": "slides/lt/ggtree.html#系統樹のあしらい特定のtipやnodeを目立たせる",
    "href": "slides/lt/ggtree.html#系統樹のあしらい特定のtipやnodeを目立たせる",
    "title": "Rで系統樹を扱う",
    "section": "系統樹のあしらい｜特定のtipやnodeを目立たせる",
    "text": "系統樹のあしらい｜特定のtipやnodeを目立たせる\nset.seed(1)                    # シードを設定\ntr = ape::rtree(n = 10)        # 系統樹を生成\n\n## node18を目立たせる\nggtree::ggtree(tr) +\n  geom_point2(aes(subset=(node==18)), color = \"#009E73\", alpha = 0.5, size = 5)\n\n## node4とnode5を目立たせる\nggtree::ggtree(tr) +\n  geom_point2(aes(subset=(node %in% c(4, 5))), color = \"#0072B2\", shape = 17, size = 5)"
  },
  {
    "objectID": "slides/lt/ggtree.html#系統樹のあしらい特定のクレードを目立たせる",
    "href": "slides/lt/ggtree.html#系統樹のあしらい特定のクレードを目立たせる",
    "title": "Rで系統樹を扱う",
    "section": "系統樹のあしらい｜特定のクレードを目立たせる",
    "text": "系統樹のあしらい｜特定のクレードを目立たせる\ngroupOTU や groupClade を使ってクレードをグルーピングする。\nset.seed(1)                    # シードを設定\ntr = ape::rtree(n = 10)        # 系統樹を生成\n\n## tipで指定\ntr2 = ggtree::groupOTU(tr, .node = c(\"t6\",\"t9\",\"t10\"))\n\n## nodeで指定\ntr3 = ggtree::groupClade(tr, .node = 13)"
  },
  {
    "objectID": "slides/lt/ggtree.html#系統樹のあしらい特定のクレードを目立たせる-1",
    "href": "slides/lt/ggtree.html#系統樹のあしらい特定のクレードを目立たせる-1",
    "title": "Rで系統樹を扱う",
    "section": "系統樹のあしらい｜特定のクレードを目立たせる",
    "text": "系統樹のあしらい｜特定のクレードを目立たせる\n複数のグルーピングも可能。\nset.seed(1)\ntr = ape::rtree(n = 10) |&gt;\n  ggtree::groupClade(c(17, 18))\nggtree::ggtree(tr, aes(color = group)) +\n  geom_tiplab() +\n  geom_nodelab(aes(label = node), hjust = -0.2, node = \"internal\") +\n  scale_color_manual(values=c(\"#444444\", \"#009E73\", \"#0072B2\", ))"
  },
  {
    "objectID": "slides/lt/ggtree.html#系統樹のあしらい特定のクレードを目立たせる-2",
    "href": "slides/lt/ggtree.html#系統樹のあしらい特定のクレードを目立たせる-2",
    "title": "Rで系統樹を扱う",
    "section": "系統樹のあしらい｜特定のクレードを目立たせる",
    "text": "系統樹のあしらい｜特定のクレードを目立たせる\n他にもいくつか方法がある。\n\n\nラベルをつける方法:\nggtree::ggtree(tr) +\n  geom_tiplab() +\n  geom_nodelab(aes(label = node), hjust = -0.2, node = \"internal\") +\n  geom_cladelabel(node=17, label=\"Clade A\", color=\"#009E73\", offset=-0.5, align=TRUE) +\n  geom_cladelabel(node=18, label=\"Clade B\", color=\"#E69F00\", offset=-0.5, align=TRUE)\n\n\n\n\n\n\n\n\n\n\n塗りつぶす方法:\nggtree::ggtree(tr) +\n  geom_tiplab() +\n  geom_nodelab(aes(label = node), hjust = -0.2, node = \"internal\") +\n  geom_hilight(node=17, fill=\"#009E73\", alpha=.2, extend=.2) +\n  geom_hilight(node=18, fill=\"#E69F00\", alpha=.2, extend=.2)"
  },
  {
    "objectID": "slides/lt/ggtree.html#references",
    "href": "slides/lt/ggtree.html#references",
    "title": "Rで系統樹を扱う",
    "section": "References",
    "text": "References\n\nape マニュアル\nggtree マニュアル\nQiita: Rで系統樹を扱う(ape, ggtree)\nhttps://guangchuangyu.github.io/ggtree-book/chapter-ggtree.html#introduction-1\nVisualizing and Annotating Phylogenetic Trees with R+ggtree"
  },
  {
    "objectID": "slides/lt/html-css.html#お品書き",
    "href": "slides/lt/html-css.html#お品書き",
    "title": "WEBサイト作成のための基礎知識",
    "section": "お品書き",
    "text": "お品書き\n\n\nHTML\n\nWEBブラウザで「なにを」見せるか\n\n\n\nCSS\n\nWEBブラウザで「どう」見せるか\n\n\n\nJavaScript\n\n静的サイトにも動きをつける\n\n\n\n静的サイトジェネレータ\n\n牧野研の人たちがよく使うWEBサイト作成技術"
  },
  {
    "objectID": "slides/lt/html-css.html#htmlは文書の中身と構造を決める",
    "href": "slides/lt/html-css.html#htmlは文書の中身と構造を決める",
    "title": "WEBサイト作成のための基礎知識",
    "section": "HTMLは文書の中身と構造を決める",
    "text": "HTMLは文書の中身と構造を決める\n\nHTML(Hyper Text Markup Language)\n\nWEBサイトを記述するマークアップ言語\n\n\n文書の中身と構造(見出し、段落、列挙など)を規定する。\n\n\n&lt;タグ&gt;テキスト&lt;/タグ&gt; という形で記述する。\n\n\n\n\n\n&lt;html&gt;\n  &lt;body&gt;\n    &lt;h2&gt;コーヒーとは&lt;/h2&gt;\n    &lt;p&gt;世界一美味しい飲み物である。&lt;/p&gt;\n    &lt;h3&gt;世界三大コーヒー&lt;/h3&gt;\n    &lt;ul&gt;\n      &lt;li&gt;キリマンジャロ&lt;/li&gt;\n      &lt;li&gt;ブルーマウンテン&lt;/li&gt;\n      &lt;li&gt;コナ&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\n\n\nコーヒーとは\n\n\n世界一美味しい飲み物である。\n\n\n世界三大コーヒー\n\n\n\nキリマンジャロ\n\n\nブルーマウンテン\n\n\nコナ"
  },
  {
    "objectID": "slides/lt/html-css.html#cssは文書の見た目を決める",
    "href": "slides/lt/html-css.html#cssは文書の見た目を決める",
    "title": "WEBサイト作成のための基礎知識",
    "section": "CSSは文書の見た目を決める",
    "text": "CSSは文書の見た目を決める\n\nCSS(Cascading Style Sheets)\n\nフォント、サイズ、色、レイアウトなど、Webサイトの見た目を規定する。\n\n\nセレクタ { プロパティ: 値}という形で記述する。 例えばh2の色を赤くしたければ: h2 { color: #ff0000}\n\n\n外部ファイル(.css)を読み込んだり、HTMLに直接書いたり。\n\n\n\n\n\nh2 {\n  color: #ff0000  /*文字色を赤く*/\n}\n\nh3 {\n  font-size: 0.5em  /*文字サイズを半分に*/\n}\n\nul{\n  margin-left: 20px  /*左側に余白をとる*/\n}\n\n\n\n\nコーヒーとは\n\n\n世界一美味しい飲み物である。\n\n\n世界三大コーヒー\n\n\n\nキリマンジャロ\n\n\nブルーマウンテン\n\n\nコナ"
  },
  {
    "objectID": "slides/lt/html-css.html#javascriptはhtmlに動きをつける",
    "href": "slides/lt/html-css.html#javascriptはhtmlに動きをつける",
    "title": "WEBサイト作成のための基礎知識",
    "section": "JavaScriptはHTMLに動きをつける",
    "text": "JavaScriptはHTMLに動きをつける\n\nJavaScript\n\nプログラミング言語のひとつ\n\n\nWEBサイトをよりレスポンシブルにできる。\n\n\nゲームや シミュレータを作ったり、 スライドっぽく見せたり(reveal.js)。\n\n\nJavaはまったく別の言語\n\n\n\n\n\n// 文字色をランダムに変更\nfunction changeBackgroundColor() {\n  var colors = [\"#e69f00\", \"#56b4e9\", \"#009e73\",\n                \"#f0e442\", \"#0072b2\", \"#d55e00\"];\n  var randomColor = colors[\n    Math.floor(Math.random() * colors.length)\n  ];\n  var targetElement = document.querySelector(\"h3.sample\");\n  targetElement.style.backgroundColor = randomColor;\n}\n\n\n\n\nJavaScriptサンプル\n\n\n文字色を変更"
  },
  {
    "objectID": "slides/lt/html-css.html#html-css-javascript-でウェブサイトが作られる",
    "href": "slides/lt/html-css.html#html-css-javascript-でウェブサイトが作られる",
    "title": "WEBサイト作成のための基礎知識",
    "section": "HTML + CSS (+ JavaScript) でウェブサイトが作られる",
    "text": "HTML + CSS (+ JavaScript) でウェブサイトが作られる\n🔰 適当なウェブサイトを開いて、「右クリック → “検証”」や「余白で右クリック → “ページのソースを表示”」から そのページのHTMLやCSSを見てみる。\n🔰 生のHTMLを書いてブラウザで見てみる。\n\n骨格↓をindex.html というファイルにコピペして編集する。\n&lt;html&gt;\n  &lt;body&gt;\n    &lt;h1&gt;ここにタイトル&lt;/h1&gt;\n    &lt;h2&gt;以下のタグを使ってみる&lt;/h2&gt;\n    &lt;p&gt;段落&lt;/p&gt;\n    &lt;p&gt;強調もできる。たとえば&lt;em&gt;斜体&lt;/em&gt;や&lt;strong&gt;太字&lt;/strong&gt;。&lt;/p&gt;\n    &lt;ul&gt;\n      &lt;li&gt;これはリスト&lt;/li&gt;\n      &lt;li&gt;これもリスト&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\nダブルクリックや open コマンドで開いて閲覧する。"
  },
  {
    "objectID": "slides/lt/html-css.html#でもhtmlを直接書くことは少ない",
    "href": "slides/lt/html-css.html#でもhtmlを直接書くことは少ない",
    "title": "WEBサイト作成のための基礎知識",
    "section": "でもHTMLを直接書くことは少ない",
    "text": "でもHTMLを直接書くことは少ない\n軽量マークアップ言語であるMarkdown(.md, .Rmd, .qmd)を書いて、 それをHTMLに変換する。\n\n\n\n## コーヒーとは\n\n世界一美味しい飲み物である。\n\n### 世界三大コーヒー\n\n- キリマンジャロ\n- ブルーマウンテン\n- コナ\n\n\n\n\nコーヒーとは\n\n\n世界一美味しい飲み物である。\n\n\n世界三大コーヒー\n\n\n\nキリマンジャロ\n\n\nブルーマウンテン\n\n\nコナ"
  },
  {
    "objectID": "slides/lt/html-css.html#md-.html-を便利にする静的サイトジェネレータ",
    "href": "slides/lt/html-css.html#md-.html-を便利にする静的サイトジェネレータ",
    "title": "WEBサイト作成のための基礎知識",
    "section": ".md → .html を便利にする静的サイトジェネレータ",
    "text": ".md → .html を便利にする静的サイトジェネレータ\n\nHUGO\n\n高速な静的サイト生成フレームワーク\n\n\nいい感じの見た目にするテーマが豊富\n\n\n\n\nquarto\n\n文書作成・公開のためのフレームワーク\n\n\nコマンドライン以外にも、Jupyter notebooks、Rstudio、VScodeで使える。\n\n\nWEBサイト以外にも、スライド作りにも便利"
  },
  {
    "objectID": "slides/minicong/minicong.html#生物多様性の源は",
    "href": "slides/minicong/minicong.html#生物多様性の源は",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "生物多様性の源は?",
    "text": "生物多様性の源は?\n現在の生物の多様性・複雑性は、単一の共通祖先に端を発する進化の歴史の中で形成されてきた。\n  https://en.wikipedia.org/wiki/"
  },
  {
    "objectID": "slides/minicong/minicong.html#生物の進化とはなにか",
    "href": "slides/minicong/minicong.html#生物の進化とはなにか",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "生物の「進化」とはなにか",
    "text": "生物の「進化」とはなにか\n生物の性質が、世代を経るにつれて変化すること。\n↓ ちょっとアバウトすぎる\n親から子へと受け継がれる情報が変化し、その変化がやがて集団中に広まっていくこと。\n↓ もう少し学術的にいうと\n親から子へ遺伝する情報に変異が生じ、集団中における頻度が変化すること。\n\nキリンの例: (こんなに単純ではないだろうけど)\n\nとある遺伝子に変異が生じた結果、首の長い個体が現れた。\n首の長い個体は高いところの葉っぱも食べることができて生存に有利。\n首の長い個体ばっか生き残った結果、キリンの首が長くなった。\n\n\n決して高いところの葉を食べようとして首を長くしたわけではない。"
  },
  {
    "objectID": "slides/minicong/minicong.html#遺伝情報-遺伝子",
    "href": "slides/minicong/minicong.html#遺伝情報-遺伝子",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "遺伝情報？ 遺伝子？",
    "text": "遺伝情報？ 遺伝子？\n\n遺伝情報(親から子へ伝わる情報)の実体\n\nDNAの配列 = DNAを構成する4種類の塩基(A, T, G, C)の並び\n\n遺伝子\n\nDNAのうち、タンパク質(体を形作る素材)をつくる領域\n\n\n https://theory.labster.com/"
  },
  {
    "objectID": "slides/minicong/minicong.html#バイオインフォマティクスとは",
    "href": "slides/minicong/minicong.html#バイオインフォマティクスとは",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "バイオインフォマティクスとは",
    "text": "バイオインフォマティクスとは\n生物の持つ膨大な情報(主に遺伝情報)を、コンピュータの力を借りて扱う学問。\n\nある生物の遺伝情報(A, T, G, Cの並び)はどうなっているのか\nある種と別の種の遺伝情報はどこが同じで、どこが違うのか\n遺伝情報はどう変わってきたのか、どう変わりつつあるのか\n\n\n\n\n本日は野良データ + Python + Linuxで、バイオインフォマティクスの一部を体感。"
  },
  {
    "objectID": "slides/minicong/minicong.html#本日のお品書き",
    "href": "slides/minicong/minicong.html#本日のお品書き",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "本日のお品書き",
    "text": "本日のお品書き\n野良データを使って、バイオインフォマティクスの解析の一部を体験してもらう。\nペットとしてお馴染みのイヌ( Canis lupus familiaris )と、オーストラリアに生息するイヌの近縁種であるディンゴ( Canis lupus dingo )のゲノムを、重複遺伝子の観点から比較する。\n \n\n- CONTENTS -\n\n重複遺伝子とは?\n種の環境適応と重複遺伝子\n重複遺伝子を調べるゲノミクス手法\nLet’s try on your computer!\n\n\nGithub: https://github.com/ymat2/minicong"
  },
  {
    "objectID": "slides/minicong/minicong.html#重複遺伝子とは",
    "href": "slides/minicong/minicong.html#重複遺伝子とは",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "重複遺伝子とは",
    "text": "重複遺伝子とは\nもともと1つだった遺伝子が、さまざまな要因（組換えのミス、トランスポゾンの転移、etc.）で2つ以上になること。"
  },
  {
    "objectID": "slides/minicong/minicong.html#重複遺伝子は環境への適応に関与する",
    "href": "slides/minicong/minicong.html#重複遺伝子は環境への適応に関与する",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "重複遺伝子は環境への適応に関与する",
    "text": "重複遺伝子は環境への適応に関与する"
  },
  {
    "objectID": "slides/minicong/minicong.html#アミラーゼ遺伝子の数",
    "href": "slides/minicong/minicong.html#アミラーゼ遺伝子の数",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "アミラーゼ遺伝子の数",
    "text": "アミラーゼ遺伝子の数\n\nアミラーゼはでんぷんを分解する消化酵素。いろんなものを食べるヒトは5つのアミラーゼ遺伝子をもつ。: AMY1A, AMY1B, AMY1C, AMY2A, AMY2B\n\n  左: αアミラーゼ　右: βアミラーゼ\n\n\nこれまでの話と絡めると、多様な食事を摂る環境ではアミラーゼ遺伝子の重複が有利に働いたと言える。\nでは、長く人間のペットとして生きてきたイヌと、野生に暮らすディンゴでは、どちらの方がアミラーゼ遺伝子を多く持つだろう？"
  },
  {
    "objectID": "slides/minicong/minicong.html#重複遺伝子を調べるためのゲノミクス手法",
    "href": "slides/minicong/minicong.html#重複遺伝子を調べるためのゲノミクス手法",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "重複遺伝子を調べるためのゲノミクス手法",
    "text": "重複遺伝子を調べるためのゲノミクス手法\n重複遺伝子どうしはもともとは1つの遺伝子（=同じ配列）なので、互いに似た配列を持つ。そこで、\n\nBLAST (Basic Local Alignment Search Tool)\n\nDNAの塩基配列あるいはタンパク質のアミノ酸配列のアライメントを行うためのアルゴリズム\n\n\nある閾値以上のスコアで類似する配列を発見することができる。"
  },
  {
    "objectID": "slides/minicong/minicong.html#実際にやってみよう-前準備",
    "href": "slides/minicong/minicong.html#実際にやってみよう-前準備",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "実際にやってみよう: 前準備",
    "text": "実際にやってみよう: 前準備\n\nhomebrewのインストール:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n\nsudo apt update\nsudo apt install install build-essential curl file git\n\necho 'export PATH=\"/home/linuxbrew/.linuxbrew/bin:$PATH\"' &gt;&gt; ~/.bash_profile\nsource ~/.bash_profile\nblastのインストール:\nbrew update\nbrew install blast\n今回使うリポジトリを取ってくる:\ngit clone https://github.com/ymat2/minicong.git"
  },
  {
    "objectID": "slides/minicong/minicong.html#実際にやってみよう",
    "href": "slides/minicong/minicong.html#実際にやってみよう",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "実際にやってみよう:",
    "text": "実際にやってみよう:\n\nminicongに移動\ncd minicong\nイヌとディンゴの配列を取得\nsh src/get_sequence.sh\nblastpを実行 (1行ずつやってみてもいいよ)\nsh src/run_blastp.sh\n結果を確認してみる。\nls result\nless result/Canis_lupus_dingo.ASM325472v1.blastp"
  },
  {
    "objectID": "slides/minicong/minicong.html#アミラーゼ遺伝子の数は-イヌ-ディンゴ",
    "href": "slides/minicong/minicong.html#アミラーゼ遺伝子の数は-イヌ-ディンゴ",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "アミラーゼ遺伝子の数は イヌ > ディンゴ",
    "text": "アミラーゼ遺伝子の数は イヌ &gt; ディンゴ\nヒトと共に生活し始めたことで雑食性に変化したこととの関与が示唆されている。\n\nSee also &gt; イヌの多様化における遺伝的背景（かずさDNA研究所）"
  },
  {
    "objectID": "slides/minicong/minicong.html#バイオインフォマティクスは生物学における強力な研究手法",
    "href": "slides/minicong/minicong.html#バイオインフォマティクスは生物学における強力な研究手法",
    "title": "Minimal hands-on for Comparative Genomics",
    "section": "バイオインフォマティクスは生物学における強力な研究手法",
    "text": "バイオインフォマティクスは生物学における強力な研究手法\nゲノムを読む技術の発達に伴い、日々多くの種のゲノムが解読されている。バイオインフォマティクスは、蓄積されつつある大規模な情報を扱い多様な生命現象を解き明かす強力なツールである。\n\n\n\n\n\n\nSEE MORE &gt;\n\n東北大学 生命科学研究科 進化ゲノミクス分野"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#part.-2-リードマッピングバリアントコール",
    "href": "slides/snp24/02_mapping-call.html#part.-2-リードマッピングバリアントコール",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "Part. 2 リードマッピング、バリアントコール",
    "text": "Part. 2 リードマッピング、バリアントコール\n目標\n\n公開データを用いた SNP 解析ができるようになる。\nデータの中身と解析の流れについて理解を深める。\n\n\nコンテンツ\n\n基本的なコマンドライン操作\nNGS 公開データの取得\nクオリティコントロール\nリードマッピング\nバリアントコール\nSNP アノテーション"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#参照配列にリードをマッピング-前準備",
    "href": "slides/snp24/02_mapping-call.html#参照配列にリードをマッピング-前準備",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "参照配列にリードをマッピング (前準備)",
    "text": "参照配列にリードをマッピング (前準備)\n\nリードマッピング\n\nリードを参照配列の相同な位置に貼り付ける\n\n\n\n\n\n前準備\n大腸菌の参照配列をダウンロード\nwget https://ftp.ensemblgenomes.ebi.ac.uk/pub/bacteria/release-47/fasta/bacteria_5_collection/escherichia_coli_b_str_rel606/dna/Escherichia_coli_b_str_rel606.ASM1798v1.dna.toplevel.fa.gz\n\n\n\nダウンロードしたファイルは圧縮されている (.gz) ので解凍する:\ngunzip Escherichia_coli_b_str_rel606.ASM1798v1.dna.toplevel.fa.gz"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#参照配列にリードをマッピング-前準備-1",
    "href": "slides/snp24/02_mapping-call.html#参照配列にリードをマッピング-前準備-1",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "参照配列にリードをマッピング (前準備)",
    "text": "参照配列にリードをマッピング (前準備)\nファイル名が長いので Ecoli.fa に変えておく (任意):\nmv Escherichia_coli_b_str_rel606.ASM1798v1.dna.toplevel.fa Ecoli.fa\n\n\n\n参照配列の中身を見てみる:\nless Ecoli.fa\n\n\n\n&gt;Chromosome dna:chromosome chromosome:ASM1798v1:Chromosome:1:4629812:1 REF\nAGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAGAGTGTC\nTGATAGCAGCTTCTGAACTGGTTACCTGCCGTGAGTAAATTAAAATTTTATTGACTTAGG\nTCACTAAATACTTTAACCAATATAGGCATAGCGCACAGACAGATAAAAATTACAGAGTAC\n︙\n&gt; で始まるヘッダー行と配列からなる FASTA というファイル形式。 Fastq と似ているけど別フォーマット。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#より小さいデータを使ってリードマッピングを理解する",
    "href": "slides/snp24/02_mapping-call.html#より小さいデータを使ってリードマッピングを理解する",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "より小さいデータを使ってリードマッピングを理解する",
    "text": "より小さいデータを使ってリードマッピングを理解する\n使うデータ (fastq と参照配列) が用意できたところで、 より小さなデータを使ってこれから扱うファイルの形式を先に理解しよう。\nデータ置き場: https://github.com/ymat2/md4rm\n\nデータをダウンロードする:\ngit clone https://github.com/ymat2/md4rm.git\n\n\n\nディレクトリを移動して ls で中身を確認:\ncd md4rm\nls\n\nref.fa: 参照配列。100bp。\nsra_1.fq, sra_2.fq: Paired-end のショートリード (もどき)。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#ショートリードの詳細",
    "href": "slides/snp24/02_mapping-call.html#ショートリードの詳細",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "ショートリードの詳細",
    "text": "ショートリードの詳細\nsra_1.fq, sra_2.fq には以下の5本のリードがある。\n\nless などで中身を見てみる:\nless sra_1.fq\nless sra_2.fq"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#リードマッピングの全体をまず眺める",
    "href": "slides/snp24/02_mapping-call.html#リードマッピングの全体をまず眺める",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "リードマッピングの全体をまず眺める",
    "text": "リードマッピングの全体をまず眺める\n## 参照配列のインデックスを作る\nbwa index ref.fa\n\n## ショートリードを参照配列へマッピングする\nbwa mem ref.fa sra_1.fq sra_2.fq &gt; small.sam\n\n## SAM ファイルを処理する\nsamtools collate small.sam -o small.c.sam      # リード名ソート\nsamtools fixmate -m small.c.sam small.cf.sam   # MC, ms タグを付加\nsamtools sort small.cf.sam -o small.cfs.sam    # 位置順ソート\nsamtools markdup small.cfs.sam small.cfsm.sam  # PCR duplicates をマーク\n\n## BAM ファイルへ圧縮する\nsamtools view -b small.cfsm.sam &gt; small.bam\n\n# 一般的には BAM への圧縮を最初にやる。(SAM のサイズが大きいので。)\n# 今回はファイルの中身を見ながら進めるので最後に。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#参照配列のインデックス作成とリードマッピング",
    "href": "slides/snp24/02_mapping-call.html#参照配列のインデックス作成とリードマッピング",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "参照配列のインデックス作成とリードマッピング",
    "text": "参照配列のインデックス作成とリードマッピング\nbwa index ref.fa\nbwa mem ref.fa sra_1.fq sra_2.fq &gt; small.sam\nマッピングの結果はターミナルに出力されるので、 リダイレクト &gt; して small.sam に書き込む。\n\n\n\n\n「インデックスを作る📑」とは？\n\n文字列検索を高速化するために参照配列を変換したファイルを生成する。 BWA では Burrows-Wheeler 変換というのを使うらしい。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#sequence-alignment-map-sam-フォーマット",
    "href": "slides/snp24/02_mapping-call.html#sequence-alignment-map-sam-フォーマット",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "Sequence Alignment Map (SAM) フォーマット",
    "text": "Sequence Alignment Map (SAM) フォーマット\n https://samtools.github.io/hts-specs/SAMv1.pdf \n参照配列にマッピングされたリードの情報を記載するためのフォーマット\n@SQ SN:NC_052532.1  LN:100\n@PG ID:bwa  PN:bwa  VN:0.7.17-r1188 CL:bwa mem -I 90 ref.fa sra_1.fq sra_2.fq\nread1   99  NC_052532.1 3   60  40M =   53  90  TCACCCATCTCGGAGTGCTCACACCATCCCCATGATCTTG    AAAAAAAAA6AAA7AAAAABBAAA?A7&lt;?AAA:&gt;6::662    NM:i:1  MD:Z:13G26  MC:Z:40M    AS:i:35 XS:i:0\nread1   147 NC_052532.1 53  60  40M =   3   -90 ATCACCCCCATGTCCCCCGGATGCTCACAGCATCACCCAT    266::6&gt;:AAA?&lt;7A?AAABBAAAAA7AAA6AAAAAAAAA    NM:i:0  MD:Z:40 MC:Z:40M    AS:i:40 XS:i:0\nread2   83  NC_052532.1 55  60  40M =   5   -90 CACCCCCATGTCCCCCGGATGCTCACAGCATCACCCATCT    266::6&gt;:AAA?&lt;7A?AAABBAAAAA7AAA6AAAAAAAAA    NM:i:0  MD:Z:40 MC:Z:40M    AS:i:40 XS:i:0\nread2   163 NC_052532.1 5   60  40M =   55  90  ACCCATCTCGGAGTGCTCACACCATCCCCATGATCTTGGG    AAAAAAAAA6AAA7AAAAABBAAA?A7&lt;?AAA:&gt;6::662    NM:i:1  MD:Z:11G28  MC:Z:40M    AS:i:35 XS:i:0\n︙\n@ で始まるヘッダー行と、1リード1行のデータからなる。\n11 列以上で構成され、11列目まではツール共通、それ以降はマッピングツールによって異なる。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#sequence-alignment-map-sam-フォーマット-1",
    "href": "slides/snp24/02_mapping-call.html#sequence-alignment-map-sam-フォーマット-1",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "Sequence Alignment Map (SAM) フォーマット",
    "text": "Sequence Alignment Map (SAM) フォーマット\n\nQNAME: リード名\nFLAG: マッピング状況を表す数字\nRNAME: 参照配列の名前 (染色体、コンティグ等)\nPOS: 位置\nMAPQ: マッピングクオリティ。\\(-10 \\times \\log_{10}{\\text{(誤マッピングの確率)}}\\)。\nCIGAR: いくつの塩基がどう張り付いたかを示す文字列\nMRNM: Paired-end のもう片方が張り付いた染色体。一緒なら =。\nMPOS: Paired-end のもう片方の位置\nTLEN: Insert size (Paired-end の端から端までの長さ)\nSEQ: 配列\nQUAL: 配列のクオリティ"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#flag-について-このあと出てくるので説明",
    "href": "slides/snp24/02_mapping-call.html#flag-について-このあと出てくるので説明",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "FLAG について (このあと出てくるので説明)",
    "text": "FLAG について (このあと出てくるので説明)\nリードのマッピング状況を表す数字。Bit 表現の足し算。\n    1  0x001  Paired-end である\n    2  0x002  正しくマッピングされている\n    4  0x004  マッピングされていない\n    8  0x008  Pair の相方がマッピングされていない\n   16  0x010  逆鎖\n   32  0x020  Pair の相方が逆鎖\n   64  0x040  read1 である\n  128  0x080  read2 である\n  256  0x100  ゲノム上の複数個所にマッピングされている\n  512  0x200  クオリティが低い\n 1024  0x400  Duplicate である\n 2048  0x800  supplementary alignment\n例えば FLAG が 99 なら 64+32+2+1 で「正しくマッピングされた、ペアが逆鎖のread1」、 133 なら 128+4+1 で「マッピングされていないペアのread2」となる。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#samtools-を用いたファイル処理-collate-fixmate",
    "href": "slides/snp24/02_mapping-call.html#samtools-を用いたファイル処理-collate-fixmate",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "SAMtools を用いたファイル処理: collate, fixmate",
    "text": "SAMtools を用いたファイル処理: collate, fixmate\nsamtools collate small.sam -o small.c.sam\nsamtools fixmate -m small.c.sam small.cf.sam\n\nsamtools collate\n\nリードの名前をシャッフルして同じリード名でグループ化する。\n\n\nBWA の出力がすでにこうなっているのでやらなくても OK。\n\nsamtools fixmate -m\n\nmate タグ (MC, ms) というタグを付加する。\n\n\n下流の markdup の際にどのリードを残すかの基準となる。\n\n\n\n\n\n🔰 small.sam と small.cf.sam を見比べて、 リードの順番の違いと、行の右端に MC/ms タグがあることを確認しよう。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#samtools-を用いたファイル処理-sort",
    "href": "slides/snp24/02_mapping-call.html#samtools-を用いたファイル処理-sort",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "SAMtools を用いたファイル処理: sort",
    "text": "SAMtools を用いたファイル処理: sort\nsamtools sort small.cf.sam -o small.cfs.sam\n\nsamtools sort\n\nリードを位置順に (4列目の POS に基づいて) 並び替える。\n\n\n\n\n\n🔰 small.cf.sam と small.cfs.sam を見比べて、 リードの順番が4列目 POS の昇順になっていることを確認しよう。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#samtools-を用いたファイル処理-markdup",
    "href": "slides/snp24/02_mapping-call.html#samtools-を用いたファイル処理-markdup",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "SAMtools を用いたファイル処理: markdup",
    "text": "SAMtools を用いたファイル処理: markdup\nsamtools markdup small.cfs.sam small.cfsm.sam\n\nsamtools markdup\n\nDuplicates (同じ領域のリード) を重複リードとしてマークする。\n\n\n\n\n\n🔰 small.cfs.sam と small.cfsm.sam とで read3 の2列目 FLAG の変化を比べよう。\nread3   163 NC_052532.1 5   60  40M =   55  90  ACCCATCTCGGAGTGCTCACACCATCCCCATGATCTTGGG    AAAAAAAAA6AAA7AAAAABBAAA?A7&lt;?AAA:&gt;6::662    NM:i:1  MD:Z:11G28  AS:i:35 XS:i:0  MQ:i:60 MC:Z:40M    ms:i:1170\n↓\nread3   1187    NC_052532.1 5   60  40M =   55  90  ACCCATCTCGGAGTGCTCACACCATCCCCATGATCTTGGG    AAAAAAAAA6AAA7AAAAABBAAA?A7&lt;?AAA:&gt;6::662    NM:i:1  MD:Z:11G28  AS:i:35 XS:i:0  MQ:i:60 MC:Z:40M    ms:i:1170\n\n163 = 128 + 32 + 2 + 1\n1187 = 1024 + 128 + 32 + 2 + 1"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#samtools-を用いたファイル処理-markdup--r",
    "href": "slides/snp24/02_mapping-call.html#samtools-を用いたファイル処理-markdup--r",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "SAMtools を用いたファイル処理: markdup -r",
    "text": "SAMtools を用いたファイル処理: markdup -r\nsamtools markdup -r small.cfs.sam small.cfsm.sam\n\nsamtools markdup -r\n\nDuplicates (同じ領域のリード) を重複リードとしてマークして除く。\n\n\nなお、リードを除かなくてもマークさえしておけば、 この後のバリアントコールの時には使われないっぽい。\n\n\n\n\n\n🔰 small.cfsm.sam から read3 が除かれたことを確認しよう。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#bam-ファイルへの圧縮と閲覧",
    "href": "slides/snp24/02_mapping-call.html#bam-ファイルへの圧縮と閲覧",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "BAM ファイルへの圧縮と閲覧",
    "text": "BAM ファイルへの圧縮と閲覧\nBAM は SAM をバイナリに圧縮したファイル形式。 バイナリファイルなのでそのままでは読めず、インデックスを作って閲覧する。\nsamtools view -b small.cfsm.sam &gt; small.bam\nsamtools index small.bam\n\n閲覧方法\n\nSAM として閲覧\n\nsamtools view -h --no-PG small.bam | less\n\nリードの貼りつき状況を視覚的に表示 (Q で閲覧画面を閉じる)\n\nsamtools tview small.bam ref.fa"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#公開データを使ってリードマッピング",
    "href": "slides/snp24/02_mapping-call.html#公開データを使ってリードマッピング",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "公開データを使ってリードマッピング",
    "text": "公開データを使ってリードマッピング\n改めて先ほど取得した大腸菌のデータを使って、リードマッピングを行う。\ncd ..  # 元の snp24 ディレクトリへ移動\n\n## インデックス作成とマッピング\nbwa index Ecoli.fa\nbwa mem Ecoli.fa qc_SRR030257_1.fq.gz qc_SRR030257_2.fq.gz &gt; SRR030257.sam\n\n## SAMtools による処理\nsamtools view -b SRR030257.sam &gt; SRR030257.bam         # 最初に BAM へ圧縮\nsamtools collate SRR030257.bam -o SRR030257.c.bam      # リード名ソート\nsamtools fixmate -m SRR030257.c.bam SRR030257.cf.bam   # MC, ms タグを付加\nsamtools sort SRR030257.cf.bam -o SRR030257.cfs.bam    # 位置順ソート\nsamtools markdup SRR030257.cfs.bam SRR030257.cfsm.bam  # PCR duplicates をマーク\nsamtools index SRR030257.cfsm.bam                      # インデックス作成\n\n\n\n🔰 samtools tview でリードのマッピング状況を可視化してみよう。 (矢印キー ←/→ で移動できる。)"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#samtools-tview-で眺めると変異らしき座位が見つかる",
    "href": "slides/snp24/02_mapping-call.html#samtools-tview-で眺めると変異らしき座位が見つかる",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "samtools tview で眺めると変異らしき座位が見つかる",
    "text": "samtools tview で眺めると変異らしき座位が見つかる\n\n\n 閲覧画面で / を押して Chromosome:161041 と打つとこの位置へジャンプ \n\nSNP (T から G) ↑"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#アライメントから変異を特定する-バリアントコール",
    "href": "slides/snp24/02_mapping-call.html#アライメントから変異を特定する-バリアントコール",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "アライメントから変異を特定する (=バリアントコール)",
    "text": "アライメントから変異を特定する (=バリアントコール)\nバリアントコールのお気持ち。例えば参照配列が A のある座位に対して、\n\n100本のリードがマッピングされ、100本が G\n\nこの座位は G だろう。\n\n100本のリードがマッピングされ、49本が A、51本が G\n\nこの座位は A/G のヘテロだろう。\n\n100本のリードがマッピングされ、98本が A、2本が G\n\nA/G のヘテロである確率よりは、2本が誤っている確率が高そう。 シーケンスのエラー、誤った場所へのマッピングなど。\n\n2本のリードがマッピングされ、1本が A、1本が G\n\n割合的には A/G のヘテロだけど、本数が少ないので確実な変異とは言えない。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#bcftools-によるバリアントコール",
    "href": "slides/snp24/02_mapping-call.html#bcftools-によるバリアントコール",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "BCFtools によるバリアントコール",
    "text": "BCFtools によるバリアントコール\nbcftools mpileup -f Ecoli.fa SRR030257.cfsm.bam &gt; SRR030257.mpileup\nbcftools call -c -v --ploidy 1 SRR030257.mpileup -o SRR030257.vcf\n\nbcftools mpileup\n\n1座位ごとに遺伝子型尤ゆう度を計算して VCF/BCF を生成する。\n\nbcftools call\n\nmpileup で出力した遺伝子型尤度に基づいて遺伝子型を決定する。\n\n\n-c: biallelic コール (REF/ALT)。-m にすると multi-allelic コール (REF/ALT1/ALT2…)。\n\n\n-v: 変異がある座位のみを出力する。\n\n\n--ploidy N: 一倍体か二倍体か。デフォルトは二倍体。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#vcf-variant-call-format",
    "href": "slides/snp24/02_mapping-call.html#vcf-variant-call-format",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "VCF (Variant Call Format)",
    "text": "VCF (Variant Call Format)\n https://samtools.github.io/hts-specs/VCFv4.2.pdf \nバリアントコールした変異の情報を記述するフォーマット。 BCF は VCF をバイナリ化したもの。\n##fileformat=VCFv4.2\n##FILTER=&lt;ID=PASS,Description=\"All filters passed\"&gt;\n##bcftoolsVersion=1.13+htslib-1.13+ds\n︙\n#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  SRR030257.cfsm.bam\nChromosome      161041  .       T       G       225.007 .       DP=55;VDB=0.000910305;SGB=-0.693147;MQSBZ=1.32288;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,20,35;MQ=60;FQ=-999   GT:PL   1:255,0\nChromosome      380188  .       A       C       225.007 .       DP=42;VDB=0.701392;SGB=-0.693146;MQSBZ=-0.595683;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,11,31;MQ=60;FQ=-999    GT:PL   1:255,0\n︙\n## で始まるヘッダー行と、1座位1行のデータ行からなる。\n8列目までは共通、10列目以降は各サンプルの列。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#vcf-variant-call-format-1",
    "href": "slides/snp24/02_mapping-call.html#vcf-variant-call-format-1",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "VCF (Variant Call Format)",
    "text": "VCF (Variant Call Format)\n\n#CHROM: 染色体やコンティグの名前\nPOS: 染色体上の位置\nID: SNP に名前がついている場合がある。(例: rs247)\nREF: 参照配列の塩基 (配列)\nALT: 変異の塩基 (配列)\nQUAL: クオリティ。\\(-10 \\times \\log_{10}{\\text{(変異が間違いである確率)}}\\)\nFILTER: フィルターを通過したかどうか (PASS)\nINFO: ; 区切りの追加情報。たいていヘッダー行に説明が書いてある。\n##INFO=&lt;ID=DP,Number=1,Type=Integer,Description=\"Raw read depth\"&gt;\nFORMAT: 10列目以降の各サンプル列に何が書いてあるか。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#format-フィールドの読み方",
    "href": "slides/snp24/02_mapping-call.html#format-フィールドの読み方",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "FORMAT フィールドの読み方",
    "text": "FORMAT フィールドの読み方\n... FORMAT  sampleA         sampleB\n... GT:PL   0/1:139,0,112   1/1:245,27,0\n\nsampleA 以降の列には GT と PL の情報が : 区切りで書いてある。\nsampleA の GT は 0/1、PL は 139,0,112。\nsampleB の GT は 1/1、PL は 245,27,0。\n\n\nGT (genotype)\n\n遺伝子型。/ もしくは | 区切りで、0/0 なら REF/REF (参照配列のホモ)、 0/1 なら REF/ALT (ヘテロ)、1/1 なら ALT/ALT (変異のホモ) のように読む。\n\nPL (phred-scaled genotype likelihood)\n\n遺伝子型ごとの尤度。, 区切りで REF/REF,REF/ALT,ALT/ALT の順にスコアリングされており、 数字が小さいほど尤もらしい。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#srr030257.vcf-を見てみる",
    "href": "slides/snp24/02_mapping-call.html#srr030257.vcf-を見てみる",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "SRR030257.vcf を見てみる",
    "text": "SRR030257.vcf を見てみる\n## ヘッダー省略\n#CHROM          POS     ID      REF     ALT     QUAL    FILTER  FORMAT  SRR030257.cfsm.bam\nChromosome      161041  .       T       G       225.007 .       DP=55;VDB=0.000910305;SGB=-0.693147;MQSBZ=1.32288;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,20,35;MQ=60;FQ=-999   GT:PL   1:255,0\nChromosome      380188  .       A       C       225.007 .       DP=42;VDB=0.701392;SGB=-0.693146;MQSBZ=-0.595683;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,11,31;MQ=60;FQ=-999    GT:PL   1:255,0\nChromosome      430835  .       C       T       225.007 .       DP=72;VDB=0.0514064;SGB=-0.693147;RPBZ=-4.55905;MQBZ=5.72838;MQSBZ=-2.34454;BQBZ=-1.62502;SCBZ=-1.61283;FS=0;MQ0F=0.208333;AF1=1;AC1=1;DP4=1,13,31,27;MQ=46;FQ=-999;PV4=0.0020037,0.174994,1,1    GT:PL   1:255,0\nChromosome      475288  .       CGGGG   CGGGGG  217.469 .       INDEL;IDV=34;IMF=0.772727;DP=44;VDB=0.0585699;SGB=-0.693132;RPBZ=-1.90593;MQBZ=-1.12363;MQSBZ=2.23545;SCBZ=-3.81819;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=3,1,14,20;MQ=60;FQ=-999;PV4=0.30678,1,0.282827,1  GT:PL   1:255,65,0\nChromosome      649391  .       T       A       225.007 .       DP=60;VDB=0.100294;SGB=-0.693147;MQSBZ=-0.0713471;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,31,29;MQ=60;FQ=-999   GT:PL   1:255,0\n︙\nChromosome      1286699 .       C       A       225.007 .       DP=53;VDB=0.327747;SGB=-0.693147;MQSBZ=2.54111;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,21,32;MQ=59;FQ=-999      GT:PL   1:255,0\nChromosome      1329516 .       C       T       225.007 .       DP=50;VDB=0.0979545;SGB=-0.693147;MQSBZ=2.05363;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,18,31;MQ=59;FQ=-999     GT:PL   1:255,0\nChromosome      1976879 .       T       G       225.007 .       DP=48;VDB=0.218639;SGB=-0.693147;MQSBZ=-1.29099;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,30,18;MQ=60;FQ=-999     GT:PL   1:255,0\nChromosome      2031736 .       A       G       18.0728 .       DP=5;VDB=0.0672958;SGB=-0.590765;FS=0;MQ0F=0.2;AF1=1;AC1=1;DP4=0,0,0,5;MQ=19;FQ=-999    GT:PL   1:48,0\nChromosome      2054876 .       A       G       119.006 .       DP=18;VDB=0.155125;SGB=-0.691153;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,18,0;MQ=31;FQ=-999     GT:PL   1:149,0"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#クオリティがよろしくない変異もある",
    "href": "slides/snp24/02_mapping-call.html#クオリティがよろしくない変異もある",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "クオリティがよろしくない変異もある",
    "text": "クオリティがよろしくない変異もある\n## ヘッダー省略\n#CHROM          POS     ID      REF     ALT     QUAL    FILTER  FORMAT  SRR030257.cfsm.bam\nChromosome      161041  .       T       G       225.007 .       DP=55;VDB=0.000910305;SGB=-0.693147;MQSBZ=1.32288;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,20,35;MQ=60;FQ=-999   GT:PL   1:255,0\nChromosome      380188  .       A       C       225.007 .       DP=42;VDB=0.701392;SGB=-0.693146;MQSBZ=-0.595683;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,11,31;MQ=60;FQ=-999    GT:PL   1:255,0\nChromosome      430835  .       C       T       225.007 .       DP=72;VDB=0.0514064;SGB=-0.693147;RPBZ=-4.55905;MQBZ=5.72838;MQSBZ=-2.34454;BQBZ=-1.62502;SCBZ=-1.61283;FS=0;MQ0F=0.208333;AF1=1;AC1=1;DP4=1,13,31,27;MQ=46;FQ=-999;PV4=0.0020037,0.174994,1,1    GT:PL   1:255,0\nChromosome      475288  .       CGGGG   CGGGGG  217.469 .       INDEL;IDV=34;IMF=0.772727;DP=44;VDB=0.0585699;SGB=-0.693132;RPBZ=-1.90593;MQBZ=-1.12363;MQSBZ=2.23545;SCBZ=-3.81819;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=3,1,14,20;MQ=60;FQ=-999;PV4=0.30678,1,0.282827,1  GT:PL   1:255,65,0\nChromosome      649391  .       T       A       225.007 .       DP=60;VDB=0.100294;SGB=-0.693147;MQSBZ=-0.0713471;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,31,29;MQ=60;FQ=-999   GT:PL   1:255,0\n︙\nChromosome      1286699 .       C       A       225.007 .       DP=53;VDB=0.327747;SGB=-0.693147;MQSBZ=2.54111;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,21,32;MQ=59;FQ=-999      GT:PL   1:255,0\nChromosome      1329516 .       C       T       225.007 .       DP=50;VDB=0.0979545;SGB=-0.693147;MQSBZ=2.05363;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,18,31;MQ=59;FQ=-999     GT:PL   1:255,0\nChromosome      1976879 .       T       G       225.007 .       DP=48;VDB=0.218639;SGB=-0.693147;MQSBZ=-1.29099;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,30,18;MQ=60;FQ=-999     GT:PL   1:255,0\nChromosome      2031736 .       A       G       18.0728 .       DP=5;VDB=0.0672958;SGB=-0.590765;FS=0;MQ0F=0.2;AF1=1;AC1=1;DP4=0,0,0,5;MQ=19;FQ=-999    GT:PL   1:48,0\nChromosome      2054876 .       A       G       119.006 .       DP=18;VDB=0.155125;SGB=-0.691153;FS=0;MQ0F=0;AF1=1;AC1=1;DP4=0,0,18,0;MQ=31;FQ=-999     GT:PL   1:149,0"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#高品質な変異をフィルタリングする",
    "href": "slides/snp24/02_mapping-call.html#高品質な変異をフィルタリングする",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "高品質な変異をフィルタリングする",
    "text": "高品質な変異をフィルタリングする\n https://samtools.github.io/bcftools/howtos/filtering.html \nbcftools filter -i \"QUAL&gt;20 && INFO/DP&gt;10\" SRR030257.vcf -o hq_SRR030257.vcf\n\n-i (or -e)\n\n条件を満たす変異を残す -i (or 除外する -e)\n\n\"QUAL&gt;20 && INFO/DP&gt;10\"\n\nQUAL フィールドの値が20より大きい、かつ (&&) INFO フィールドの DP が10より大きい。\n\n\nほかにもいろいろ指定可能\n\n\n🔰 条件を変えて bcftools filter してみよう。\n🔰 SRR030257.vcf と hq_SRR030257.vcf を比べて意図した通りできているか確認しよう。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#part.-2-まとめ",
    "href": "slides/snp24/02_mapping-call.html#part.-2-まとめ",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "Part. 2 まとめ",
    "text": "Part. 2 まとめ\n達成🎉\n\nリードマッピングの方法と SAM ファイルの形式について理解した。\nバリアントコールの方法と VCF について理解した。\n\n\n参考\n\nBWA ドキュメント\nSAMtools マニュアルページ\nBCFtools マニュアルページ\n\n\n\n\nPart. 3 へ"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#tips-1.-パイプ-によるファイル出力の省略",
    "href": "slides/snp24/02_mapping-call.html#tips-1.-パイプ-によるファイル出力の省略",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "Tips 1. パイプ | によるファイル出力の省略",
    "text": "Tips 1. パイプ | によるファイル出力の省略\nパイプ | は | の前のコマンドの標準出力を | の後のコマンドの標準入力へ渡す仕組み。\n\n\n\n使い方:\nbcftools mpileup -f Ecoli.fa SRR030257.cfsm.bam &gt; SRR030257.mpileup\nbcftools call -c -v --ploidy 1 SRR030257.mpileup -o SRR030257.vcf\n  \nbcftools mpileup -f Ecoli.fa SRR030257.cfsm.bam | bcftools call -c -v --ploidy 1 -o SRR030257.vcf\nbcftools mpileup の出力 (SRR030257.mpileup) を bcftools call の入力として直接使う。"
  },
  {
    "objectID": "slides/snp24/02_mapping-call.html#tips-2.-apptainer-イメージの使用",
    "href": "slides/snp24/02_mapping-call.html#tips-2.-apptainer-イメージの使用",
    "title": "Part. 2 リードマッピング、バリアントコール",
    "section": "Tips 2. apptainer イメージの使用",
    "text": "Tips 2. apptainer イメージの使用\n https://sc.ddbj.nig.ac.jp/software/BioContainers/ \nApptainer はユーザが解析ソフトウェアをインストール不要で使える仕組み。\n「使いたいコマンドが遺伝研スパコンにない！」ときや「違うバージョンのソフトが使いたい！」ときに便利。\n$ samtools --version\nsamtools 1.13\n# デフォルトの SAMtools のバージョンは 1.13 だけど\n\n$ apptainer exec /usr/local/biotools/s/samtools:1.19.1--h50ea8bc_0 samtools --version\nsamtools 1.19.1\n# もっと新しいバージョンを使うこともできる。"
  },
  {
    "objectID": "slides/snp24/index.html#概要",
    "href": "slides/snp24/index.html#概要",
    "title": "全ゲノム解析ハンズオン — スモールデータで理解する SNP 解析の流れ",
    "section": "概要",
    "text": "概要\n\n目的\n\nスモールデータを使って、全ゲノム解析のパイプラインを一通り (公開データ取得から SNP アノテーションまで) 体験する。 その際、各解析で出てくる中間ファイル等にも触れることで、どのようなデータを使って、どのような解析が動いているかについて理解を深める。\n\n日程\n\n2024-11-29 10:30–12:00, 15:00–16:30\n\n環境\n\n遺伝研スパコン\n\nやること\n\n基本的なコマンドライン操作\n\n\nNGS 公開データの取得\n\n\nクオリティコントロール\n\n\nリードマッピング、バリアントコール\n\n\nSNP アノテーション\n\nスライドのリンク\n\nPart. 1 コマンドライン操作、データ取得、クオリティコントロール\n\n\nPart. 2 リードマッピング、バリアントコール\n\n\nPart. 3 SNP アノテーション\n\n\n←/→ で戻る/進む"
  },
  {
    "objectID": "slides/snp24/index.html#材料",
    "href": "slides/snp24/index.html#材料",
    "title": "全ゲノム解析ハンズオン — スモールデータで理解する SNP 解析の流れ",
    "section": "材料",
    "text": "材料\n大腸菌 Escherichia coli\n\n参照配列: B str. REL606 (Ensembl47)\nIllumina ショートリード: SRR030257\n\n\n参考論文\n\nBarrick et al. 2009"
  },
  {
    "objectID": "slides/snp24/index.html#requirement",
    "href": "slides/snp24/index.html#requirement",
    "title": "全ゲノム解析ハンズオン — スモールデータで理解する SNP 解析の流れ",
    "section": "Requirement",
    "text": "Requirement\n\n遺伝研スパコンにログインできる環境\nSRA toolkit\nfastp\nBWA\nSAMtools\nBCFtools\nSnpEff\n\nスライドを見て、自身で進められるところまで進めておいてもらえると当日とてもスムーズです。"
  },
  {
    "objectID": "slides/snp24/index.html#全ゲノム解析の流れ",
    "href": "slides/snp24/index.html#全ゲノム解析の流れ",
    "title": "全ゲノム解析ハンズオン — スモールデータで理解する SNP 解析の流れ",
    "section": "全ゲノム解析の流れ",
    "text": "全ゲノム解析の流れ\n\n\n\n配列取得\n\n次世代シーケンサ (NGS) によりシーケンスした DNA は Fastq フォーマット (.fastq) になる。 既報で解読済みの配列は NCBI などにアーカイブされており、 データベースから取得して利用できる。\n\n\nSRA Toolkit\n\nクオリティコントロール (QC)\n\nFastq の生データにはうまくシーケンスできていない低品質な配列、 シーケンス時に付加するアダプタ配列、他サンプル由来のリードなどが含まれる。 こうした配列は偽陽性バリアントのもととなるため、解析から取り除く。\n\n\nFastQC, Fastp, Trimmomatic など\n\nマッピング\n\nシーケンスしたショートリードを参照配列 (リファレンス) の一致する箇所に並べ、 もとのゲノム配列のどこに由来するのかを調べる。\n\n\nBWA, Bowtie2 など\n\nバリアントコール\n\n参照配列とリードの配列とを比べ、参照配列と異なる塩基 (SNP) や 重複配列、挿入欠失 (Indel) を特定する。\n\n\nGATK, SAMtools, BCFtools など\n\n\n\n\n\n\n\n\n\n\nflowchart TD\n  A(Sample) -.-&gt;|DNA 抽出| B(DNA)\n  B -.-&gt;|NGS| C[Fastq]\n  X[(NCBI)] -.-&gt;|prefetch| C\n  C -.-&gt;|QC, マッピング| D[SAM]\n  D -.-&gt;|圧縮| E[BAM]\n  E -.-&gt;|バリアントコール| F[VCF/BCF]"
  },
  {
    "objectID": "win/git4win.html#git-for-windows-をインストールする",
    "href": "win/git4win.html#git-for-windows-をインストールする",
    "title": "Git for Windows — Windows で Git を使う",
    "section": "Git for Windows をインストールする",
    "text": "Git for Windows をインストールする\nDownload for Windows のページからインストーラを入手。\nインストール時の設定は基本的にデフォルトでいい。 コミット時のエディタと git pull の挙動は適当なものを選ぶ。\n\nSelect Destination Location\n\nC:\\Program Files\\Git\n\nSelect Components, Select Start Menu Folder\n\ndefault\n\nChoosing the default editor used by Git\n\nUse Visual Studio Code as Git’s default editor\n\nAdjusting the name of the initil branch in new repositories\n\nOverride the default branch name for new repositories main\n\nAdjusting your PATH environment\n\nGit from the command line and also from 3rd-party software (recommended)\n\nChoosing the SSH executable\n\nUse bundle OpenSSH\n\nChoose HTTPS transport backend\n\nUse the OpenSSL library\n\nConfiguring the line ending conversion\n\nCheckout Windows-style, commit Unix-style line ending\n\nConfiguring the terminal emulator to use with Git Bash\n\nUse MinTTY (the default terminal of MSYS2)\n\nChoose the default behavior of git pull\n\nFast-forward or merge\n\nChoose a credential helper\n\nGit Credential Manager\n\nConfiguring extra options\n\nEnable file system caching\n\n\nEnable symboic links\n\nConfiguring experimental options\n\nチェックなし",
    "crumbs": [
      "Windows",
      "Git for Windows"
    ]
  },
  {
    "objectID": "win/git4win.html#グローバル設定",
    "href": "win/git4win.html#グローバル設定",
    "title": "Git for Windows — Windows で Git を使う",
    "section": "グローバル設定",
    "text": "グローバル設定\nWindows のホームディレクトリに .gitconfig ができる。\nここに必要な設定を追加していく:\n\n\n~/.gitconfig\n\n[user]\n    name = ymat2\n    email = ymat2@users.noreply.github.com\n\n[init]\n    defaultBranch = main\n\n[push]\n    default = simple\n\n[pull]\n    ff = only\n\n[url \"git@github.com:\"]\n    pushinsteadof = https://github.com/\n\n[diff]\n    submodule = log\n\n[core]\n    editor = vim\n\nこれだけでもほぼ Unix と同じように使える。 実際の使い方は Git/GitHub を参照。",
    "crumbs": [
      "Windows",
      "Git for Windows"
    ]
  },
  {
    "objectID": "win/git4win.html#git-bash",
    "href": "win/git4win.html#git-bash",
    "title": "Git for Windows — Windows で Git を使う",
    "section": "Git Bash",
    "text": "Git Bash\nGit for Windows に同梱されている Bash エミュレーション。 Bash と基本的なコマンドが提供されている。 MSYS ベース。 パッケージ管理ツール (pacman) とビルドツールチェイン (gcc など) は付いていない。\nGit Bash アプリからターミナルを開くか、 Windows Terminal のプロンプトの1つとして登録する。 起動オプションで明示的にログインシェルとして立ち上げる --login 必要がある?",
    "crumbs": [
      "Windows",
      "Git for Windows"
    ]
  },
  {
    "objectID": "win/git4win.html#posh-git",
    "href": "win/git4win.html#posh-git",
    "title": "Git for Windows — Windows で Git を使う",
    "section": "posh-git",
    "text": "posh-git\n\nposh-git is a PowerShell module that integrates Git and PowerShell by providing Git status summary information that can be displayed in the PowerShell prompt\n\nらしい。 PowerShell で Git を便利に使うためのモジュールっぽいが、必ずしも必要ではない。",
    "crumbs": [
      "Windows",
      "Git for Windows"
    ]
  },
  {
    "objectID": "win/wsl-disk-space.html#wsl-を使っている人へ",
    "href": "win/wsl-disk-space.html#wsl-を使っている人へ",
    "title": "WSL Disk Space — 逼迫した WSL のディスクスペースを解放する",
    "section": "WSL を使っている人へ",
    "text": "WSL を使っている人へ\nWSL2 のディスク消費は、WSL2 内部でファイルを消してもサイズが小さくならないらしい。 つまり、いくら WSL 側でファイルを rm しようが garbage collection しようが、 マシンのストレージは圧迫され続ける。\nWSL2 で使用する Linux ディストリビューションのデータは仮想ハードディスク (VHD) で管理されていて、 ここがデータの本体を持っているから、だと思う。\nなので根本的にディスク容量を開放するには、 VHD を最適化する必要がある。",
    "crumbs": [
      "Windows",
      "WSL Disk Space"
    ]
  },
  {
    "objectID": "win/wsl-disk-space.html#vhd-.vhdx-を探す",
    "href": "win/wsl-disk-space.html#vhd-.vhdx-を探す",
    "title": "WSL Disk Space — 逼迫した WSL のディスクスペースを解放する",
    "section": "VHD (.vhdx) を探す",
    "text": "VHD (.vhdx) を探す\n\n\nPowerShell\n\n&gt; ls C:\\Users\\_username_\\AppData\\Local\\Packages\\Canonical*  # _username_ は自分のものを\n\n\n    ディレクトリ: C:\\Users\\_username_\\AppData\\Local\\Packages\n\n\nMode                 LastWriteTime         Length Name\n----                 -------------         ------ ----\nd-----        2023/01/05     21:33                CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\nd-----        2023/01/05     21:36                CanonicalGroupLimited.Ubuntu_79rhkp1fndgsc\n\n使っているディストリビューションのディレクトリ内にある LocalState\\ に ext4.vhdx がいる。 (onWindows の方にはなかった。)\n\n\nPowerShell\n\n&gt; ls C:\\Users\\_username_\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu_79rhkp1fndgsc\\LocalState\\\n\n\n    ディレクトリ: C:\\Users\\_username_\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu_79rhkp1fndgsc\\LocalState\n\n\nMode                 LastWriteTime         Length Name\n----                 -------------         ------ ----\n-a----        2024/06/06     14:04   208281796608 ext4.vhdx",
    "crumbs": [
      "Windows",
      "WSL Disk Space"
    ]
  },
  {
    "objectID": "win/wsl-disk-space.html#diskpart-を使って-vhd-を確認する",
    "href": "win/wsl-disk-space.html#diskpart-を使って-vhd-を確認する",
    "title": "WSL Disk Space — 逼迫した WSL のディスクスペースを解放する",
    "section": "DISKPART を使って VHD を確認する",
    "text": "DISKPART を使って VHD を確認する\nまず wsl をシャットダウンする:\n\n\nPowerShell\n\nwsl --shutdown\n\nDISKPART インタプリタを起動する:\n\n\nPowerShell\n\ndiskpart\n\n先ほど調べた VHD を選択する:\n\n\nDISKPART\n\nDISKPART&gt; select vdisk file=C:\\Users\\_username_\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu_79rhkp1fndgsc\\LocalState\\ext4.vhdx\n\nDiskPart により、仮想ディスク ファイルが選択されました。\n\nVHD の情報を確認する:\n\n\nDISKPART\n\nDISKPART&gt; detail vdisk\n\nデバイスの種類 ID: 0 (不明)\nベンダー ID: {00000000-0000-0000-0000-000000000000} (不明)\n状態: 追加済み\n仮想サイズ: 1024 GB\n物理サイズ:  193 GB\nファイル名: C:\\Users\\_username_\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu_79rhkp1fndgsc\\LocalState\\ext4.vhdx\n子: いいえ\n親ファイル名:\n関連付けられたディスク番号: 見つかりません。",
    "crumbs": [
      "Windows",
      "WSL Disk Space"
    ]
  },
  {
    "objectID": "win/wsl-disk-space.html#vhd-ディスクスペースを最適化する",
    "href": "win/wsl-disk-space.html#vhd-ディスクスペースを最適化する",
    "title": "WSL Disk Space — 逼迫した WSL のディスクスペースを解放する",
    "section": "VHD ディスクスペースを最適化する",
    "text": "VHD ディスクスペースを最適化する\nAttach -&gt; Compact -&gt; Detach の順に実行する。\nAttach:\n\n\nDISKPART\n\nDISKPART&gt; attach vdisk readonly\n\n  100% 完了しました\n\nDiskPart により、仮想ディスク ファイルがアタッチされました。\n\nCompact (本質):\n\n\nDISKPART\n\nDISKPART&gt; compact vdisk\n\n  100% 完了しました\n\nDiskPart により、仮想ディスク ファイルは正常に圧縮されました。\n\nDetach:\n\n\nDISKPART\n\nDISKPART&gt; detach vdisk\n\nDiskPart により、仮想ディスク ファイルがデタッチされました。\n\nDISKPART を終了する (その前にもう一回 detail してもよい):\n\n\nDISKPART\n\nDISKPART&gt; exit",
    "crumbs": [
      "Windows",
      "WSL Disk Space"
    ]
  }
]